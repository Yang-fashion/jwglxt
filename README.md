# 计网

## CDN

CDN的全称是Content Delivery Network，即**内容分发网络**。其目的是**通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度**。CDN有别于镜像，因为它比镜像更智能，或者可以做这样一个比喻：CDN=更智能的镜像+缓存+流量导流。因而，CDN可以明显提高Internet网络中信息流动的效率。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等问题，提高用户访问网站的响应速度。

![](https://img-blog.csdn.net/20181018144849100)

其工作流程可以总结为：**当用户访问已经加入CDN服务的网站时，首先通过DNS重定向技术确定最接近用户的最佳CDN节点，同时将用户的请求指向该节点。当用户的请求到达指定节点时，CDN的服务器（节点上的高速缓存）负责将用户请求的内容提供给用户**。具体流程为: 用户在自己的浏览器中输入要访问的网站的域名，浏览器向本地DNS请求对该域名的解析，本地DNS将请求发到网站的主DNS，主DNS根据一系列的策略确定当时最适当的CDN节点，并将解析的结果（IP地址）发给用户，用户向给定的CDN节点请求相应网站的内容。


### 负载均衡技术

负载均衡技术不仅仅应用于CDN中，在网络的很多领域都得到了广泛的应用，如**服务器的负载均衡、网络流量的负载均衡**。顾名思义，**网络中的负载均衡就是将网络的流量尽可能均匀分配到几个能完成相同任务的服务器或网络节点上，由此来避免部分网络节点过载**。这样既可以提高网络流量，又提高了网络的整体性能。**在CDN中，负载均衡又分为服务器负载均衡和服务器整体负载均衡**(也有的称为服务器全局负载均衡)。服务器负载均衡是指能够**在性能不同的服务器之间进行任务分配**，既能保证性能差的服务器不成为系统的瓶颈，又能保证性能高的服务器的资源得到充分利用。而服务器整体负载均衡允许Web网络托管商、门户站点和企业根据地理位置分配内容和服务。通过使用多站点内容和服务来提高容错性和可用性，防止因本地网或区域网络中断、断电或自然灾害而导致的故障。在CDN的方案中服务器整体负载均衡将发挥重要作用，其性能高低将直接影响整个CDN的性能。

### 动态分发与复制技术

众所周知，网站访问响应速度取决于许多因素，如网络的带宽是否有瓶颈、传输途中的路由是否有阻塞和延迟、网站服务器的处理能力及访问距离等。多数情况下，**网站响应速度和访问者与网站服务器之间的距离有密切的关系。**如果访问者和网站之间的距离过远的话，它们之间的通信一样**需要经过重重的路由转发和处理**，网络延误不可避免。一个有效的方法就是**利用内容分发与复制技术**，将占网站主体的大部分**静态网页、图像和流媒体数据分发复制到各地的加速节点上**。所以动态内容分发与复制技术也是CDN所需的一个主要技术。

### 缓存技术

缓存技术已经不是一种新鲜技术。Web缓存服务通过几种方式来改善用户的响应时间，如代理缓存服务、透明代理缓存服务、使用重定向服务的透明代理缓存服务等。通过Web缓存服务，用户访问网页时可以将广域网的流量降至最低。对于公司内联网用户来说，这意味着将内容在本地缓存，而无须通过专用的广域网来检索网页。对于Internet用户来说，这意味着将内容存储在他们的ISP的缓存器中，而无须通过Internet来检索网页。这样无疑会提高用户的访问速度。CDN的核心作用正是提高网络的访问速度，所以，缓存技术将是CDN所采用的又一个主要技术。

### 工作原理

**CDN网络是在用户和服务器之间增加Cache层**，主要是通过接管DNS实现，**将用户的请求引导到Cache上获得**源服务器的数据，从而降低网络的访问时间。
首先，让我们看一下传统的未加缓存服务的访问过程：

![在这里插入图片描述](https://img-blog.csdn.net/20181018151508334)

如图可以看出，传统的网络访问的流程如下：

1. 用户输入访问的域名,操作系统向 LocalDns 查询域名的ip地址；
2. LocalDns向 ROOT DNS 查询域名的授权服务器(这里假设LocalDns缓存过期)；
3. ROOT DNS将域名授权dns记录回应给 LocalDns
4. LocalDns得到域名的授权dns记录后，继续向域名授权dns查询域名的ip地址；
5. 域名授权dns 查询域名记录后，回应给 LocalDns；
6. LocalDns 将得到的域名ip地址，回应给用户端；
7. 用户得到域名ip地址后，访问站点服务器；
8. 站点服务器应答请求，将内容返回给客户端.



下面让我们看一下使用CDN缓存后的网站的访问过程：

![在这里插入图片描述](https://img-blog.csdn.net/20181018152139324)

如上图，是使用CDN缓存后的网络访问流程：

1. 用户输入访问的域名,操作系统向 LocalDns 查询域名的ip地址；
2. LocalDns向 ROOT DNS 查询域名的授权服务器(这里假设LocalDns缓存过期)；
3. ROOT DNS将域名授权dns记录回应给 LocalDns；
4. LocalDns得到域名的授权dns记录后,继续向域名授权dns查询域名的ip地址；
5. 域名授权dns 查询域名记录后(一般是CNAME)，回应给 LocalDns；
6. LocalDns 得到域名记录后,向智能调度DNS查询域名的ip地址；
7. 智能调度DNS 根据一定的算法和策略(比如静态拓扑，容量等),将最适合的CDN节点ip地址回应给 LocalDns；
   LocalDns 将得到的域名ip地址，回应给用户端；
8. 用户得到域名ip地址后，访问站点服务器。
9. 宗上，CDN网络是在用户和服务器之间增加Cache层，主要是通过接管DNS实现，将用户的请求引导到Cache上获得源服务器的数据，从而降低网络的访问的速度。
   



## 为什么把网络分为这么多层

- 简化问题难度和复杂度。由于各层之间独立，我们可以分割大问题为小问题。
- 灵活性好。当其中一层的技术变化时，只要层间接口关系保持不变，其他层不受影响。
- 易于实现和维护。
- 促进标准化工作。分开后，每层功能可以相对简单地被描述。

#### 网络协议分层的缺点

 功能可能出现在多个层里，产生了额外开销。



## webSocket

WebSocket protocol 是HTML5一种新的协议。它实现了浏览器与服务器全双工通信(full-duplex)。一开始的握手需要借助HTTP请求完成。——百度百科

### 目的：即时通讯，替代轮询

HTTP协议是**非持久化**的(每次只能处理一个请求)，**单向**的网络协议，在建立连接后只允许浏览器向服务器发出请求后，服务器才能返回相应的数据。当需要**即时通讯时**，通过轮询在特定的时间间隔（如1秒），由浏览器向服务器发送Request请求，然后将最新的数据返回给浏览器。这样的方法最明显的缺点就是需要不断的发送请求，而且通常HTTP request的Header(请求头信息)是非常长的，为了传输一个很小的数据 需要付出巨大的代价，是很不合算的，占用了很多的宽带。还有就是频繁的建立关闭连接是很耗资源和时间的。

### webSocket实现原理

- \1. 浏览器、服务器建立TCP连接，三次握手。这是通信的基础，传输控制层，若失败后续都不执行。
- \2. TCP连接成功后，浏览器通过HTTP协议向服务器传送WebSocket支持的版本号等信息。（***\*开始前的HTTP握手\****）
- . 服务器收到客户端的握手请求后，**同样采用HTTP协议**回馈数据。
- . 当收到了连接成功的消息后，通过TCP通道进行传输通信。

### WebSocket与HTTP的关系

#### 相同点

- \1. 都是一样基于TCP的，都是可靠性传输协议。
- \2. 都是应用层协议。

#### 不同点

- \1. WebSocket是双向通信协议，模拟Socket协议，可以双向发送或接受信息。HTTP是单向的。
- \2. WebSocket是需要握手进行建立连接的。

#### 联系

WebSocket在建立握手时，数据是通过HTTP传输的。但是建立之后，在真正传输时候是不需要HTTP协议的。

###  WebSocket与Socket的关系

Socket其实并不是一个协议，而是为了方便使用TCP或UDP而抽象出来的一层，是位于应用层和传输控制层之间的一组接口。

Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。

当两台主机通信时，必须通过Socket连接，Socket则利用TCP/IP协议建立TCP连接。TCP连接则更依靠于底层的IP协议，IP协议的连接则依赖于链路层等更低层次。

WebSocket则是一个典型的应用层协议。

### websocket握手环节(详解)

握手环节：验证服务端是否支持websocket协议
		1）创建连接，浏览器连接服务端，创建连接成功
		2）浏览器生成一个随机字符串，浏览器存一份该随机字符串，同时发一份给服务端（基于http协议发到服务端，会把该字符串放在http请求头里发给服务端）
		3）服务端收到随机字符串之后，让它跟魔法字符串（magic string，全球公认的固定字符串）拼接，然后再通过sha1算法进行加密然后再通过base64编码后，生成密文
		4）服务端将密文返回给浏览器（该密文无法反解）
		5）浏览器也将本地存的随机字符串与magic string进行拼接并加密编码之后得到一个密文
		6）浏览器将服务端发来的密文与本地的密文进行对比、校验，若通过，则说明两端用的同一个magic string，即用的同一种加密手段，即可以判定服务端支持websocket协议，握手成功；若校验不通过，则代表服务端不支持websocket协议，握手失败

###  websocket收发数据环节(详细)

收发数据环节：数据是加密的
	1）浏览器将数据加密发往客户端
	2）服务端接收到数据之后进行的解密（解密是全球公认的）
		a) 拿到第2个字节（8位），取其后7位(即前两个字节的10-16位)，也就是数据的前9位都不要，我们取到的7位称之为payload length（7位最大值是127）；
		b) 服务端对payload length的值进行判断：
			1> 若payload length =  127：
				  再往后读8个字节(即64bit/位)，也就是说前10个字节(8+2)是数据头，后面才是数据
			2> 若payload length =  126：
				  再往后读2个字节(即16bit/位)，也就是说前4个字节(2+2)是数据头，后面才是数据部分
			3> 若payload length <= 125：
				  不往后读，前面2个字节就是数据头，后面都是数据部分
	3）通过b解密过程获取数据，但是该数据也不是明文的，还需要再解密
		a) 获取到数据部分后，再往后读4个字节，该4个字节称之为masking key，剩下部分是真正的数据；
		b) 让masking key与数据的每一个字节进行位运算(与或运算)，运算完之后就获取到了最终的数据(具体过程可见官网)

## 大型网站都采用get方法，而非post方法

## Http

### HTTP的幂等性

HTTP协议本身是一种**面向资源的应用层协议**，但对HTTP协议的使用实际上存在着两种不同的方式：一种是RESTful的，它把HTTP当成应用层协议，比较忠实地遵守了HTTP协议的各种规定；另一种是SOA的，它并没有完全把HTTP当成应用层协议，而是把HTTP协议作为了传输层协议，然后在HTTP之上建立了自己的应用层协议。本文所讨论的HTTP幂等性主要针对RESTful风格的，不过正如上一节所看到的那样，幂等性并不属于特定的协议，它是分布式系统的一种特性；所以，不论是SOA还是RESTful的Web API设计都应该考虑幂等性。下面将介绍HTTP GET、DELETE、PUT、POST四种主要方法的语义和幂等性。

HTTP **GET方法用于获取资源，不应有副作用，所以是幂等的**。比如：GET http://www.bank.com/account/123456，**不会改变资源的状态，不论调用一次还是N次都没有副作用。这里强调的是一次和N次具有相同的副作用，而不是每次GET的结果相同。GET http://www.news.com/latest-news这个HTTP请求可能会每次得到不同的结果，但它本身并没有产生任何副作用，因而是满足幂等性的。

HTTP **DELETE方法用于删除资源，有副作用，但它应该满足幂等性。**比如：DELETE http://www.forum.com/article/4231，调用一次和N次对系统产生的副作用是相同的，即删掉id为4231的帖子；因此，调用者可以多次调用或刷新页面而不必担心引起错误。

比较容易混淆的是HTTP POST和PUT。POST和PUT的区别容易被简单地误认为“**POST表示创建资源，PUT表示更新资源**”；而实际上，二者均可用于创建资源，更为本质的差别是在幂等性方面。



**POST所对应的URI并非创建的资源本身，而是资源的接收者**。比如：POST http://www.forum.com/articles的语义是在http://www.forum.com/articles下创建一篇帖子，HTTP响应中应包含帖子的创建状态以及帖子的URI。**两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI**；所以，**POST方法不具备幂等性**。而PUT所对应的URI是要**创建或更新的资源本身**。比如：PUT http://www.forum/articles/4231的语义是创建或更新ID为4231的帖子。对同一URI进行多次PUT的副作用和一次PUT是相同的；因此，PUT方法具有幂等性。

在介绍了几种操作的语义和幂等性之后，我们来看看如何通过Web API的形式实现前面所提到的取款功能。很简单，用POST /tickets来实现create_ticket；用PUT /accounts/account_id/ticket_id&amount=xxx来实现idempotent_withdraw。值得注意的是严格来讲amount参数不应该作为URI的一部分，真正的URI应该是/accounts/account_id/ticket_id，而amount应该放在请求的body中。这种模式可以应用于很多场合，比如：论坛网站中防止意外的重复发帖。



### 认识 HTTP

 HTTP 是一种 `超文本传输协议(Hypertext Transfer Protocol)`

超文本传输协议可以进行文字分割：**超文本（Hypertext）、传输（Transfer）、协议（Protocol）**

### 什么是超文本

在互联网早期的时候，**我们输入的信息只能保存在本地**，无法和其他电脑进行交互。我们保存的信息通常都以**文本即简单字符的形式存在**，文本是一种能够**被计算机解析的有意义的二进制数据包**。而随着互联网的高速发展，两台电脑之间能够进行数据的传输后，人们不满足只能在两台电脑之间传输文字，还想要**传输图片、音频、视频，甚至点击文字或图片能够进行超链接的跳转**，那么文本的语义就被扩大了，这种语义扩大后的文本就被称为超文本(Hypertext)。

### 什么是传输

两台计算机之间会形成互联关系进行通信，我们存储的超文本会被解析成为二进制数据包，**由传输载体（例如同轴电缆，电话线，光缆）负责把二进制数据包由计算机终端传输到另一个终端的过程**（对终端的详细解释可以参考 [你说你懂互联网，那这些你知道么？](https://mp.weixin.qq.com/s?__biz=MzU2NDg0OTgyMA==&mid=2247484872&idx=1&sn=49e3e9d3f31ad39ad92f78921bc45ccf&chksm=fc45f83bcb32712d98e577ef3980be895e72432de9749ba3c56d6189268552a738a88103deeb&token=600677552&lang=zh_CN#rd)这篇文章）称为`传输(transfer)`。

通常我们把传输数据包的一方称为`请求方`，把接到二进制数据包的一方称为`应答方`。请求方和应答方可以进行互换，请求方也可以作为应答方接受数据，应答方也可以作为请求方请求数据，它们之间的关系如下

### 什么是协议

协议这个名词不仅局限于互联网范畴，也体现在日常生活中，比如情侣双方约定好在哪个地点吃饭，这个约定也是一种协议，比如你应聘成功了，企业会和你签订劳动合同，这种双方的雇佣关系也是一种 协议。注意自己一个人对自己的约定不能成为协议，协议的前提条件必须是多人约定。

那么网络协议是什么呢？

网络协议就是网络中(包括互联网)传递、管理信息的一些规范。如同人与人之间相互交流是需要遵循一定的规矩一样，计算机之间的相互通信需要共同遵守一定的规则，这些规则就称为网络协议。

没有网络协议的互联网是混乱的，就和人类社会一样，人不能想怎么样就怎么样，你的行为约束是受到法律的约束的；那么互联网中的端系统也不能自己想发什么发什么，也是需要受到通信协议约束的。

那么我们就可以总结一下，什么是 HTTP？可以用下面这个经典的总结回答一下： HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范



### 网络模型

为了给网络协议的设计提供一个结构，网络设计者以分层(layer)的方式组织协议，每个协议属于层次模型之一。每一层都是向它的上一层提供服务(service)，即所谓的服务模型(service model)。每个分层中所有的协议称为 协议栈(protocol stack)。因特网的协议栈由五个部分组成：物理层、链路层、网络层、运输层和应用层。我们采用自上而下的方法研究其原理，也就是应用层 -> 物理层的方式。

### CDN

CDN的全称是Content Delivery Network，即内容分发网络，它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。**CDN 是构建在现有网络基础之上的网络，它依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。**

打比方说你要去亚马逊上买书，之前你只能通过购物网站购买后从美国发货过海关等重重关卡送到你的家里，现在在中国建立一个亚马逊分基地，你就不用通过美国进行邮寄，从中国就能把书尽快给你送到。

###  HTTP 报文

**1. 请求信息组成**
　　请求信息 = 请求行 + 请求头 + 请求体（只有post请求才会存在请求体信息）

**2. 请求行**
请求行 = 请求方式 + 请求的资源 + http协议的版本

- 请求方式：get / post
- 请求资源：URL
- Http协议的版本：HTTP/1.1

**3. 请求头**

```java
Host: localhost:9090 (服务器的域名)
Connection: keep-alive (网络连接是持久的)
Content-Length: 12      (发送数据的大小, 单位字节)
Cache-Control: max-age=0   (设置缓存数据的存活时间, 单位秒)
Origin: http://localhost:9090  (指示了请求来自于哪个站点——服务器名称)
Upgrade-Insecure-Requests: 1   (如果存在更安全的响应，客户端优先选择加密及带有身份验证的响应)
Content-Type: application/x-www-form-urlencoded (发送数据的媒体类型 — 发挥作用类似后缀名：.mp3 .avi)
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36  (当前客户使用的浏览器版本)
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8
Referer: http://localhost:9090/day01/1.html(代表了来哪个页面)
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9
Cookie: JSESSIONID=98006861B5044ACC8D5C7840C93C17DA

```

**4. 请求体**
　　只有Post请求有

#### 响应信息

**1. 响应信息组成**
　　响应信息 = 状态行（响应行）+ 响应头 + 响应体

```
HTTP/1.1 200        ----------------  响应行(状态行)
Content-Length: 3
Date: Sun, 26 Aug 2019 00:41:49 GMT	  -----响应头

空行

ABC    响应体内容            ---------------响应体

```

**2. 响应行**
　　响应行 = 协议版本 + 状态码，例：`HTTP/1.1 200`

**常见的响应状态码**
　　状态码的作用：代表了本次的请求服务器的响应状态(本次的请求是否成功)

```
1. 200 OK                 ------请求已成功,服务器通信正常。
2. 302 Move temporarily   -----设置重定向页面跳转的动作执行(页面发生跳转了)
3. 304 Not Modified       -----从浏览器缓存中读取数据,不从服务器重新获取数据
4. 404 Not Found                -----请求的资源不存在,url地址出错
5. 405 Method Not Allowed  请求行中指定的请求方法不存在,例如发送post请求,服务器没有doPost方法,就会报这个错误
6. 500 Internal Server Error    ------服务器发生了错误,一般服务器代码错误

```

**3. 响应头**
　　响应头的数据是响应给浏览器，可以设置响应头的数据，让浏览器按照我们指定的设置进行执行响应的功能。
　　
**常见响应头介绍：**

```
Location: http://www.it315.org/index.jsp 	--跳转方向
Server:apache tomcat			--服务器型号
Content-Encoding: gzip 			--数据压缩  
Content-Length: 80 			--数据长度
Content-Language: zh-cn 		--语言环境
Content-Type: text/html; charset=GB2312 		--编码
Last-Modified: Tue, 11 Jul 2000 18:23:51 GMT	--最后修改时间
Refresh: 1;url=http://www.it315.org		--定时跳转
Content-Disposition: attachment; filename=aaa.zip	--下载
Set-Cookie:SS=Q0=5Lb_nQ; path=/search
Expires: -1					--缓存
Cache-Control: no-cache  			--缓存
Pragma: no-cache   				--缓存
Connection: close/Keep-Alive   			--连接
Date: Tue, 11 Jul 2000 18:23:51 GMT		--时间

```

refresh: 定时刷新跳转页面
location:重定向操作，通常告知浏览器马上向该地址发送请求，与响应码302一起使用
content-encoding: 设置当前数据的压缩格式，告知浏览器以何种压缩格式解压数据
content-disposition: 通知浏览器以何种方式获取数据，直接解析数据(网页/图片文本)或者以附件方式(下载文件)
content-type: 实体头部用于指示资源的MIME类型（MIME类型：用于提示当前文件的媒体类型，例如图片 — (image/png)、音频 —（audio/ogg)）

## HTTPS

HTTPs请求流程

 ![img](https://img-blog.csdnimg.cn/20190509111404989.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NldWphdmFfZXI=,size_16,color_FFFFFF,t_70) 

客户端首先发送请求到服务器，服务器返回CA机构提供的公钥，和证书。客户端验证证书有没有过期，以及证书的真假。如果验证有效那我客户端这边随机生成一个密钥，使用CA机构的公钥进行一个非对称加密算法加密，服务器使用私钥进行解密。服务器知道了密钥以后以后的传输就用对称加密。

### 对称加密

对称加密的大致过程是服务端随机生成一个密钥发给浏览器，此后浏览器在和服务端进行通信的时候都是基于这个密钥，但是很明显的一个问题就是在服务端发送密钥给浏览器的时候，如果被中间人给截获，换成了攻击者的密钥，那次后浏览器和服务端进行通信的时候都会被中间人知道了。对称加密的代表算法有：AES、DES等。

### 非对称加密

非对称加密的大致过程是服务端有两把密钥，一把是私钥，一把1是公钥，服务端先把公钥传输给浏览器，浏览器有了公钥以后，再发送数据用这个公钥对数据进行加密，这样及时中间人截获了数据由于没有私钥，也还是无法进行解密的，所以相对来说比对称加密更加安全，但是效率比较低，**这是因为对称加密主要的运算是位运算，速度非常快，如果使用硬件计算，速度会更快。但是非对称加密计算一般都比较复杂，比如 RSA，它里面涉及到大数乘法、大数模等等运算。非对称加密的代表算法有：RSA、ElGamal等**

### 混合加密

因为非对称加密太慢了，所以采用了一种混合加密的方式，

- 某网站服务器拥有一组用于公开密钥加密的非对称密钥：公钥 A1、私钥 A2
- 浏览器向网站服务器请求，服务器把公钥 A1 明文给传输浏览器
- 接收到这把公钥 A1 后，浏览器随机生成一个用于共享密钥加密（对称加密）的密钥 X，用公钥 A1 加密后传给服务器。这个阶段，即便被攻击者截获，由于攻击者没有对应的私钥也无法解密该内容
- 服务器拿到后用对应的私钥 A2 解密得到密钥 X（以上这些阶段就是公开密钥加密）
- 这样双方就都拥有密钥 X 了，且别人无法知道它。之后双方之间所有的数据传输都使用密钥 X 进行加密和解密即可（这个阶段就是共享密钥加密）

###  数字证书

但是混合加密本身还是存在问题，就是第一次服务端传递给浏览器的公钥是明文传输依然存在被截取的风险，如果被截取了，那即便得不到服务端的私钥，也能截获传输的信息

- 某网站服务器拥有一组用于公开密钥加密的非对称密钥：公钥 A1、私钥 A2
- 浏览器向网站服务器请求，**服务器把公钥 A1 明文给传输浏览器**
- 攻击者劫持到公钥 A1，保存下来，**把数据包中的公钥 A1 替换成自己伪造的公钥 B1**（它当然也拥有公钥 B1 对应的私钥 B2）
- **浏览器随机生成一个用于对称加密的密钥 X，用攻击者的公钥 B1**（服务器此时不知道自己的公钥被替换了）加密后传给服务器
- **攻击者劫持后用自己的私钥 B2 解密就得到了密钥 X。然后再用服务器的公钥 A1 加密后传给服务器**
- 服务器接收到攻击者用公钥 A1 加密的信息后，用对应的私钥 A2 解密得到密钥 X

以后的通信都是基于这个密钥x来进行通信，而中间人已经知道了这个密钥x所以信息还是可以被截获，还是不安全的。

其根本原因是**「浏览器客户端无法确认自己收到的公钥是不是真正的网站服务器的」**

那这里其实就引出了CA机构，**它其实就是所谓公信机构，就是客户端和浏览器都信赖的第三方机构**

**「数字证书认证机构 Certificate Authority, CA」**



网站服务器在使用 HTTPS 前，需要向 CA 申请颁发**「数字证书」**，数字证书里有证书持有者、证书持有者的公钥等信息。服务器把数字证书明文传输给浏览器客户端，然后浏览器从证书里取出服务器的公钥就可以了。

然而这里又有一个显而易见的问题：**「证书本身的传输过程中，如何防止被篡改」**？即如何证明证书本身的真实性？数字证书怎么防伪呢？

数字证书认证机构 CA 在判明提出申请者的身份之后，会对其申请的公开密钥做**「数字签名」**，然后将数字签名和公开密钥放入数字证书。**而客户端在收到服务器发送来的数字证书后，对证书上面的数字签名进行验证，如果这个数字签名和证书上的原始公开密钥 Hash 后的结果一致**，那么客户端便可明确两件事情：

- 认证服务器的公开密钥的是真实有效的数字证书认证机构
- 服务器的公开密钥是值得信赖的



**数字证书认证机构 CA 把要传送的明文信息（也就是申请认证的网站服务器的公钥）通过 Hash 算法得出摘录信息 MIC（摘录技术），再用自己的私钥对 MIC 值进行加密，就得到了得到数字签名。**



认证机构一般会持有一组公钥 A1 和私钥 A2，为了确保证书的安全性，**「浏览器客户端通常会在内部事先植入常用认证机构的公钥 A1」**，认证机构在颁发数字证书的时候，会**用自己的私钥 A2 对数字签名进行加密**。而浏览器接收到数字证书后，先利用事先存储好的公钥 A1 解密数字签名，再对数字签名进行验证。

**浏览器客户端验证网站数字证书的过程**

- 浏览器客户端接收到网站服务器发来的数字证书，得到网站的公钥 A 和数字签名 S1
- 浏览器使用事先植入的 CA 机构的公钥对 S1 进行解密，得到 S2
- 用数字证书里说明的 Hash 算法对网站的公钥 A 进行 Hash 得到 A2。
- 比较 S2 是否等于 A2，若相等则表示证书可信。于是浏览器就可以放心的取出数字证书中的网站公钥 A 进行使用

###  **为什么 HTTPS 没有被全面采用**

其中一个原因就是，由于使用了加密通信， 相比于纯文本通信的 HTTP 来说，**「HTTPS 会消耗掉更多的 CPU 及内存资源」**，如果每次通信都加密，会消耗掉非常多的资源，平摊到一台计算机上时，能够处理的请求数量必定也会随之减少。一些国际大型网站比如维基百科等，在启用 HTTPS 前都会先考虑自己服务器资源和计算能力是否可以承载 HTTPS。

因此，如果是非敏感信息，使用 HTTP 通信也无妨。只有在涉及个人敏感信息等数据时，才需要使用 HTTPS。

另外，开启 HTTPS 需要申请 SSL 证书，**「高额的证书申购费用」**会让很多网站开发者望而却步。





## Session与Cookie区别

1、我们知道HTTP是一种无状态的协议，服务器无法分辨链接是谁发起的。这样就会有一个问题，就是有些情况下即使是同一个网站每打开一个页面也都要登录一下。这样的话就会造成不必要的访问数据库，无端的给数据库造成压力。那Session和Cookie就是为解决这个问题而提出来的两个机制。

### 2、session原理(有时间限制，默认30分钟,浏览器关闭即消失)：

1. 浏览器第一次访问服务器时会创建一个session对象(一般是以文件的形式创建)并返回一个JSESSIONID=ID的值，创建一个Cookie对象key为JSSIONID，value为ID的值，将这个Cookie写回浏览器；

2. 浏览器在第二次访问服务器的时候携带Cookie信息JSESSIONID(Java中)=ID的值，如果该JSESSIONID的session已经销毁，那么会重新创建一个新的session再返回一个新的JSESSIONID通过Cookie返回到浏览器；

3. 针对一个web项目，一个浏览器是共享一个session，就算有两个web项目部署在同一个服务器上，针对两个项目的session是不同的。 如：你在tomcat上同时部署了两个web项目，分别是web1、web2。当你在一个浏览器上同时访问web1时创建的session是A1，访问web2时创建的session是A2。后面你再多次访问web1使用的session还是A1,多次访问web2时使用session就是A2

4. session是基于Cookie技术实现，重启浏览器后再次访问原有的连接依然会创建一个新的session，因为Cookie在关闭浏览器后就会消失，但是原来服务器的Session还在，只有等到了销毁的时间会自动销毁；

5. 如果浏览器端禁用了Cookie，那么每次访问都会创建一个新的Session，但是我们可以通过服务器端程序重写URL即可，如果页面多连接多，会增加不必要的工作量，那可以强制让你用户开启接收Cookie后再让其访问即可。无法禁用服务器的session

6. 两者区别： Cookie和Session都是会话技术，Cookie是保存在客户端，Session是保存在服务器端。
    Cookie有大小限制以及浏览器在存cookie的个数也有限制(我记得好像一般都是20几个，不同的浏览器也会不同，一个cookie大小一般小于4KB)，Session是没有大小限制和服务器的内存大小有关。  
   Cookie有安全隐患(因为存在客户端)，通过拦截或本地文件找得到你的cookie后可以进行攻击。
   Session是保存在服务器端上会存在一段时间才会消失，如果session过多会增加服务器的压力。
   存储数据量方面：session 能够存储任意的 java 对象，cookie 只能存储 String 类型的对象。
   Session过多时会消耗服务器资源，大型网站会有专门Session服务器，Cookie存在客户端没问题。
   域的支持范围不一样，比方说a.com的Cookie在a.com下都能用，而www.a.com的Session在api.a.com下都不能用，解决这个问题的办法是JSONP或者跨域资源共享。

   

### 关于cookie失效了session的使用情况

因为，服务器在创建session后，需要将sessionID传递给客户端，传递给客户端的方法有两种，一是URL重写机制，二是使用cookie传递。

如果客户端禁止了cookie，而你的代码中又没有实现URL重写，那么，你的sessionID是无法进行传送的，自然也就是session失效了。

**解决办法：**对所有的链接和重定向使用encodeURL()或encodeRedictURL()方法进行URL重定向，这时便相当于给了sessionID两条路，cookie禁用不会导致重定向的路走不通，就可以正常传递sessionID了。

session可以写在地址栏上，例如公众号的openid也是拼接在地址栏上的。

## URI 和 URL 的区别

Web上可用的每种资源如HTML文档、图像、视频片段、程序等都是一个来URI来定位的； URI一般由三部组成：

①访问资源的命名机制 ②存放资源的主机名 ③资源自身的名称，由路径表示，着重强调于资源。

URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上，特别是著名的Mosaic。 采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。 URL一般由三部组成：

①协议(或称为服务方式) ②存有该资源的主机IP地址(有时也包括端口号) ③主机资源的具体地址。如目录和文件名等

## **GET 和 POST 的区别**

主要区别get请求没有请求体，post请求有请求体。最重要的一个例子就是我们在做项目的时候，在controller层的某个方法的参数上加了@Requestbody的话如果用的是get方式提交请求会报错的。

#### get

get请求
Get请求就是向服务器取得的指定的资源（相当于crud的查操作）。在发出Get请求时，必须一并告诉服务器所请求资源的URL、请求参数和标头信息等。URL的编码格式采用的是ASCII编码，而不是UNICODE，就是说所有的非ASCII字符都要编码之后再传输。请求参数通常是用户发送给服务器的必要信息，请求参数是在URL之后跟一个问号?，然后是请求参数名(name)和请求参数值(value)，中间以等号(=)表示成对关系，若有多个请求参数，则以&字符连接。使用Get方式发送请求，浏览器的地址栏上会出现请求参数信息。比如：

http://localhost:8080/test/login?username=***&password=123

#### post

Post请求就是在请求时发布信息给服务器，对于大量或复杂的信息发送(如：文件上传)，基本都会采用Post方法。一个注意点是get请求没有请求体，post有。（具体原因好像有些复杂，小伙伴们自行百度一下~）

#### 如何选择

从功能上：

Get请求的请求参数会出现在地址栏上，敏感性或有安全性考虑的请求参数（如：信用卡卡号、用户名、密码等），就不应该使用GET请求发送；

Get请求可以发送的请求参数长度有限（这个长度根据浏览器种类和版本而有所不同），对于数据量太大的数据并不适合用GET方式来请求；

Post请求的请求参数不会出现在地址栏上，所以无法加入浏览器的书签（Bookmark）之中，如果有些页面是根据请求参数来作不同的画面呈现（如：论坛的文章发表），而你希望可以让用户设定书签，则应该使用GET请求。

从非功能性上：

Get请求应该用于等幂操作。Get请求纯粹取得资源，而不改变服务器上的数据或者状态。Get的请求参数，只是用来告知服务器，必须进一步根据请求参数（而不是url）来标识出要响应的内容（如查询数据库数据），同样的Get请求使用相同的参数使用多次，都应该传回相同的结果；

Post请求应该用于非等幂操作。Post请求发送的数据，可能会影响服务器上的数据或状态，例如修改（增、删）数据库的内容，或是在服务器上保存文件，你的请求若会改变服务器的状态，则应该使用Post请求。

是否为等幂操作，就是请求的操作是否改变服务器的状态，即同一个操作重复多次，是否传回同样的结果。

#### Get和Post的区别

GET在浏览器回退时是无害的，而POST会再次提交请求。

GET请求会被浏览器主动cache，而POST不会，除非手动设置。

GET请求只能进行url编码，而POST支持多种编码方式。

GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。

GET请求在URL中传送的参数是有长度限制的，而POST么有。（因为浏览器对url有长度限制，get请求的参数放在url中所以对get请求的参数也就有了限制）

GET只接受ASCII字符，而POST没有限制。（非ASCII编码都会转成ASCII）

GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。(比如一些密码等重要信息)

GET参数通过URL传递，POST放在Request body中。（浏览器对请求体没有长度限制，对于大量或复杂的信息发送，如：文件上传）

GET产生一个TCP数据包；POST产生两个TCP数据包。（对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。）注意并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

一般浏览器默认选择Get方式，上面提到的post请求会产生两个tcp包，在网络好的情况下可能感觉不到，要是网络差的话可能就明显了。

## HTTP1.0和HTTP1.1的区别

最主要的两个点:

#### 带宽优化

HTTP/1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了。例如，客户端只需要显示一个文档的部分内容，又比如下载大文件时需要支持断点续传功能，而不是在发生断连后不得不重新下载完整的包。

HTTP/1.1中在请求消息中引入了range头域，它允许只请求资源的某个部分。在响应消息中Content-Range头域声明了返回的这部分对象的偏移值和长度。如果服务器相应地返回了对象所请求范围的内容，则响应码为206（Partial Content），它可以防止Cache将响应误以为是完整的一个对象。

另外一种情况是请求消息中如果包含比较大的实体内容，但不确定服务器是否能够接收该请求（如是否有权限），此时若贸然发出带实体的请求，如果被拒绝也会浪费带宽。

HTTP/1.1加入了一个新的状态码100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。注意，HTTP/1.0的客户端不支持100响应码。但可以让客户端在请求消息中加入Expect头域，并将它的值设置为100-continue。

#### 长连接：

HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。此外，由于大多数网页的流量都比较小，一次TCP连接很少能通过slow-start区，不利于提高带宽利用率。

HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。例如：一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。

HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间。

在HTTP/1.0中，要建立长连接，可以在请求消息中包含Connection: Keep-Alive头域，如果服务器愿意维持这条连接，在响应消息中也会包含一个Connection: Keep-Alive的头域。同时，可以加入一些指令描述该长连接的属性，如max，timeout等。

#### 其他

还有一些没深入了解的一i邪恶区别比如错误提示、还有关于缓存做的一些优化。

## 输入一个网址后...

### **URL 解析**

 首先判断你输入的是一个合法的 URL 还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作。 

 由于安全隐患，会使用 HSTS 强制客户端使用 HTTPS 访问页面。 

 HSTS（HTTP Strict Transport Security）国际互联网工程组织IETF正在推行一种新的**Web安全协议**
**HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。** 

### **1.DNS解析**

（1）首先是查找**浏览器缓存**，浏览器会保存一段时间内访问过的一些网址的DNS信息，不同浏览器保存的时常不等。

（2）如果没有找到对应的记录，这个时候浏览器会尝试调用**操作系统缓存**来继续查找这个网址的对应DNS信息。

（3）如果还是没找到对应的IP，那么接着会发送一个请求到**路由器**上，然后路由器在自己的路由器缓存上查找记录，路由器一般也存有DNS信息。

（4）如果还是没有，这个请求就会被发送到ISP（注：Internet Service Provider，互联网服务提供商，就是网络运营商，中国电信中国移动等），ISP也会有相应的ISP DNS服务器，就是本地**DNS服务器**，请求的域名基本上都能在这里找得到。

（5）如果还是没有的话， ISP的DNS服务器会将请求发向**根域名服务器**进行搜索。根域名服务器就是面向全球的顶级DNS服务器，共有13台逻辑上的服务器，从A到M命名，真正的实体服务器则有几百台，分布于全球各大洲。

（6）如果到了这里还是找不到域名的对应信息，那只能说明一个问题：这个域名本来就不存在，它没有在网上正式注册过。或者域名过期了。

这也就是为什么有时候打开一个新页面会有点慢，**因为如果本地没什么缓存**，查找域名的过程要这样递归地查询下去，查找完还要一层层的向上返回。例如"mp3.baidu.com"，域名先是解析出这是个.com的域名，然后跑到管理.com域的服务器上进行进一步查询，然后是.baidu，最后是mp3， 所以域名结构为：三级域名.二级域名.一级域名。

所以DNS根据域名查询IP地址的过程为：浏览器缓存 --> 操作系统缓存 --> 路由器缓存-->本地（ISP）域名服务器缓存 --> 根域名服务器。

### 2.进行TCP连接

浏览器终于得到了IP以后，向服务器发送TCP连接，TCP连接经过三次握手。

### 3.浏览器发送HTTP请求

浏览器和服务器建立连接以后，浏览器接着给这个IP地址给服务器发送一个http请求，方式为get，例如访问www.baidu.com。其本质是在建立起的TCP连接中，按照HTTP协议标准发送一个索要网页的请求。

这个get请求包含了主机（Host）、用户代理(User-Agent)，用户代理就是自己的浏览器，它是你的"代理人"，Connection（连接属性）中的keep-alive表示浏览器告诉对方服务器在传输完现在请求的内容后不要断开连接，不断开的话下次继续连接速度就很快了。可能还会有Cookies，Cookies保存了用户的登陆信息，一般保存的是用户的JSESSIONID，在每次向服务器发送请求的时候会重复发送给服务器。

在建立连接发送请求时每个服务端需要和客户端保持通信，有很多客户端都会和服务器进行通信。服务器为了识别是哪个客户端与它通信，就必须用一个标识记录客户端的信息。客户端首次访问服务器，服务端返回响应时通过附带一个记录的客户端信息的标识来返回给客户端，这个标识就是JSESSIONID，JSESSIONID就放在了客户端的Cookies里。当客户端再次向服务器发送请求时上就使用上次记录的Cookies里面的JSESSIONID，这样服务器就知道是哪个浏览器了。这样他们之间就能保持通信了。

### 4.服务器处理请求

服务器收到浏览器的请求以后），会解析这个请求（读请求头），然后生成一个响应头和具体响应内容。接着服务器会传回来一个响应头和一个响应，响应头告诉了浏览器一些必要的信息，例如重要的Status Code，2开头如200表示一切正常，3开头表示重定向，4开头是客户端错误，如404表示请求的资源不存在，5开头表示服务器端错误。响应就是具体的要请求的页面内容。
当客户请求某个资源时，HTTP服务器会用一个ServletRequest对象把客户的请求信息封 装，然后调用Servlet容器的service方法，Servlet容器拿到请求后，根据请求的URL 和Servlet的映射关系，找到相应的Servlet，如果Servlet还没有被加载，就用反射机制创 建这个Servlet，并调用Servlet的init方法来完成初始化，接着调用Servlet的service方法 来处理请求，把ServletResponse对象返回给HTTP服务器，HTTP服务器会把响应发送给 客户端.

### 5.浏览器解析渲染页面

（1）浏览器显示HTML

当服务器返回响应之后，浏览器读取关于这个响应的说明书（响应头），然后开始解析这个响应并在页面上显示出来。

浏览器打开一个网址的时候会慢慢加载这个页面，一部分一部分的显示，直到完全显示，知道最后的旋转进度条停止。因此在浏览器没有完整接受全部HTML文档时，它就已经开始显示这个页面了。

（2）浏览器向服务器发送请求获取嵌入在HTML中的对象

在浏览器显示HTML时，打开一个网页的过程中，主页（index）页面框架传送过来以后，浏览器还会因页面上的静态资源多次发起连接请求，需要获取嵌入在HTML中的其他地址的资源。这时，浏览器会发送一些请求来获取这些文件。这些内容也要一点点地请求过来，所以标签栏转啊转，内容刷啊刷，最后全部请求并加载好了就终于好了。

这时请求的内容是主页里面包含的一些资源，如图片，视频，css样式，JavaScript文件等等。

这在文件属于静态文件，首次访问会留在浏览器的缓存中，过期才会从服务器去取。缓存的内容通常不会保存很久，因为难保网站不会被改动。

静态的文件一般会从CDN中去取，CDN根据请求获取资源的时候可能还会用到负载均衡。

（3）浏览器发送异步（AJAX）请求

对于那些动态的请求，动态网页等就必须要从服务器获取了。对于静态的页面内容，浏览器通常会进行缓存，而对于动态的内容，浏览器通常不会进行缓存。对于这些动态请求，Nginx可能会专门设置一些服务器用来处理这些访问动态页面的请求。

### 6.关闭TCP连接

当数据完成请求到返回的过程之后，根据Connection的Keep-Alive属性可以选择是否断开TCP连接，HTTP/1.1一般支持同一个TCP多个请求，而不是1.0版本下的完成一次请求就发生断开。TCP的断开与连接不一样，断开可以分为主动关闭和被动关闭，需要经过4次握手。

当浏览器需要的全部数据都已经加载完毕，一个页面就显示完了。

## HTTP相关状态码

1×× : 请求处理中，请求已被接受，正在处理

返回的状态码和状态不一致的情况是有可能发生得 
比如Web应用程序内部错误，但仍然返回 200 OK

200 OK 请求正常处理完毕
204 No Content 请求成功处理，没有实体的主体返回
206 Partial Content 该状态码表示客户端进行了范围请求， 而服务器成功执行了这部分的GET 请求。 响应报文中包含由 Content-Range 指定范围的实体内容。
301 Moved Permanently 永久重定向，该状态码表示请求的资源已被分配了新的 URI， 以后应使用资源现在所指的 URI。 也就是说， 如果已经把资源对应的 URI保存为书签了， 这时应该按 Location 首部字段提示的 URI 重新保存。
302 Found 临时重定向，该状态码表示请求的资源已被分配了新的 URI， 希望用户（本次） 能使用新的 URI 访问。
303 See Other 临时重定向，该状态码表示由于请求对应的资源存在着另一个 URI， 应使用 GET方法定向获取请求的资源。
304 Not Modified 发送的附带条件请求未满足
307 Temporary Redirect 临时重定向，POST不会变成GET
400 Bad Request 请求报文语法错误或参数错误
401 Unauthorized 需要通过HTTP认证，或认证失败
403 Forbidden 请求资源被拒绝
404 Not Found 无法找到请求资源（服务器无理由拒绝）
500 Internal Server Error 服务器故障或Web应用故障
503 Service Unavailable 服务器超负载或停机维护
502  Bad Gateway   作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应
504 Gateway Time-out 网关超时，这个有时候Nginx会抛出的异常，主要原因是请求超时，比如你想导出下载某个文件，结果文件太大，就可能请求超时了。

## **forward 和 redirect 的区别**

#### forward（转发）：

就是我们的网址不会变，可能这个过程中服务器自己在内部进行了一些转发，但是我们不用关心我们要的资源是服务器去哪里找的。

是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器。浏览器根本不知道服务器发送的内容从哪里来的,因为这个跳转过程实在服务器实现的，并不是在客户端实现的所以客户端并不知道这个跳转动作，所以它的地址栏还是原来的地址.

#### **redirect（重定向）**：

**是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL.**

#### 总结一句话

转发是服务器行为，重定向是客户端行为。

## HTTP1.0和HTTP2.0的区别

### 多路复用

  HTTP2.0使用了多路复用的技术，能做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。

### 头部数据压缩

 在HTTP1.1中，HTTP请求和响应都是由状态行、请求/响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输UserAgent、Cookie这类不会频繁变动的内容，完全是一种浪费。

 HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。

###  服务器推送

    服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP1.1中这些资源每一个都必须明确地请求。这是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的。
    
       为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，在浏览器明确地请求之前，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。

## HTTP2.0

### Http协议各版本的对比

```
 超文本传输协议是分布式协作超媒体信息系统的应用协议。超文本传输协议是万维网数据通信的基础，在万维网中超文本文档包括到用户可以轻松访问的其他资源的超链接。
```

```
蒂姆·伯纳斯·李于1989年在欧洲核子研究中心发起了超文本传输协议的开发。早期的超文本传输协议征求意见(RFCs)的开发是由互联网工程任务组(IETF)和万维网联盟(W3C)共同努力的结果，其工作后来转移到IETF。
```

**万维网之父蒂姆·伯纳斯·李简介**

```
 Tim Berners-Lee是英国工程师和计算机科学家，最著名的是万维网的发明者。他是牛津大学计算机科学教授和麻省理工学院教授。
```

```
他于1989年3月12日提出了一种信息管理系统，然后在同年11月中旬通过Internet实现了超文本传输协议HTTP客户端和服务器之间的首次成功通信。
```

```
他是万维网联盟W3C的负责人，该联盟负责监督Web的持续发展，他还是万维网基金会的创始人，还是麻省理工学院计算机科学和人工智能实验室CSAIL的3Com创始人主席和高级研究员，他也是网络科学研究计划WSRI的主任和MIT集体智慧中心的顾问委员会成员，他也是开放数据研究所的创始人兼总裁，目前是社交网络MeWe的顾问。
```

```
2004年，伯纳斯·李因其开创性工作而被女王伊丽莎白二世封为爵士。在2009年4月，他当选为美国国家科学院外籍研究员，位列《时代》杂志的20世纪100位最重要人物名单被誉为“万维网发明者”获得了2016年图灵奖。
```



### **http各个版本的基本情况**

http协议经过20多年的演进出现过**0.9、1.0、1.1、2.0、3.0**五个主要版本

**A.Http0.9版本**
0.9是鼻祖版本，它的主要特点包括：

- **请求方法支持有限**
  只支持GET请求方式，不支持其他请求方式 因此客户端向服务端传输信息的量非常有限，也就是现在常用的Post请求无法使用
- **不支持请求头header**
  不能在请求中指定版本号，服务端只具有返回HTML字符串的能力
- **响应即关闭**
  服务端相响应之后，立即关闭TCP连接

**B.Http1.0版本**

1.0版本主要是对0.9版本的强化，效果也比较明显，主要特性和缺点包括：

- **丰富请求方法**
  请求方式新增了POST，DELETE，PUT，HEADER等方式，提高了客户端向服务端发送信息的量级
- **增加请求头和响应头**
  增添了请求头和响应头的概念，可以在通信中指定了HTTP协议版本号，以及其他header信息，使得C/S交互更加灵活方便
- **丰富数据传输内容**
  扩充了传输内容格式包括：**图片、音视频资源、二进制**等都可以进行传输，相比0.9的只能传输html内容让http的应用场景更多
- **链接复用性差**
  1.0版本中每个TCP连接只能发送一个请求，数据发送完毕连接就关闭，如果还要请求其他资源，就必须重新建立连接。TCP为了保证正确性和可靠性需要客户端和服务器三次握手和四次挥手，因此建立连接成本很高，基于拥塞控制开始时发送速率较慢，所以1.0版本的**性能并不理想**。
- **无状态无连接的弊端**
  1.0版本是**无状态且无连接**的，换句话说就是服务器不跟踪不记录请求过的状态，客户端每次请求都需要建立tcp连接不能复用，并且1.0规定在前一个请求响应到达之后下一个请求才能发送，如果前一个阻塞后面的请求就会被阻塞。 **丢包和乱序问题**和高成本的链接过程让复用和**队头阻塞**产生很多问题，所以**无连接无状态**是1.0版本的一个**弱肋**。

**C.Http1.1版本**
1.1版本在1.0版本发布后大约1年就推出了，是**对1.0版本的优化和完善**，1.1版本的主要特点包括：

- **增加长连接**
  新增Connection字段，可以设置keep-alive值保持连接不断开，即 TCP 连接默认不关闭，可以被多个请求复用，这也是1.1版本很重要的优化，但是在S端服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着，仍然存在队头阻塞问题。
- **管道化**
  在长连接的基础上，管道化可以不等第一个请求响应继续发送后面的请求，但响应的顺序还是按照请求的顺序返回，即在同一个TCP连接中，客户端可以同时发送多个请求，进一步改进了HTTP协议的传输效率。
- **更多的请求方法**
  增加了 PUT、PATCH、OPTIONS、DELETE 等请求方式。
- **host字段**
  Host字段用来指定服务器的域名，这样就可以将多种请求发往同一台服务器上的不同网站，提高了机器的复用，这个也是重要的优化

**D.Http2.0版本**
2.0版本是个里程碑式的版本，相比1.x版本有了非常多的优化去适应当前的网络场景，其中几个重要功能点包括：

- **二进制格式**
  1.x是文本协议，然而2.0是以二进制帧为基本单位，可以说是一个二进制协议，将所有传输的信息分割为消息和帧，并采用二进制格式的编码，一帧中包含数据和标识符，使得网络传输变得高效而灵活。
- **多路复用**
  这是一个非常重要的改进，1.x中建立多个连接的消耗以及效率都存在问题，2.0版本的多路复用多个请求共用一个连接，多个请求可以同时在一个TCP连接上并发，主要借助于二进制帧中的标识进行区分实现链路的复用。
- **头部压缩**
  2.0版本使用使用HPACK算法对头部header数据进行压缩，从而减少请求的大小提高效率，这个非常好理解，之前每次发送都要带相同的header，显得很冗余，2.0版本对头部信息进行增量更新有效减少了头部数据的传输。
- **服务端推送**
  这个功能有点意思，之前1.x版本服务端都是收到请求后被动执行，在2.0版本允许服务器主动向客户端发送资源，这样在客户端可以起到加速的作用。

###  Http2.0 详解

#### SPDY协议

要说2.0版本标准和新特性就必须提谷歌的**SPDY协议**，看一下百度百科:

```
 SPDY是Google开发的基于TCP的会话层协议，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验。SPDY并不是一种用于替代HTTP的协议，而是对HTTP协议的增强。
```

```
新协议的功能包括数据流的多路复用、请求优先级以及HTTP报头压缩。谷歌表示引入SPDY协议后，在实验室测试中页面加载速度比原先快64%。
```

随后SPDY协议得到**Chrome、Firefox**等大型浏览器的支持，在一些大型网站和小型网站种部署，这个高效的协议引起了**HTTP工作组**的注意，在**此基础上制定了官方Http2.0标准**。

之后几年SPDY和Http2.0继续演进相互促进，Http2.0让服务器、浏览器和网站开发者在新协议中获得更好的体验，很快被大众所认可。

#### 二进制分帧层

二进制编码机制使得通信可以在**单个TCP连接**上进行，该连接在整个对话期间一直处于活跃状态。

二进制协议将通信**数据分解为更小的帧**，数据帧充斥在C/S之间的双向数据流中，就像双向多车道的高速路，来往如织川流不息：

要理解二进制分帧层需要知道四个概念：

- **链接Link**
  就是指一条C/S之间的TCP链接，这是个基础的链路数据的高速公路
- **数据流Stream**
  已建立的TCP连接内的双向字节流，TCP链接中可以承载一条或多条消息
- **消息Message**
  消息属于一个数据流，消息就是逻辑请求或响应消息对应的完整的一系列帧，也就是帧组成了消息
- **帧Frame**
  帧是通信的最小单位，每个帧都包含帧头和消息体，标识出当前帧所属的数据流

再来看一下HeadersFrame头部帧的结构：从各个域可以看到长度、类型、标志位、流标识符、数据净荷等

```
https://httpwg.org/specs/rfc7540.html
```

**总之**2.0版本将通信数据分解为二进制编码帧进行交换，每个帧对应着特定数据流中的特定消息，所有帧和流都在一个TCP连接内复用，二进制分帧协议是2.0其他功能和性能优化的重要基础。

#### 多路复用

1.1版本中存在**队首阻塞问题**，因此如果客户端要发起多个并行请求来提升性能，必须使用**多个TCP连接**，这样就要承受**更大延时和建链拆链成本**，不能有效利用TCP链接。

由于2.0版本中使用新的二进制分帧协议突破了1.0的诸多限制，从根本上实现了真正的**请求和响应多路复用**。

客户端和服务器将交互数据分解为**相互独立的帧**，互不影响地**交错传输**，最后再在对端根据**帧头中的流标识符**把它们**重新组装**起来，从而实现了TCP链接的多路复用。

####  首部压缩

**A.Header冗余传输**

我们都知道http请求都有header部分，每个包都有并且相对于一条链接而言**大部分的包的header部分都是相同**的，这样的话每次传输相同的部分确实**非常浪费**。

```
现代网络中每个网页平均包含100多个http请求，每个请求头平均有300-500字节，总数据量达到几十KB以上，这样可能造成数据延时，尤其复杂*的WiFi环境或者蜂窝网络*，这样只能看到手机在转圈，但是这些请求头之间通常几乎没有变化，在本已经拥挤的链路中多次传输相同的数据部分确实不是高效做法。
```

```
 基于TCP设计的拥塞控制具有线增积减AIMD特性，如果发生丢包那么传输速率将大幅度下降，这样在拥挤的网络环境中大的包头意味着只能加剧拥塞控制造成的低速率传输。
```

**B.Http压缩和犯罪攻击**

在2.0版本的HPACK算法之前，http压缩使用gzip去压缩，后来提出的SPDY算法对Headers进行特殊设计，但是它依旧使用的是**DEFLATE算法**。

在后面的一些实际应用中发现**DEFLATE和SPDY都有被攻击的危险**，因为DEFLATE算法使用后向**字符串匹配和动态Huffman编码**，攻击者可以控制部分请求头部通过修改请求部分然后看压缩之后大小改变多少，如果变小了攻击者就知道注入的文本和请求中的某些内容有重复。

这个过程有点像**俄罗斯方块的消除过程**，这样经过一段时间的尝试数据内容就可能被全部搞清楚，由于这种风险的存在才研发出更安全的压缩算法。

**C.HPACK算法**

2.0版本中HPACK算法在C/S中使用**首部表**来存储之前发送的键值对，对于相同的数据通信期间几乎不会改变的通用键值对只需发送一次即可。

极端情况如果请求头每次没有变化，那么传输中则不包含首部，也就是首部开销就是**零字节**。如果首部键值对发生变化了，也只需要发送变化的数据，并且将**新增或修改的首部帧会被追加到首部表**，首部表在链接存活期始终存在, 并且由客户端和服务器**共同更新和维护**。

**简单说就是客户端和服务端共同维护了一个key-value的结构，发生变化时则更新传输，否则就不传输**，这样相当于**首次全量传输之后增量更新传输**即可，这个思想在日常开发中也非常普遍，不用想的太复杂。

####  服务端推送

服务端推送是2.0版本新增的一个强大功能，和一般的**一问一答**式的C/S交互不同，**推送式交互中服务器可以对客户端的一个请求发送多个响应**，除了对最初请求的响应外还向客户端推送额外资源，无需客户端明确地请求也可以推送。

**举个栗子：**
想象一下你去餐厅吃饭，服务好的快餐厅在你点好一份牛肉面之后，还会给你送上餐巾纸、筷子、勺子甚至调料等，这样主动式的服务，节约了客人的时间并且提高了用餐体验。

在实际的C/S交互中这种**主动推送额外资源**的方法很有效，因为几乎每个网络应用都会包含多种资源，客户端需要全部逐个获取它们，此时如果让服务器提前推送这些资源，从而可以**有效减少额外的延迟时****间**，因为服务器可以知道客户端下一步要请求什么资源。

## TCP如何保证可靠性传输

TCP协议保证数据传输可靠性的方式主要有：

- 校验和
- 序列号
- 确认应答
- 超时重传
- 连接管理
- 流量控制
- 拥塞控制

### 校验和

计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。
发送方：在发送数据之前计算检验和，并进行校验和的填充。
接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。

tcp报文中，在tcp的首部之前，多了一个12字节的伪首部，伪首部中4个字节保存源ip信息，4个字节目的ip信息，一个字节的保留位置，一个字节保存协议号（6代表tcp，17代表udp），2个字节保存tcp的真正首部和数据。

根据伪首部的信息通过位运算，得到了一个校验和数据，保存在tcp保温的checksum字段。接收端接收到tcp报文后，也按照特定算法计算出一个校验和，与checksum保存的校验和比较，如果相同，则完成此报文的接收。如果不相同，则丢弃此报文，让发送端重传。

tcp校验和与ip校验和的区别是：TCP和UDP检验和覆盖首部和数据，而IP首部中的检验和只覆盖IP的首部，不覆盖IP数据报中的任何数据。

tcp校验和和udp校验和的区别是：TCP的检验和是必需的，而UDP的检验和是可选的




注意：如果接收方比对校验和与发送方不一致，那么数据一定传输有误。但是如果接收方比对校验和与发送方一致，**数据不一定传输成功。**



### **确认应答与序列号**

序列号：TCP传输时将每个字节的数据都进行了编号，这就是序列号。
确认应答：TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文。这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。



序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一。



### **超时重传**

在进行TCP传输时，由于确认应答与序列号机制，也就是说**发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功**。如果发送方发送完数据后，迟迟没有等到接收方的ACK报文，这该怎么办呢？而没有收到ACK报文的原因可能是什么呢？

首先，发送方没有介绍到响应的ACK报文**原因可能有两点**：

**数据在传输过程中由于网络原因等直接全体丢包，接收方根本没有接收到。**
接收方接收到了响应的数据，但是发送的ACK报文响应却由于网络原因丢包了。
TCP在解决这个问题的时候引入了一个新的机制，叫做超时重传机制。简单理解就是**发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送**。如果是刚才第一个原因，接收方收到二次重发的数据后，便进行ACK应答。如果是第二个原因，**接收方发现接收的数据已存在**（判断存在的根据就是序列号，所以上面说序列号还有去除重复数据的作用），**那么直接丢弃，仍旧发送ACK应答**。

那么发送方发送完毕后等待的时间是多少呢？如果这个**等待的时间过长，那么会影响TCP传输的整体效率**，如果等待时间过短，又会导致频繁的发送重复的包。如何权衡？

由于TCP传输时保证能够在任何环境下都有一个高性能的通信，因此这个最大超时时间（也就是等待的时间）是动态计算的。

在L**inux中（BSD Unix和Windows下也是这样）超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。重发一次后，仍未响应，那么等待2*500ms的时间后，再次重传。等待4*500ms的时间继续重传。以一个指数的形式增长。累计到一定的重传次数，TCP就认为网络或者对端出现异常，强制关闭连接。**

### 连接管理

连接管理就是三次握手与四次挥手的过程，在前面详细讲过这个过程，这里不再赘述。保证可靠的连接，是保证可靠性的前提。



### 流量控制（滑动窗口）

接收端在接收到数据后，对其进行处理。**如果发送端的发送速度太快，导致接收端的接收缓冲区很快的填充满了**。此时如果发送端**仍旧发送数据**，那么接下来发送的数据都会**丢包**，继而**导致丢包**的一系列连锁反应，超时重传呀什么的。而**TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。**

在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道，**窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小**。这个数字越大，证明接收端接收缓冲区的剩余空间越大，网络的吞吐量越大。**接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入**，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。

16位的窗口大小最大能表示65535个字节（64K），但是TCP的窗口大小最大并不是64K。在TCP首部中40个字节的选项中还包含了一个窗口扩大因子M，实际的窗口大小就是16为窗口字段的值左移M位。每移一位，扩大两倍。



### 拥塞控制

TCP传输的过程中，发送端开始发送数据的时候，**如果刚开始就发送大量的数据，那么就可能造成一些问题**。网络可能在**开始的时候就很拥堵**，如果给网络中在扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。

所以TCP引入了慢启动的机制，在开始发送数据时，**先发送少量的数据探路**。探清当前的网络状态如何，再决定多大的速度进行传输。这时候就引入一个叫做**拥塞窗口**的概念。发送刚开始定义拥塞窗口为 1，每次收到ACK应答，拥塞窗口加 1。在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小比对，取较小的值作为实际发送的窗口。

拥塞窗口的增长是指数级别的。慢启动的机制只是说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。为了控制拥塞窗口的增长，不能使拥塞窗口单纯的加倍，设置一个拥塞窗口的阈值，当拥塞窗口大小超过阈值时，不能再按照指数来增长，而是线性的增长。在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，发生超时重传时，慢启动的阈值会为原来的一半（这里的原来指的是发生网络拥塞时拥塞窗口的大小），同时拥塞窗口重置为 1。
拥塞控制是TCP在传输时尽可能快的将数据传输，并且避免拥塞造成的一系列问题。是可靠性的保证，同时也是维护了传输的高效性。



## 三次握手

三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。

刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态。
进行三次握手：

第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN。此时客户端处于 SYN_SENT 状态。

首部的同步位SYN=1，初始序号seq=x，SYN=1的报文段不能携带数据，但要消耗掉一个序号。

第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_RCVD 的状态。

在确认报文段中SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y。

第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。

确认报文段ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。

发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN的另一端执行被动打开（passive open）。



### 为什么需要三次握手，两次不行吗？

弄清这个问题，我们需要先弄明白三次握手的目的是什么，能不能只用两次握手来达到同样的目的。

第一次握手：客户端发送网络包，服务端收到了。
这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
第二次握手：服务端发包，客户端收到了。
这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
第三次握手：客户端发包，服务端收到了。
这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。
因此，需要三次握手才能确认双方的接收与发送能力是否正常。

试想如果是用两次握手，则会出现下面这种情况：


```
如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

```

### 什么是半连接队列？

服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。

当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

这里在补充一点关于SYN-ACK 重传次数的问题：
服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传。如果重传次数超过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。
注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s，2s，4s，8s…

### ISN(Initial Sequence Number)是固定的吗？

当一端为建立连接而发送它的SYN时，它为连接选择一个初始序号。ISN随时间而变化，因此每个连接都将具有不同的ISN。ISN可以看作是一个32比特的计数器，每4ms加1 。这样选择序号的目的在于防止在网络中被延迟的分组在以后又被传送，而导致某个连接的一方对它做错误的解释。

**三次握手的其中一个重要功能是客户端和服务端交换 ISN(Initial Sequence Number)，以便让对方知道接下来接收数据的时候如何按序列号组装数据。如果 ISN 是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。**

### 三次握手过程中可以携带数据吗？

其实第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手不可以携带数据

为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。

也就是说，第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。

###  SYN攻击是什么？

服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstat 命令来检测 SYN 攻击。

```
netstat -n -p TCP | grep SYN_RECV
```

常见的防御 SYN 攻击的方法有如下几种：

- 缩短超时（SYN Timeout）时间
- 增加最大半连接数
- 过滤网关防护
- SYN cookies技术

## 半\全连接队列

 ![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/TmEUgtj9EK6.7V8ajmQrEMzUeEtXjLFxlZ.bnZXZvxFguRW7S594jGghmpXTDQtQy4uByJYG2ycvmXl7jKP7t0ed8AsF0Og0c0FtKWbkSMI!/b&bo=NwRfAgAAAAACN30!&rf=viewer_4) 

上面这个动图，是我们平时客户端和服务端建立连接时的代码流程。

对应的是下面一段简化过的服务端伪代码。

```c
int main()
{
    /*Step 1: 创建服务器端监听socket描述符listen_fd*/    
    listen_fd = socket(AF_INET, SOCK_STREAM, 0);

    /*Step 2: bind绑定服务器端的IP和端口，所有客户端都向这个IP和端口发送和请求数据*/    
    bind(listen_fd, xxx);

    /*Step 3: 服务端开启监听*/    
    listen(listen_fd, 128);

    /*Step 4: 服务器等待客户端的链接，返回值cfd为客户端的socket描述符*/    
    cfd = accept(listen_fd, xxx);

      /*Step 5: 读取客户端发来的数据*/
      n = read(cfd, buf, sizeof(buf));
}
```

需要注意的是，在执行`listen()`方法之后还会执行一个`accept()`方法。

**一般情况**下，如果启动服务器，会发现最后程序会**阻塞在**`accept()`里。

此时服务端就算ok了，就等客户端了。

那么，再看下简化过的客户端伪代码。

```c
int main()
{
    /*Step 1: 创建客户端端socket描述符cfd*/    
    cfd = socket(AF_INET, SOCK_STREAM, 0);

    /*Step 2: connect方法,对服务器端的IP和端口号发起连接*/    
    ret = connect(cfd, xxxx);

    /*Step 4: 向服务器端写数据*/
    write(cfd, buf, strlen(buf));
}
```

客户端比较简单，创建好`socket`之后，直接就发起`connect`方法。

此时回到服务端，会发现**之前一直阻塞的accept方法，返回结果了**。

这就算两端成功建立好了一条连接。之后就可以愉快的进行读写操作了。

那么，我们今天的问题是，**如果没有这个accept方法，TCP连接还能建立起来吗？**

其实只要在执行`accept()` 之前执行一个 `sleep(20)`，然后立刻执行客户端相关的方法，同时抓个包，就能得出结论。

![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/bqQfVz5yrrGYSXMvKr.cqVNjQrgcv90WwfeLBdpEmFMVWpU7I.0Wj.cmrgyEFpsFDImhilUEa1TBZe*eZ0IH6pkyCCS1D9ZS6wArr0xCFN8!/mnull&bo=4APwAAAAAAADBzE!&rf=photolist&t=5) 

从抓包结果看来，**就算不执行accept()方法，三次握手照常进行，并顺利建立连接。**

更骚气的是，**在服务端执行accept()前，如果客户端发送消息给服务端，服务端是能够正常回复ack确认包的。**

并且，`sleep(20)`结束后，服务端正常执行`accept()`，客户端前面发送的消息，还是能正常收到的。

通过这个现象，我们可以多想想为什么。顺便好好了解下三次握手的细节。

### 三次握手的细节分析

 ![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/bqQfVz5yrrGYSXMvKr.cqVCvrJALxgctxFEwrhlOW5eJTLGIBzziqt29HekS7z9*CZ58UIt*RaFraYGK6Px4rz2mHRHJS4HNU4J*4r5jHGY!/mnull&bo=OATeAwAAAAADB8M!&rf=photolist&t=5) 

服务端代码，对socket执行bind方法可以绑定监听端口，然后执行`listen方法`后，就会进入监听（`LISTEN`）状态。**内核会为每一个处于`LISTEN`状态的`socket` 分配两个队列**，分别叫**半连接队列和全连接队列**。

 ![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/TmEUgtj9EK6.7V8ajmQrEPrRjYfI17KBrGpeCb1N0X41rCXYMAF*LEATancQ3r687YhHmjknysUttcU4wkmLC*gp.UtwcrZJ.RsokuEljrw!/b&bo=OATCAQAAAAADF80!&rf=viewer_4) 

#### 半连接队列、全连接队列是什么

 ![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/bqQfVz5yrrGYSXMvKr.cqQQyOstotm2v8ixfp9C1qdowsF4LpNWCST5.RbMyBXl9ysH8lywDISrZ6uwNKhyvIqpo00erU.y.JU9q9.ROO4g!/mnull&bo=OAQgAwAAAAADBz0!&rf=photolist&t=5) 

- **半连接队列（SYN队列）**，服务端收到**第一次握手**后，会将`sock`加入到这个队列中，队列内的`sock`都处于`SYN_RECV` 状态。
- **全连接队列（ACCEPT队列）**，在服务端收到**第三次握手**后，会将半连接队列的`sock`取出，放到全连接队列中。队列里的`sock`都处于 `ESTABLISHED`状态。这里面的连接，就**等着服务端执行accept()后被取出了。**

看到这里，文章开头的问题就有了答案，**建立连接的过程中根本不需要`accept()` 参与**， **执行accept()只是为了从全连接队列里取出一条连接。**

我们把话题再重新回到这两个队列上。

虽然都叫**队列**，但其实**全连接队列（icsk_accept_queue）是个链表**，而**半连接队列（syn_table）是个哈希表**。

 ![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/bqQfVz5yrrGYSXMvKr.cqbrBDRqnSE7Q3YP6lediQ3ld1fEoUHgEaoyYRd9Gdocs*ucsjo0jx53CNyX2QDwvXzgfEgAbYTSQMrsdDrisjU4!/mnull&bo=OAQcAgAAAAADBwA!&rf=photolist&t=5) 

### 为什么半连接队列要设计成哈希表

先对比下**全连接里队列**，他本质是个链表，因为也是线性结构，说它是个队列也没毛病。它里面放的都是已经建立完成的连接，这些连接正等待被取走。**而服务端取走连接的过程中，并不关心具体是哪个连接，只要是个连接就行，所以直接从队列头取就行了。这个过程算法复杂度为`O(1)`。**

而**半连接队列**却不太一样，因为队列里的都是不完整的连接，嗷嗷等待着第三次握手的到来。那么现在有一个第三次握手来了，则需要从队列里把相应IP端口的连接取出，**如果半连接队列还是个链表，那我们就需要依次遍历，才能拿到我们想要的那个连接，算法复杂度就是O(n)。**

而如果将半连接队列设计成哈希表，那么查找半连接的算法复杂度就回到`O(1)`了。

因此出于效率考虑，全连接队列被设计成链表，而半连接队列被设计为哈希表。

### 怎么观察两个队列的大小

##### 查看全连接队列

```
# ss -lnt
State      Recv-Q Send-Q     Local Address:Port           Peer Address:Port
LISTEN     0      128        127.0.0.1:46269              *:*              
```

通过`ss -lnt`命令，可以看到全连接队列的大小，其中`Send-Q`是指全连接队列的最大值，可以看到我这上面的最大值是`128`；`Recv-Q`是指当前的全连接队列的使用值，我这边用了`0`个，也就是全连接队列里为空，连接都被取出来了。

当上面`Send-Q`和`Recv-Q`数值很接近的时候，那么全连接队列可能已经满了。可以通过下面的命令查看是否发生过队列**溢出**。

```
# netstat -s | grep overflowed
    4343 times the listen queue of a socket overflowed
```

上面说明发生过`4343次`全连接队列溢出的情况。这个查看到的是**历史发生过的次数**。

如果配合使用`watch -d` 命令，可以自动每`2s`间隔执行相同命令，还能高亮显示变化的数字部分，如果溢出的数字不断变多，说明**正在发生**溢出的行为。

```
# watch -d 'netstat -s | grep overflowed'
Every 2.0s: netstat -s | grep overflowed                                Fri Sep 17 09:00:45 2021

    4343 times the listen queue of a socket overflowed
```

##### 查看半连接队列

半连接队列没有命令可以直接查看到，但因为半连接队列里，放的都是`SYN_RECV` 状态的连接，那可以通过统计处于这个状态的连接的数量，间接获得半连接队列的长度。

```
# netstat -nt | grep -i '127.0.0.1:8080' | grep -i 'SYN_RECV' | wc -l
0
```

注意半连接队列和全连接队列都是挂在某个`Listen socket`上的，我这里用的是`127.0.0.1:8080`，大家可以替换成自己想要查看的**IP端口**。

可以看到我的机器上的半连接队列长度为`0`，这个很正常，**正经连接谁会没事老待在半连接队列里。**

当队列里的半连接不断增多，最终也是会发生溢出，可以通过下面的命令查看。

```
# netstat -s | grep -i "SYNs to LISTEN sockets dropped" 
    26395 SYNs to LISTEN sockets dropped
```

可以看到，我的机器上一共发生了`26395`次半连接队列溢出。同样建议配合`watch -d` 命令使用。

```
# watch -d 'netstat -s | grep -i "SYNs to LISTEN sockets dropped"'
Every 2.0s: netstat -s | grep -i "SYNs to LISTEN sockets dropped"       Fri Sep 17 08:36:38 2021

    26395 SYNs to LISTEN sockets dropped
```

### 全连接队列满了会怎么样？

如果队列满了，服务端还收到客户端的第三次握手ACK，默认当然会丢弃这个ACK。

但除了丢弃之外，还有一些附带行为，这会受 `tcp_abort_on_overflow` 参数的影响。

```
# cat /proc/sys/net/ipv4/tcp_abort_on_overflow
0
```

- `tcp_abort_on_overflow`设置为 0，全连接队列满了之后，会丢弃这个第三次握手ACK包，并且开启定时器，重传第二次握手的SYN+ACK，如果重传超过一定限制次数，还会把对应的**半连接队列里的连接**给删掉。

 <img src="http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/bqQfVz5yrrGYSXMvKr.cqQ74tw7cXlRAXrqU5aw0wDShd2PyrdCpGlxzi31SH9YU8YK83nxYWGr.s3E3josPflagwW8vuYuAPxM9Fl2ucmA!/mnull&amp;bo=OAQrBDgEKwQDByI!&amp;rf=photolist&amp;t=5" alt="img" style="zoom:200%;" /> 

- `tcp_abort_on_overflow`设置为 1，全连接队列满了之后，就直接发RST给客户端，效果上看就是连接断了。

这个现象是不是很熟悉，服务端**端口未监听**时，客户端尝试去连接，服务端也会回一个RST。**这两个情况长一样，所以客户端这时候收到RST之后，其实无法区分到底是****端口未监听**，还是**全连接队列满了**。

![image-20211124204344680](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124204344680.png)

### 半连接队列要是满了会怎么样

**一般是丢弃**，但这个行为可以通过 `tcp_syncookies` 参数去控制。但比起这个，更重要的是先了解下半连接队列为什么会被打满。

首先我们需要明白，一般情况下，半连接的"生存"时间其实很短，只有在第一次和第三次握手间，如果半连接都满了，说明服务端疯狂收到第一次握手请求，如果是线上游戏应用，能有这么多请求进来，那说明你可能要富了。但现实往往比较骨感，你可能遇到了**SYN Flood攻击**。

所谓**SYN Flood攻击**，可以简单理解为，攻击方模拟客户端疯狂发第一次握手请求过来，在服务端憨憨地回复第二次握手过去之后，客户端死活不发第三次握手过来，这样做，可以把服务端半连接队列打满，从而导致正常连接不能正常进来。



那这种情况怎么处理？有没有一种方法可以**绕过半连接队列**？

有，上面提到的`tcp_syncookies`派上用场了。

```
# cat /proc/sys/net/ipv4/tcp_syncookies
1
```

当它被设置为1的时候，客户端发来**第一次握手**SYN时，服务端**不会将其放入半连接队列中**，而是直接生成一个`cookies`，这个`cookies`会跟着**第二次握手**，发回客户端。客户端在发**第三次握手**的时候带上这个`cookies`，服务端验证到它就是当初发出去的那个，就会建立连接并放入到全连接队列中。可以看出整个过程不再需要半连接队列的参与。



##### 会有一个cookies队列吗

生成是`cookies`，保存在哪呢？**是不是会有一个队列保存这些cookies？**

我们可以反过来想一下，如果有`cookies`队列，那它会跟半连接队列一样，到头来，还是会被**SYN Flood 攻击**打满。

实际上`cookies`并不会有一个专门的队列保存，它是通过**通信双方的IP地址端口、时间戳、MSS**等信息进行**实时计算**的，保存在**TCP报头**的`seq`里。



当服务端收到客户端发来的第三次握手包时，会通过seq还原出**通信双方的IP地址端口、时间戳、MSS**，验证通过则建立连接。

##### cookies方案为什么不直接取代半连接队列？

目前看下来`syn cookies`方案省下了半连接队列所需要的队列内存，还能解决 **SYN Flood攻击**，那为什么不直接取代半连接队列？

凡事皆有利弊，`cookies`方案虽然能防 **SYN Flood攻击**，但是也有一些问题。**因为服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息。**

**另外，编码解码`cookies`，都是比较耗CPU的，**利用这一点，如果此时攻击者构造大量的**第三次握手包（ACK包）**，同时带上各种**瞎编的`cookies`信息**，服务端收到`ACK包`后**以为是正经cookies**，憨憨地跑去解码（**耗CPU**），最后发现不是正经数据包后才丢弃。

这种通过构造大量`ACK包`去消耗服务端资源的攻击，叫**ACK攻击**，受到攻击的服务器可能会因为**CPU资源耗尽**导致没能响应正经请求。

### 没有listen，为什么还能建立连接

那既然没有`accept`方法能建立连接，那是不是没有`listen`方法，也能建立连接？是的，之前写的一篇文章提到过客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有listen，就能建立连接。**

当时文章最后也留了个疑问，**没有listen，为什么还能建立连接？**

我们知道执行`listen`方法时，会创建半连接队列和全连接队列。

三次握手的过程中会在这两个队列中暂存连接信息。

所以形成连接，前提是你得**有个地方存放着**，方便握手的时候能根据IP端口等信息找到socket信息。



**那么客户端会有半连接队列吗？**

**显然没有**，因为客户端没有执行`listen`，因为半连接队列和全连接队列都是在执行`listen`方法时，内核自动创建的。

但内核还有个**全局hash表**，可以用于存放`sock`连接的信息。这个全局`hash`表其实还细分为`ehash，bhash和listen_hash`等，但因为过于细节，大家理解成有一个**全局hash**就够了，

**在TCP自连接的情况中，客户端在`connect`方法时，最后会将自己的连接信息放入到这个全局hash表中**，然后将信息发出，消息在经过回环地址重新回到TCP传输层的时候，**就会根据IP端口信息**，再一次从这个**全局hash**中取出信息。于是握手包一来一回，最后成功建立连接。

TCP同时打开的情况也类似，只不过从一个客户端变成了两个客户端而已。



## DDOS攻击

### DDOS简介

DDOS又称为**分布式拒绝服务**，全称是Distributed Denial of Service。DDOS本是**利用合理的请求造成资源过载**，**导致服务不可用**，从而造成服务器拒绝正常流量服务。就如酒店里的房间是有固定的数量的，比如一个酒店有50个房间，当50个房间都住满人之后，再有新的用户想住进来，就必须要等之前入住的用户先出去。如果入住的用户一直不出去，那么酒店就无法迎接新的用户，导致酒店负荷过载，这种情况就是“拒绝服务”。如果想继续提供资源，那么酒店应该提升自己的资源量，服务器也是同样的道理。

### 拒绝服务攻击的基本概念

**拒绝服务：**拒绝服务是指**应用系统无法正常对外提供服务的状态**，如网络阻塞、系统宕机、响应缓慢等都属于拒绝服务的表现。

**拒绝服务攻击（DOS）**：拒绝服务攻击（Denial of Service Attack）是一种**通过各种技术手段导致目标系统进入拒绝服务状态的攻击**，常见手段包括利用漏洞、消耗应用系统性能和消耗应用系统带宽。

**分布式拒绝服务攻击（DDOS）**：分布式拒绝服务攻击（Distributed Denial of Service Attack）是拒绝服务攻击的高级手段，利用分布全球的僵尸网络发动攻击，能够产生大规模的拒绝服务攻击。



### DDOS攻击分类

（1）漏洞型（基于特定漏洞进行攻击）：只对具备特定漏洞的目标有效,通常发送特定数据包或少量的数据包即可达到攻击效果。

（2）业务型（消耗业务系统性能额为主）：与业务类型高度相关，需要根据业务系统的应用类型采取对应的攻击手段才能达到效果，通常业务型攻击实现效果需要的流量远低于流量型。

（3）流量型（消耗带宽资源为主）：主要以消耗目标业务系统的带宽资源为攻击手段，通常会导致网络阻塞，从而影响正常业务。

### SYN Flood攻击

在正常的情况下，TCP三次握手过程如下



客户端向服务器端发送一个**SYN请求包**，包含客户端使用的**端口号和初始序列号x**。

服务器端收到客户端发送过来的SYN请求包后，知道客户端想要建立连接，于是向客户端发送一个SYN请求包和ACK回应包，包含确认号x+1和服务器端的初始序列号y。

客户端收到服务器端返回的SYN请求包和ACK回应包后，向服务器端返回一个确认号y+1和序号x+1的ACK请求包，三次握手完成，TCP连接建立成功。

### SYN Flood攻击原理：

首先是客户端发送一个**SYN请求包给服务器端**，服务器端接受后会发送一个**SYN+ACK包**回应客户端，最后客户端会返回一个ACK包给服务器端来实现一次完整的TCP连接。**Syn flood攻击就是让客户端不返回最后的ACK包**，这就**形成了半开连接**，TCP半开连接是指发送或者接受了TCP连接请求,等待对方应答的状态,半开连接状态需要占用系统资源以等待对方应答，半开连接数达到上限，无法建立新的连接，从而造成拒绝服务攻击。

### UDP Flood攻击原理：

由于UDP属于**无连接协议，消耗的系统资源较少**，相同条件下容易产生更高的流量，是流量型攻击的主要手段。当受害系统**接收到一个UDP数据包**的时候，它会确定目的端口正在等待中的应用程序。当它**发现该端口中并不存在正在等待的应用程序**，它就会**产生一个目的地址无法连接的ICMP数据包发送给该伪造的源地址**。如果向受害者计算机端口发送了足够多的UDP数据包的时候，系统就会造成拒绝服务攻击，因此，UDP FLOOD成为了流量型拒绝服务攻击的主要手段。

### ICMP Flood攻击原理：

**当 ICMP ping 产生的大量回应请求超出了系统的最大限度**，以至于系统耗费所有资源来进行响应直至再也无法处理有效的网络信息流，但是**由于ICMP协议报文被丢弃不影响大多数系统运行**，所以容易被防护。



## 防火墙

### 为什么需要防火墙

互联网在加速全球信息化进程的同时，也对世界范围内的信息安全提出了严峻的挑战。互联网的开放性与自由性给人类获取与发布信息带来了巨大便利，可这同时也是互联网信息易被污染、入侵与破坏的主要原因，这些损害主要来自于以下多个方面：

❶ **互联网信任所有的接入主机**

**互联网的开放性允许全球任何一台网络设备访问互联网而不会去检测该设备的可靠性**，也就是说如果接入互联网的**所有主机中存在一台安全性**、可靠性薄弱的设备，只要攻破这台主机，那么任何**有危害的数据或病毒都可以通过该主机进入互联网**，殃及更多的互联网设备，可以给全球企业和个人带来无法估量的损失，造成不可预料的灾难。

❷ **不完善的各种协议服务**

当今互联网中使用的所有服务，如Telnet服务、DNS服务、FTP服务、Web服务、ActiveX等都是存在安全漏洞的，我们经常为计算机打的补丁就包含修复这些服务的功能。**这些服务的任何漏洞都是可以成为互联网主机被攻击、破坏的突破口！**

❸ **TCP/IP协议的安全隐患**

TCP/IP协议是Internet中任意两台主机进行通信时必须遵循的国际通用信息规范，但由于TCP/IP协议是完全公开的，并不是一套安全性完善的信息规则，进而成为了不法分子实施网络攻击的重点目标之一。**TCP/IP协议的安全性问题主要有以下几点：**

> TCP/IP协议重在建立网络连对连接安全性做足考虑

> TCP/IP协议是基于IP地址的，而基于地址的协议本身就存在各种安全性问题

> 互联网中的主机通信只认IP报文，而报文可以被不法分子截获或者修改，这就无法保证所有的互联网主机都是来自于可信任的网络环境，大大降低了不法分子进行网络攻击的难度

由于所有的应用层计算机程序都是通过TCP连接进行数据传输的，只要TCP的安全漏洞被利用，攻击者直接可以远程操控目标主机，达到污染/盗取数据，截获密码、破坏计算机等目的，所以TCP/IP协议并不能保证网络的绝对安全。

在遇到上述这些问题时，追查根源是非常困难的，因为**互联网信任接入的每一台设备，该设备可以来自任何可接入因特网的地方，而且可以使用任何一种服务的漏洞或者TCP/IP协议的漏洞。**



既然如此，想要通过源头来解决目标主机被破坏的问题几乎没有可能，因为要防止所有类型的互联网攻击其工作量是做不到的，但反过来，只控制进入目标主机的互联网数据是可行的，**这就要求有一种网络安全解决方案，能够对安全网络环境与不安全网络环境之间的数据访问进行控制，而要达到此目的，最基本的方案就是防火墙技术！**

#### 防火墙的真面目

> 国电话电报公司（AT&T）的工程师定义了防火墙的具体内容：
>
> ◆ 所有内网与外网的数据交互都必须经过防火墙
>
> ◆ 所有的内网访问通信必须经过防火墙授权
>
> ◆ 整个内网系统具有很强的可靠性

从定义来看，**防火墙是一个可以控制网络数据进出内外网的“东西”，不仅能够检查网络数据，而且具有保障内网不受外部不安全因素破坏的能力**，所以防火墙在功能上，是一个集隔离、审查于一体的器件；在实现上，防火墙是由一组位于特殊网络位置上的硬件设备（路由器、主机等）组成的主机或路由器系统。

#### 理想的防火墙结构

在介绍防火墙结构之前，我们首先要清楚三个概念：

- **内网——又称内部网络区域，指企业内部网络或一部分内部网络**
- **外网——又称外部网络区域，指因特网或非内部区域网络，不属于互联网信任的网络环境**
- **边界网络——内外网都可以访问的子网**
- **过滤路由器——在普通路由器中设置相关的过滤功能形成的最简单的防火墙**
- **代理服务器——充当内网DNS**、**内网与外网通信的网关，可提供各种信息服务(mail、ftp服务等)功能**



根据上图可以看出，理想型防火墙**将一个主机的多种服务功能（WWW/FTP/MAIL等）分散至多个单独的从主机进行分开管理**。在理想型防火墙中一共有三道安全防线，**第一道防线**就是**过滤路由器**，能够进行IP分组数据包的过滤；**第二道防线**就是分散在边界网络中的单服务主机（图中为代理服务器），由于只提供一种服务，一方面使得边界网络中的主机更易于配置，另一方面增加了内网被攻破的难度；**第三道防线**就是内部路由器，内网最后的安全防护手段。

**其实，当今的商用防火墙已经将上述功能全部集成为单件产品，只需要进行配置就能够实现上述理想结构中的相似功能，如华为的一款防火墙产品：**

#### 如何使用window防火墙阻断软件联网

我们在使用计算机进行学习、工作的过程中经常会遇到这样一个问题：**因各种原因想要禁止某个软件联网，却不知怎么办：**

- **比如被破解的软件后台自动更新导致破解失效**
- **比如有些不法软件自动下载安装其他垃圾软件**
- **比如某些恶业软件经常弹窗广告**
- **......**

遇到上述问题时，我们就**可以使用window系统自带的防火墙来禁止这些软件联网进而避免各种问题的发生。

##  四次挥手

建立一个连接需要三次握手，而终止一个连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。

TCP 连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务端均可主动发起挥手动作。

刚开始双方都处于ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：

第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状态。
即发出连接释放报文段（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。
第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。
即服务端收到连接释放报文段后即发出确认报文段（ACK=1，确认号ack=u+1，序号seq=v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。
第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。
即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。
第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。
即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。

收到一个FIN只意味着在这一方向上没有数据流动。**客户端执行主动关闭并进入TIME_WAIT是正常的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。**





### 挥手为什么需要四次？

因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

###  2MSL等待状态

TIME_WAIT状态也成为2MSL等待状态。每个具体TCP实现必须选择一个报文段最大生存时间MSL（Maximum Segment Lifetime），它是任何报文段被丢弃前在网络内的最长时间。这个时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段。

对一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在TIME_WAIT状态停留的时间为2倍的MSL。这样可让TCP再次发送最后的ACK以防这个ACK丢失（另一端超时并重发最后的FIN）。

这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和端口号，服务器的IP地址和端口号）不能再被使用。这个连接只能在2MSL结束后才能再被使用。

###  四次挥手释放连接时，等待2MSL的意义?

```
MSL是Maximum Segment Lifetime的英文缩写，可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。
```

为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

两个理由：
1:保证客户端发送的最后一个ACK报文段能够到达服务端。

这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。

2:防止“已失效的连接请求报文段”出现在本连接中。

客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

###  为什么TIME_WAIT状态需要经过2MSL才能返回到CLOSE状态？

理论上，四个报文都发送完毕，就可以直接进入CLOSE状态了，但是可能网络是不可靠的，有可能最后一个ACK丢失。所以**TIME_WAIT状态就是用来重发可能丢失的ACK报文**。

## TCP的拥塞控制

在某段时间，若**对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏**，这种情况就叫做**网络拥塞**。

在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。

若**出现拥塞而不进行控制**，整个网络的**吞吐量将随输入负荷的增大而下降**。

 ![img](https://img-blog.csdnimg.cn/20190731190238241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70) 

当输入的负载到达一定程度 吞吐量不会增加，即一部分网络资源会丢失掉，网络的吞吐量维持在其所能控制的最大值，转发节点的缓存不够大这造成分组的丢失是拥塞的征兆。
**TCP的四种拥塞控制算法**
1.慢开始
2.拥塞控制
3.快重传
4.快恢复

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731155254165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70) 

示例如下：
传输轮次：发送方给接收方发送数据报文段后，接收方给发送方发回相应的确认报文段，一个传输轮次所经历的时间就是往返时间RTT(RTT并非是恒定的数值），使用传输轮次是为了强调，把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个报文段的确认，拥塞窗口cwnd会随着网络拥塞程度以及所使用的拥塞控制算法动态变化。

在tcp双方建立逻辑链接关系时， 拥塞窗口cwnd的值被设置为1，还需设置慢开始门限ssthresh,在执行慢开始算法时，发送方每收到一个对新报文段的确认时，就把拥塞窗口cwnd的值加一，然后开始下一轮的传输，当拥塞窗口cwnd增长到慢开始门限值时，就使用拥塞避免算法。

**慢开始：**
假设当前发送方拥塞窗口cwnd的值为1，而发送窗口swnd等于拥塞窗口cwnd，因此发送方当前只能发送一个数据报文段（拥塞窗口cwnd的值是几，就能发送几个数据报文段），接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值变为2

```
发送方此时可以连续发送两个数据报文段，接收方收到该数据报文段后，给发送方一次发回2个确认报文段，发送方收到这两个确认报文后，将拥塞窗口的值加2变为4，发送方此时可连续发送4个报文段，接收方收到4个报文段后，给发送方依次回复4个确认报文，发送方收到确认报文后，将拥塞窗口加4，置为8，发送方此时可以连续发送8个数据报文段，接收方收到该8个数据报文段后，给发送方一次发回8个确认报文段，发送方收到这8个确认报文后，将拥塞窗口的值加8变为16，
```

当前的拥塞窗口cwnd的值已经等于慢开始门限值，之后改用拥塞避免算法。

拥塞避免：
也就是每个传输轮次，拥塞窗口cwnd只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口cwnd按指数增长。同理，16+1……直至到达24，假设24个报文段在传输过程中丢失4个，接收方只收到20个报文段，给发送方依次回复20个确认报文段，一段时间后，丢失的4个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改cwnd和ssthresh.并重新开始慢开始算法，如图所示：

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731165743903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70) 
发送方发送1号数据报文段，接收方收到1号报文段后给发送方发回对1号报文段的确认，在1号报文段到达发送方之前，发送方还可以将发送窗口内的2号数据报文段发送出去，接收方收到2号报文段后给发送方发回对2号报文段的确认，在2号报文段到达发送方之前，发送方还可以将发送窗口内的3号数据报文段发送出去

```
假设该报文丢失，发送方便不会发送针对该报文的确认报文给发送方，发送方还可以将发送窗口内的4号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，发送方还可以将发送窗口中的5号报文段发送出去,接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段,，发送方还可以将发送窗口内的最后一个数据段即6号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段
```

此时，发送方收到了累计3个连续的针对2号报文段的重复确认，立即重传3号报文段，接收方收到后，给发送方发回针对6号报文的确认，表明，序号到6为至的报文都收到了，这样就不会造成发送方对3号报文的超时重传，而是提早收到了重传

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731165605396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70) 

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184314574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70) 



 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184935595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70) 

## TCP粘包

在socket网络编程中，都是端到端通信，由客户端端口+服务端端口+客户端IP+服务端IP+传输协议组成的五元组可以明确的标识一条连接。在TCP的socket编程中，发送端和接收端都有成对的socket。发送端为了将多个发往接收端的包，更加高效的的发给接收端，于是采用了优化算法（Nagle算法），将多次间隔较小、数据量较小的数据，合并成一个数据量大的数据块，然后进行封包。那么这样一来，接收端就必须使用高效科学的拆包机制来分辨这些数据。

### 什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

### 造成TCP粘包的原因

（1）发送方原因

TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

只有上一个分组得到确认，才会发送下一个分组
收集多个小分组，在一个确认到来时一起发送
Nagle算法造成了发送方可能会出现粘包问题

（2）接收方原因

TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

### 什么时候需要处理粘包现象

1. 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象
2. 如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了

### 如何处理粘包现象？

（1）发送方

对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

（2）应用层

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成，但是如何判断每条数据的长度呢？

格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。
发送长度：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。

### UDP会不会产生粘包问题呢？

TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。


# IO模型

（1）同步阻塞IO（Blocking IO）：即传统的IO模型。

（2）同步非阻塞IO（Non-blocking IO）：默认创建的socket都是阻塞的，非阻塞IO要求socket被设置为NONBLOCK。注意这里所说的NIO并非Java的NIO（New IO）库。

（3）IO多路复用（IO Multiplexing）：即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和Linux中的epoll都是这种模型。

（4）异步IO（Asynchronous IO）：即经典的Proactor设计模式，也称为异步非阻塞IO。

## 同步和异步

同步：当一个同步调用发出去后，调用者要一直等待调用结果的返回后，才能进行后续的操作。
异步：当一个异步调用发出去后，调用者不用管被调用方法是否完成，都会继续执行后面的代码。 异步调用，要想获得结果，一般有两种方式：
1、主动轮询异步调用的结果；
2、被调用方通过callback来通知调用方调用结果；

其实总结的话就是：同步和异步是相对服务器端来说的。服务器在受到我们的请求后，如果立刻给我们返回一个响应，哪怕没有返回给我们需要的信息，只是简单的给我们一个相应。那就是异步的。如果是在找到我们需要的资源之后的才给我们响应，那就是同步的。

## 阻塞和非阻塞

阻塞：调用在发出去后，在消息返回之前，当前进/线程会被挂起，直到有消息返回，当前进/线程才会被激活；
非阻塞：调用在发出去后，不会阻塞当前进/线程，而会立即返回。

总结的话也很简单，阻塞和非阻塞就是就是相对于客户端。当我们向服务器发起了一个Http请求以后，我们是挂起线程然后等待服务器给我们返回结果还是继续干其他的事情，等到服务端找到我们需要的信息以后通知我们，我们再去接收，而不是一直死等。

## 传统BIO

![img](https://img-blog.csdnimg.cn/2019042212100021.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM4MTA5MDQ2,size_16,color_FFFFFF,t_70)



采用 **BIO 通信模型** 的服务端，**通常由一个独立的 Acceptor 线程负责监听客户端的连接**。我们一般通过在 `while(true)` 循环中服务端会调用 `accept()` 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接。

如果要让 **BIO 通信模型** 能够同时处理多个客户端请求，就必须使用多线程（主要原因是 `socket.accept()`、 `socket.read()`、 `socket.write()` 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 **一请求一应答通信模型** 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过 **线程池机制** 改善，线程池还可以让线程的创建和回收成本相对较低。使用`FixedThreadPool` 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M）

##  NIO(同步非阻塞)

NIO中的N可以理解为Non-blocking，**IO流是阻塞的，NIO流是不阻塞的。**

### Buffer(缓冲区)

Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。

### Channel (通道)

NIO 通过Channel（通道） 进行读写。

通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。

### Selectors(选择器)

NIO有选择器，而IO没有。

选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。

![img](https://img-blog.csdnimg.cn/20190422121139668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzM4MTA5MDQ2,size_16,color_FFFFFF,t_70)



###  NIO 读数据和写数据方式

通常来说NIO中的所有IO都是从 Channel（通道） 开始的。

- 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。
- 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。

# IO多路复用

## I/O到底是什么

**I/O 其实就是 input 和 output 的缩写，即输入/输出。**

那输入输出啥呢？

比如我们用**键盘来敲代码其实就是输入**，那**显示器显示图案就是输出**，这其实就是 I/O。

而我们时常关心的**磁盘 I/O 指的是硬盘和内存之间的输入输出。**

读取本地文件的时候，要将磁盘的数据拷贝到内存中，修改本地文件的时候，需要把修改后的数据拷贝到磁盘中。

**网络 I/O 指的是网卡与内存之间的输入输出。**

**当网络上的数据到来时，网卡需要将数据拷贝到内存中。当要发送数据给网络上的其他人时，需要将数据从内存拷贝到网卡里。**

那为什么都要跟内存交互呢?

我们的指令最终是由 CPU 执行的，究其原因是 CPU 与内存交互的速度远高于 CPU 和这些外部设备直接交互的速度。

因此都是和内存交互，当然假设没有内存，让 CPU 直接和外部设备交互，那也算 I/O。

总结下：I/O 就是指内存与外部设备之间的交互（数据拷贝）。

## 创建 socket

首先服务端需要先创建一个 socket。在 Linux 中一切都是文件，那么创建的 socket 也是文件，每个文件都有一个整型的文件描述符（fd）来指代这个文件。

```
int socket(int domain, int type, int protocol);
```

- domain：这个参数用于选择通信的协议族，比如选择 IPv4 通信，还是 IPv6 通信等等
- type：选择套接字类型，可选字节流套接字、数据报套接字等等。
- protocol：指定使用的协议。

这个 protocol 通常可以设为 0 ，因为由前面两个参数可以推断出所要使用的协议。

比如`socket(AF_INET, SOCK_STREAM, 0);`，表明使用 IPv4 ，且使用字节流套接字，可以判断使用的协议为 TCP 协议。

这个方法的返回值为 int ，其实就是创建的 socket 的 fd。

## bind

现在我们已经创建了一个 socket，但现在还没有地址指向这个 socket。

众所周知，服务器应用需要指明 IP 和端口，这样客户端才好找上门来要服务，所以此时我们需要指定一个地址和端口来与这个 socket 绑定一下。

```
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

参数里的 sockfd 就是我们创建的 socket 的文件描述符，执行了 bind 参数之后我们的 socket 距离可以被访问又更近了一步。

## listen

执行了 socket、bind 之后，此时的 socket 还处于 closed 的状态，也就是不对外监听的，然后我们需要调用 listen 方法，让 socket 进入被动监听状态，这样的 socket 才能够监听到客户端的连接请求。

```
int listen(int sockfd, int backlog);
```

传入创建的 socket 的 fd，并且指明一下 backlog 的大小。

这个 backlog 我查阅资料的时候，看到了三种解释：

1. socket 有一个队列，同时存放已完成的连接和半连接，backlog为这个队列的大小。
2. socket 有两个队列，分别为已完成的连接队列和半连接队列，backlog为这个两个队列的大小之和。
3. socket 有两个队列，分别为已完成的连接队列和半连接队列，backlog仅为已完成的连接队列大小。

## accept

现在我们已经初始化好监听套接字了，此时会有客户端连上来，然后我们需要处理这些已经完成建连的连接。

从上面的分析我们可以得知，三次握手完成后的连接会被加入到已完成连接队列中去。

这时候，我们就需要从已完成连接队列中拿到连接进行处理，这个拿取动作就由 accpet 来完成。

```
int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
```

这个方法返回的 int 值就是拿到的已完成连接的 socket 的文件描述符，之后操作这个 socket 就可以进行通信了。

如果已完成连接队列没有连接可以取，那么调用 accept 的线程会阻塞等待。

## connect

客户端也需要创建一个 socket，也就是调用 `socket()`，这里就不赘述了，我们直接开始建连操作。

客户端需要与服务端建立连接，在 TCP 协议下开始经典的三次握手操作，再看一下上面画的图：

客户端创建完 socket 并调用 `connect` 之后，连接就处于 `SYN_SEND` 状态，当收到服务端的 `SYN+ACK` 之后，连接就变为 `ESTABLISHED` 状态，此时就代表三次握手完毕。

```
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

调用`connect`需要指定远程的地址和端口进行建连，三次握手完毕之后就可以开始通信了。

客户端这边不需要调用 bind 操作，默认会选择源 IP 和随机端口。

用一幅图来小结一下建连的操作：



可以看到这里的两个阻塞点：

- connect：需要阻塞等待三次握手的完成。
- accept：需要等待可用的已完成的连接，如果已完成连接队列为空，则被阻塞。

## read、write

连接建立成功之后，就能开始发送和接收消息了，我们来看一下



read 为读数据，从服务端来看就是等待客户端的请求，如果客户端不发请求，那么调用 read 会处于阻塞等待状态，没有数据可以读，这个应该很好理解。

write 为写数据，一般而言服务端接受客户端的请求之后，会进行一些逻辑处理，然后再把结果返回给客户端，这个写入也可能会被阻塞。

这里可能有人就会问 read 读不到数据阻塞等待可以理解，**write 为什么还要阻塞，有数据不就直接发了吗**？

因为我们用的是 TCP 协议，TCP 协议需要保证数据可靠地、有序地传输，并且给予端与端之间的流量控制。

**所以说发送不是直接发出去，它有个发送缓冲区，**我们需要把数据先拷贝到 TCP 的发送缓冲区，**由 TCP 自行控制发送的时间和逻辑，有可能还有重传什么的。**

如果我们发的过快，导致接收方处理不过来，那么接收方就会通过 TCP 协议告知：别发了！忙不过来了。发送缓存区是有大小限制的，由于无法发送，还不断调用 write 那么缓存区就满了，满了就不然你 write 了，所以 write 也会发生阻塞。

综上，read 和 write 都会发生阻塞。

## ‘两次拷贝

当程序请求获取网络数据的时候，需要经历两次拷贝：

- 程序需要等待数据从网卡拷贝到内核空间。
- 因为用户程序无法访问内核空间，所以内核又得把数据拷贝到用户空间，这样处于用户空间的程序才能访问这个数据。

介绍这么多就是让你理解为什么会有两次拷贝，且系统调用是有开销的，因此最好不要频繁调用。

## 同步阻塞 I/O



当用户程序的线程调用 read 获取网络数据的时候，首先这个数据得有，也就是网卡得先收到客户端的数据，然后这个数据有了之后需要拷贝到内核中，然后再被拷贝到用户空间内，这整一个过程用户线程都是被阻塞的。

假设没有客户端发数据过来，那么这个用户线程就会一直阻塞等着，直到有数据。即使有数据，那么两次拷贝的过程也得阻塞等着。

所以这称为同步阻塞 I/O 模型。

它的优点很明显，简单。调用 read 之后就不管了，直到数据来了且准备好了进行处理即可。

缺点也很明显，一个线程对应一个连接，一直被霸占着，即使网卡没有数据到来，也同步阻塞等着。

我们都知道线程是属于比较重资源，这就有点浪费了。

所以我们不想让它这样傻等着。

于是就有了同步非阻塞 I/O。

## 同步非阻塞 I/O



从图中我们可以很清晰的看到，同步非阻塞I/O 基于同步阻塞I/O 进行了优化：

在没数据的时候可以不再傻傻地阻塞等着，而是直接返回错误，告知暂无准备就绪的数据！

这里要注意，从内核拷贝到用户空间这一步，用户线程还是会被阻塞的。

这个模型相比于同步阻塞 I/O 而言比较灵活，比如调用 read 如果暂无数据，则线程可以先去干干别的事情，然后再来继续调用 read 看看有没有数据。

但是如果你的线程就是取数据然后处理数据，不干别的逻辑，那这个模型又有点问题了。

等于你不断地进行系统调用，如果你的服务器需要处理海量的连接，那么就需要有海量的线程不断调用，上下文切换频繁，CPU 也会忙死，做无用功而忙死。

那怎么办？

于是就有了I/O 多路复用。

## I/O 多路复用



从图上来看，好像和上面的同步非阻塞 I/O 差不多啊，其实不太一样，线程模型不一样。

既然同步非阻塞 I/O 在太多的连接下频繁调用太浪费了， 那就招个专员吧。

这个专员工作就是管理多个连接，帮忙查看连接上是否有数据已准备就绪。

也就是说，可以只用一个线程查看多个连接是否有数据已准备就绪。

具体到代码上，这个专员就是  select ，**我们可以往 select 注册需要被监听的连接，由 select 来监控它所管理的连接是否有数据已就绪，如果有则可以通知别的线程来 read 读取数据，这个 read 和之前的一样，还是会阻塞用户线程。**

这样一来就可以用少量的线程去监控多条连接，减少了线程的数量，降低了内存的消耗且减少了上下文切换的次数，很舒服。

想必到此你已经理解了什么叫 I/O 多路复用。

所谓的多路指的是多条连接，复用指的是用一个线程就可以监控这么多条连接。

## 信号驱动式I/O





上面的 select 虽然不阻塞了，但是他得时刻去查询看看是否有数据已经准备就绪，那是不是可以让内核告诉我们数据到了而不是我们去轮询呢？

信号驱动 I/O 就能实现这个功能，由内核告知数据已准备就绪，然后用户线程再去 read（还是会阻塞）。

听起来是不是比 I/O 多路复用好呀？那为什么好像很少听到信号驱动 I/O？

**因为我们的应用通常用的都是 TCP 协议，而 TCP 协议的 socket 可以产生信号事件有七种。**

**也就是说不仅仅只有数据准备就绪才会发信号，其他事件也会发信号，而这个信号又是同一个信号，所以我们的应用程序无从区分到底是什么事件产生的这个信号。**

那就麻了呀！

所以我们的应用基本上用不了信号驱动 I/O，但如果你的应用程序用的是 UDP 协议，那是可以的，因为 **UDP 没这么多事件。**

因此，这么一看对我们而言信号驱动 I/O 也不太行。

## 异步 I/O

信号驱动 I/O 虽然对 TCP 不太友好，但是这个思路对的：往异步发展，但是它并没有完全异步，因为其后面那段 read 还是会阻塞用户线程，所以它算是半异步。

因此，我们得想下如何弄成全异步的，也就是把 read 那步阻塞也省了。

其实思路很清晰：**让内核直接把数据拷贝到用户空间之后再告知用户线程，来实现真正的非阻塞I/O！**

所以异步 I/O 其实就是用户线程调用 `aio_read` ，然后包括将数据从内核拷贝到用户空间那步，所有操作都由内核完成，**当内核操作完毕之后，再调用之前设置的回调，此时用户线程就拿着已经拷贝到用户控件的数据可以继续执行后续操作。**

在整个过程中，用户线程没有任何阻塞点，这才是真正的非阻塞I/O。

那么问题又来了:为什么常用的还是I/O多路复用，而不是异步I/O？

**因为 Linux 对异步 I/O 的支持不足，你可以认为还未完全实现，所以用不了异步 I/O。**

**这里可能有人会说不对呀，像 Tomcat 都实现了 AIO的实现类，其实像这些组件或者你使用的一些类库看起来支持了 AIO(异步I/O)，实际上底层实现是用 epoll 模拟实现的。**

**而 Windows 是实现了真正的 AIO，**不过我们的服务器一般都是部署在 Linux 上的，所以主流还是 I/O 多路复用。

## 先驱者select

select 是 2000年左右出现的



作为第一个IO复用系统调用，**select 使用一个宏定义函数按照 bitmap原理填充 fd**，默认大小是 1024个，因此对于fd的**数值大于 1024都可能出现问题**，看下官方预警:

简单解释一下这段话的含义：

当fd的**绝对数值大于1024时将不可控**，因为底层的位数组的原因，官方不建议超过 1024，但是我们也无法控制 fd的绝对数值大小，之前针对这个问题做过一些调研，结论是系统对于 fd的分配有自己的策略，会大概率分配到1024以内，对此我并没有充分理解，只是提及一下这个坑。

### select 实现多路复用的方式

**将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。**

所以，对于 select 这种方式，**需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里** ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。

**poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。**

**但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，**因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。

### 存在的问题和客观评价

由于底层实现方式的局限性，select 存在一些问题，主要包括：

- 可协调fd数量和数值都不超过1024 无法实现高并发
- 使用O(n)复杂度遍历fd数组查看fd的可读写性 效率低
- 涉及大量kernel和用户态拷贝 消耗大
- 每次完成监控需要再次重新传入并且分事件传入 操作冗余

select 以朴素的方式实现了IO复用，将并发量提高的最大K级，但是对于完成这个任务的代价和灵活性都有待提高。

无论怎么样 **select作为先驱对IO复用有巨大的推动**，并且指明了后续的优化方向，不要无知地指责 select。

## 继承者epoll

**在 epoll出现之前，poll 对 select进行了改进，但是本质上并没有太大变化，因此我们跳过 poll直接看 epoll。**

epoll 最初在2.5.44内核版本出现，后续在2.6.x版本中对代码进行了优化使其更加简洁，先后面对外界的质疑在后续增加了一些设置来解决隐藏的问题，所以 epoll也已经有十几年的历史了。

### epoll的基础API和数据结构

epoll主要包括epoll_data、epoll_event、三个api,如下所示：



### epoll三级火箭的科班理解

- **epoll_create**
  该接口是在内核区创建一个epoll相关的一些列结构，并且将一个句柄fd返回给用户态，后续的操作都是基于此fd的，参数size是告诉内核这个结构的元素的大小，类似于stl的vector动态数组，如果size不合适会涉及复制扩容，不过貌似4.1.2内核之后size已经没有太大用途了；
- **epoll_ctl**
  该接口是将fd添加/删除于epoll_create返回的epfd中，其中epoll_event是用户态和内核态交互的结构，定义了用户态关心的事件类型和触发时数据的载体epoll_data；
- **epoll_wait**
  该接口是阻塞等待内核返回的可读写事件，epfd还是epoll_create的返回值，events是个结构体数组指针存储epoll_event，也就是将内核返回的待处理epoll_event结构都存储下来，maxevents告诉内核本次返回的最大fd数量，这个和events指向的数组是相关的；

其中三个api中贯穿了一个数据结构：epoll_event，它可以说是用户态需监控fd的代言人，后续用户程序对fd的操作都是基于此结构的；

### epoll三级火箭的通俗解释

可能上面的描述有些抽象，举个现实中的例子，来帮助大家理解：

- **epoll_create场景**
  大学开学第一周，你作为班长需要帮全班同学领取相关物品，你在学生处告诉工作人员，我是xx学院xx专业xx班的班长，这时工作人员确定你的身份并且给了你凭证，后面办的事情都需要用到(也就是调用epoll_create向内核申请了epfd结构，内核返回了epfd句柄给你使用)；
- **epoll_ctl场景**
  你拿着凭证在办事大厅开始办事，分拣办公室工作人员说班长你把所有需要办理事情的同学的学生册和需要办理的事情都记录下来吧，于是班长开始在每个学生手册单独写对应需要办的事情：李明需要开实验室权限、孙大熊需要办游泳卡......就这样班长一股脑写完并交给了工作人员(也就是告诉内核哪些fd需要做哪些操作)；
- **epoll_wait场景**
  你拿着凭证在领取办公室门前等着，这时候广播喊xx班长你们班孙大熊的游泳卡办好了速来领取、李明实验室权限卡办好了速来取....还有同学的事情没办好，所以班长只能继续(也就是调用epoll_wait等待内核反馈的可读写事件发生并处理)；



**epoll 通过两个方面，很好解决了 select/poll 的问题。**

第一点，**epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字**，**把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)**，通过对这棵黑红树进行操作，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。

第二点， **epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时**，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

**epoll 的方式即使监听的 Socket 数量越多的时候**，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。

插个题外话，网上文章不少说，epoll_wait 返回时，对于就绪的事件，epoll使用的是共享内存的方式，即用户态和内核态都指向了就绪链表，所以就避免了内存拷贝消耗。

这是错的！看过 epoll 内核源码的都知道，压根就没有使用共享内存这个玩意。你可以从下面这份代码看到， epoll_wait 实现的内核代码中调用了 __put_user 函数，这个函数就是将数据从内核拷贝到用户空间。

epoll 支持两种事件触发模式，分别是**边缘触发（\*edge-triggered，ET\*）\**和\**水平触发（\*level-triggered，LT\*）**。

这两个术语还挺抽象的，其实它们的区别还是很好理解的。

**使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；**
**使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；**

举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。

这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。

如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。

如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。

一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。

**select/poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。**






# spring八股

## spring的七种事务传播机制：

最近有看过，这其中其中一对是required就是必须的意思，和他对应的是required_new，他俩的一个共同点是当前的都必须要运行在具有事务的一个上下文中。

另外一组是supports就是说当前方法不需要在一个具有事务的上下文中运行，但是如果有事务的话也可以要运行在这个事务里面，和他对应的是not_supported,就是说这个方法不能运行在一个事务里面，如果一个事务正在运行的话他就会被挂起，等到这个事务提交了或者回滚了才恢复执行

然后是mandatory我记得他的意思是强制性的，方法必须运行在一个事务里，如果没有事务就会抛出异常。和他对应的是never，就是说当前的事务不应该运行在一个事务里面，如果存在事务就会抛出异常

还有最后一个我记得好像是比较特殊的一个叫nested翻译过来是嵌套的这么一个意思。

![image-20210416123901772](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416123901772.png)

假设有类A的方法methodB(),有类B的方法methodB().

1)     PROPAGATION_REQUIRED

如果B的方法methodB()的事务传播特性是propagation_required，那么如下图

![image-20210416124804633](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416124804633.png)



A.methodA()调用B的methodB()方法，那么如果A的方法包含事务，则B的方法则不从新开启事务，

1、  如果B的methodB()抛出异常，A的methodB()没有捕获，则A和B的事务都会回滚；

2、   如果B的methodB()运行期间异常会导致B的methodB()的回滚，A如果捕获了异常，并正常提交事务，则会发生Transaction rolled back because it has been marked as rollback-only的异常。(它已被标记为仅回滚)

3、  如果A的methodA()运行期间异常，则A和B的Method的事务都会被回滚

2)     PROPAGATION_SUPPORTS

如果B的方法methodB()的事务传播特性是propagation_supports,么如下图

![image-20210416124911278](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416124911278.png)



A.methodA()调用B的methodB()方法，那么如果A的方法包含事务，则B运行在此事务环境中，如果A的方法不包含事务，则B运行在非事务环境；

1、如果A没有事务，则A和B的运行出现异常都不会回滚。

2、如果A有事务，A的method方法执行抛出异常，B.methodB和A.methodA都会回滚。

3、如果A有事务，B.method抛出异常，B.methodB和A.methodA都会回滚，如果A捕获了B.method抛出的异常，则会出现异常Transactionrolled back because it has been marked as rollback-only。

3)     PROPAGATION_MANDATORY

表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常，如下图调用关系：

![image-20210416124922475](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416124922475.png)



B.methodB()事务传播特性定义为:PROPAGATION_MANDATORY

1、如果A的methoda()方法没有事务运行环境，则B的methodB()执行的时候会报如下异常：No existingtransaction found for transaction marked with propagation 'mandatory'

2、如果A的Methoda()方法有事务并且执行过程中抛出异常，则A.methoda（）和B.methodb（）执行的操作被回滚；

3、如果A的methoda()方法有事务，则B.methodB()抛出异常时，A的methoda()和B.methodB()都会被回滚；如果A捕获了B.method抛出的异常，则会出现异常Transaction rolled back because ithas been marked as rollback-only

4)     PROPAGATION_NESTED

如有一下方法调用关系，如图：![image-20210416124935554](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416124935554.png)





B的methodB()定义的事务为PROPAGATION_NESTED；

1、        如果A的MethodA()不存在事务，则B的methodB()运行在一个新的事务中，B.method()抛出的异常，B.methodB()回滚,但A.methodA()不回滚；如果A.methoda()抛出异常，则A.methodA()和B.methodB()操作不回。

 

2、        如果A的methodA()存在事务，则A的methoda()抛出异常，则A的methoda()和B的Methodb()都会被回滚；

3、        如果A的MethodA()存在事务，则B的methodB()抛出异常，B.methodB()回滚，如果A不捕获异常，则A.methodA()和B.methodB()都会回滚，如果A捕获异常，则B.methodB()回滚,A不回滚；

5）PROPAGATION_NEVER

表示事务传播特性定义为PROPAGATION_NEVER的方法不应该运行在一个事务环境中

有如下调用关系：

![image-20210416124946449](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416124946449.png)



如果B.methodB()的事务传播特性被定义为PROPAGATION_NEVER，则如果A.methodA()方法存在事务，则会出现异常Existingtransaction found for transaction marked with propagation 'never'。

6）PROPAGATION_REQUIRES_NEW

      表示事务传播特性定义为PROPAGATION_REQUIRES_NEW的方法需要运行在一个新的事务中。

如有一下调用关系：B.methodB()事务传播特性为PROPAGATION_REQUIRES_NEW.

![image-20210416124957296](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416124957296.png)



1、        如果A存在事务，A.methodA()抛出异常，A.methodA()的事务被回滚，但B.methodB()事务不受影响；如果B.methodB()抛出异常，A不捕获的话，A.methodA()和B.methodB()的事务都会被回滚。如果A捕获的话，A.methodA()的事务不受影响但B.methodB()的事务回滚。

7) PROPAGATION_NOT_SUPPORTED

表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行。

如有一下调用关系图：

![image-20210416125019172](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416125019172.png)



如果B.methodB()方法传播特性被定义为：PROPAGATION_NOT_SUPPORTED。

1、        如果A.methodA()存在事务，如果B.methodB()抛出异常，A.methodA()不捕获的话，A.methodA()的事务被回滚，而B.methodB()出现异常前数据库操作不受影响。如果A.methodA()捕获的话，则A.methodA()的事务不受影响，B.methodB()异常抛出前的数据操作不受影响。

## spring循环依赖问题：



### Spring是如何解决的循环依赖？

关于循环依赖的解决方式应该要分两种情况来讨论

1. 简单的循环依赖（没有AOP）
2. 结合了AOP的循环依赖

### 简单的循环依赖（没有AOP）

```java
@Component
public class A {
    // A中注入了B
	@Autowired
	private B b;
}

@Component
public class B {
    // B中也注入了A
	@Autowired
	private A a;
}

```

首先，我们要知道Spring在创建Bean的时候默认是按照自然排序来进行创建的，所以第一步Spring会去创建A。

与此同时，我们应该知道，**Spring在创建Bean的过程中分为三步**

实例化，对应方法：**AbstractAutowireCapableBeanFactory**中的**createBeanInstance**方法

属性注入，对应方法：**AbstractAutowireCapableBeanFactory**的**populateBean**方法

初始化，对应方法：**AbstractAutowireCapableBeanFactory**的**initializeBean**


1. 实例化，简单理解就是new了一个对象
2. 属性注入，为实例化中new出来的对象填充属性
3. 初始化，**执行aware接口中的方法，初始化方法，完成`AOP`代理**



我们开始解读整个循环依赖处理的过程，整个流程应该是以A的创建为起点，前文也说了，第一步就是创建A嘛！

![image-20200706092738559](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjA5MjczODU1OS5wbmc?x-oss-process=image/format,png)

创建A的过程实际上就是调用`getBean`方法，这个方法有两层含义

1. 创建一个新的Bean
2. 从缓存中获取到已经被创建的对象

我们现在分析的是第一层含义，因为这个时候缓存中还没有A嘛！

### 调用getSingleton(beanName)

首先调用`getSingleton(a)`方法，这个方法又会调用`getSingleton(beanName, true)`，在上图中我省略了这一步

```java
public Object getSingleton(String beanName) {
    return getSingleton(beanName, true);
}

```

getSingleton(beanName, true)这个方法实际上就是到缓存中尝试去获取Bean，整个缓存分为三级

singletonObjects，一级缓存，**存储的是所有创建好了的单例Bean**
earlySingletonObjects，完成实例化，但是**还未进行属性注入及初始化的对象**
singletonFactories，提前暴露的一个单例工厂，二级缓存中存储的就是从这个工厂中获取到的对象

因为A是第一次被创建，所以不管哪个缓存中必然都是没有的，因此会进入`getSingleton`的另外一个重载方法`getSingleton(beanName, singletonFactory)`。

### 调用getSingleton(beanName, singletonFactory)

这个方法就是用来创建Bean的，其源码如下：

```java
public Object getSingleton(String beanName, ObjectFactory<?> singletonFactory) {
    Assert.notNull(beanName, "Bean name must not be null");
    synchronized (this.singletonObjects) {
        Object singletonObject = this.singletonObjects.get(beanName);
        if (singletonObject == null) {

            // ....
            // 省略异常处理及日志
            // ....

            // 在单例对象创建前先做一个标记
            // 将beanName放入到singletonsCurrentlyInCreation这个集合中
            // 标志着这个单例Bean正在创建
            // 如果同一个单例Bean多次被创建，这里会抛出异常
            beforeSingletonCreation(beanName);
            boolean newSingleton = false;
            boolean recordSuppressedExceptions = (this.suppressedExceptions == null);
            if (recordSuppressedExceptions) {
                this.suppressedExceptions = new LinkedHashSet<>();
            }
            try {
                // 上游传入的lambda在这里会被执行，调用createBean方法创建一个Bean后返回
                singletonObject = singletonFactory.getObject();
                newSingleton = true;
            }
            // ...
            // 省略catch异常处理
            // ...
            finally {
                if (recordSuppressedExceptions) {
                    this.suppressedExceptions = null;
                }
                // 创建完成后将对应的beanName从singletonsCurrentlyInCreation移除
                afterSingletonCreation(beanName);
            }
            if (newSingleton) {
                // 添加到一级缓存singletonObjects中
                addSingleton(beanName, singletonObject);
            }
        }
        return singletonObject;
    }
}

```

通过`createBean`方法返回的Bean最终被放到了一级缓存，也就是单例池中。

### 调用addSingletonFactory方法

![image-20200706105535307](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjEwNTUzNTMwNy5wbmc?x-oss-process=image/format,png)

在完成Bean的实例化后，属性注入之前Spring将Bean包装成一个工厂添加进了三级缓存中，对应源码如下：

```java
// 这里传入的参数也是一个lambda表达式，() -> getEarlyBeanReference(beanName, mbd, bean)
protected void addSingletonFactory(String beanName, ObjectFactory<?> singletonFactory) {
    Assert.notNull(singletonFactory, "Singleton factory must not be null");
    synchronized (this.singletonObjects) {
        if (!this.singletonObjects.containsKey(beanName)) {
            // 添加到三级缓存中
            this.singletonFactories.put(beanName, singletonFactory);
            this.earlySingletonObjects.remove(beanName);
            this.registeredSingletons.add(beanName);
        }
    }
}

```



这里只是添加了一个工厂，**通过这个工厂（ObjectFactory）的getObject方法可以得到一个对象**，而这个对象实际上就是通过**getEarlyBeanReference**这个方法创建的。那么，什么时候会去调用这个工厂的getObject方法呢？这个时候就要到创建B的流程了。

当A完成了实例化并添加进了三级缓存后，就要开始为A进行属性注入了，在注入时发现A依赖了B，那么这个时候Spring又会去getBean(b)，然后反射调用setter方法完成属性注入。

![image-20200706114501300](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjExNDUwMTMwMC5wbmc?x-oss-process=image/format,png)

因为B需要注入A，所以在创建B的时候，又会去**调用getBean(a)**，这个时候就又回到之前的流程了，但是不同的是，之前的getBean是为了创建Bean，而此时再调用getBean不是为了创建了，而是要**从缓存中获取**，因为之前A在实例化后已经将其放入了三级缓存singletonFactories中，所以此时getBean(a)的流程就是这样子了

![image-20200706115959250](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjExNTk1OTI1MC5wbmc?x-oss-process=image/format,png)

从这里我们可以看出，注入到B中的A是通过`getEarlyBeanReference`方法提前暴露出去的一个对象，还不是一个完整的Bean，那么`getEarlyBeanReference`到底干了啥了，我们看下它的源码

```Java
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {
        for (BeanPostProcessor bp : getBeanPostProcessors()) {
            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {
                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;
                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);
            }
        }
    }
    return exposedObject;
}

```

它实际上就是调用了**后置处理器的getEarlyBeanReference**，而真正实现了这个方法的后置处理器只有一个，就是通过@EnableAspectJAutoProxy注解导入的AnnotationAwareAspectJAutoProxyCreator。也就是说如果在不考虑AOP的情况下，上面的代码等价于：

```java
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    return exposedObject;
}

```

**也就是说这个工厂啥都没干，直接将实例化阶段创建的对象返回了！所以说在不考虑`AOP`的情况下三级缓存有用嘛？讲道理，真的没什么用**，我直接将这个对象放到二级缓存中不是一点问题都没有吗？如果你说它提高了效率，那你告诉我提高的效率在哪?

整个创建A这个Bean的流程

![image-20200706133018669](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjEzMzAxODY2OS5wbmc?x-oss-process=image/format,png)



虽然在创建B时会提前给B注入了一个还未初始化的A对象，但是**在创建A的流程中一直使用的是注入到B中的A对象的引用，之后会根据这个引用对A进行初始化**，所以这是没有问题的。

### 结合了AOP的循环依赖

在普通的循环依赖的情况下，三级缓存没有任何作用。三级缓存实际上跟Spring中的`AOP`相关，我们再来看一看`getEarlyBeanReference`的代码：

```java
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {
        for (BeanPostProcessor bp : getBeanPostProcessors()) {
            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {
                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;
                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);
            }
        }
    }
    return exposedObject;
}

```

如果在开启`AOP`的情况下，那么就是调用到`AnnotationAwareAspectJAutoProxyCreator`的`getEarlyBeanReference`方法，对应的源码如下：

```java
public Object getEarlyBeanReference(Object bean, String beanName) {
    Object cacheKey = getCacheKey(bean.getClass(), beanName);
    this.earlyProxyReferences.put(cacheKey, bean);
    // 如果需要代理，返回一个代理对象，不需要代理，直接返回当前传入的这个bean对象
    return wrapIfNecessary(bean, beanName, cacheKey);
}

```

回到上面的例子，我们对A进行了`AOP`代理的话，那么此时`getEarlyBeanReference`将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。

![image-20200706161709829](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE2MTcwOTgyOS5wbmc?x-oss-process=image/format,png)

看到这个图你可能会产生下面这些疑问

1. 在给B注入的时候为什么要注入一个代理对象？

答：当我们对A进行了`AOP`代理时，说明我们希望**从容器中获取到的就是A代理后的对象而不是A本身**，因此把A当作依赖进行注入时也要注入它的代理对象

1. 明明初始化的时候是A对象，那么Spring是在哪里将代理对象放入到容器中的呢？

![image-20200706160542584](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE2MDU0MjU4NC5wbmc?x-oss-process=image/format,png)

在完成初始化后，**Spring又调用了一次getSingleton方法，这一次传入的参数又不一样了，false可以理解为禁用三级缓存**，前面图中已经提到过了，在为B中注入A时已经将三级缓存中的工厂取出，并从工厂中获取到了一个对象放入到了二级缓存中，所以这里的这个getSingleton方法做的时间就是从二级缓存中获取到这个代理后的A对象。exposedObject == bean可以认为是必定成立的，除非你非要在初始化阶段的后置处理器中替换掉正常流程中的Bean，例如增加一个后置处理器：


```Java
@Component
public class MyPostProcessor implements BeanPostProcessor {
	@Override
	public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
		if (beanName.equals("a")) {
			return new A();
		}
		return bean;
	}
}

```

**初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？**

答：不会，这是因为不管是cglib代理还是jdk动态代理生成的代理类，**内部都持有一个目标类的引用**，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化

三级缓存为什么要使用工厂而不是直接使用引用？换而言之，为什么需要这个三级缓存，直接通过二级缓存暴露一个引用不行吗？
答：**这个工厂的目的在于延迟对实例化阶段生成的对象的代理，只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会创建一个工厂并将其放入到三级缓存中，但是不会去通过这个工厂去真正创建对象**

我们思考一种简单的情况，就以单独创建A为例，假设AB之间现在没有依赖关系，但是A被代理了，这个时候当A完成实例化后还是会进入下面这段代码：

```java
// A是单例的，mbd.isSingleton()条件满足
// allowCircularReferences：这个变量代表是否允许循环依赖，默认是开启的，条件也满足
// isSingletonCurrentlyInCreation：正在在创建A，也满足
// 所以earlySingletonExposure=true
boolean earlySingletonExposure = (mbd.isSingleton() && this.allowCircularReferences &&
                                  isSingletonCurrentlyInCreation(beanName));
// 还是会进入到这段代码中
if (earlySingletonExposure) {
	// 还是会通过三级缓存提前暴露一个工厂对象
    addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));
}

```

看到了吧，**即使没有循环依赖，也会将其添加到三级缓存中，而且是不得不添加到三级缓存中，因为到目前为止Spring也不能确定这个Bean有没有跟别的Bean出现循环依赖。**

假设我们在这里直接使用二级缓存的话，那么意味着所有的Bean在这一步都要完成AOP代理。这样做有必要吗？

不仅没有必要，而且违背了Spring在结合AOP跟Bean的生命周期的设计！Spring结合AOP跟Bean的生命周期本身就是通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来完成的，在这个后置处理的postProcessAfterInitialization方法中对初始化后的Bean完成AOP代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。

### 三级缓存真的提高了效率了吗？

1. 没有进行`AOP`的Bean间的循环依赖

从上文分析可以看出，这种情况下三级缓存根本没用！所以不会存在什么提高了效率的说法

1. 进行了`AOP`的Bean间的循环依赖

就以我们上的A、B为例，其中A被`AOP`代理，我们先分析下使用了三级缓存的情况下，A、B的创建流程

![image-20210916090421250](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210916090421250.png)

假设不使用三级缓存，直接在二级缓存中

![image-20200706172523258](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE3MjUyMzI1OC5wbmc?x-oss-process=image/format,png)

上面两个流程的唯一区别在于**为A对象创建代理的时机不同**，在使用了三级缓存的情况下为A创建代理的时机是在**B中需要注入A的时候**，而不使用三级缓存的话在A实例化后**就需要马上为A创建代理然后放入到二级缓存中去**。对于整个A、B的创建过程而言，消耗的时间是一样的

综上，不管是哪种情况，三级缓存提高了效率这种说法都是错误的！

### 总结

面试官：”Spring是如何解决的循环依赖？“

答：Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（singletonObjects）,二级缓存为早期曝光对象earlySingletonObjects，三级缓存为早期曝光对象工厂（singletonFactories）。当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取，第一步，先获取到三级缓存中的工厂；第二步，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！

面试官：”为什么要使用三级缓存呢？二级缓存能解决循环依赖吗？“

答：如果要使用二级缓存解决循环依赖，意味着所有Bean在实例化后就要完成AOP代理，这样违背了Spring设计的原则，Spring在设计之初就是通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来在Bean生命周期的最后一步来完成AOP代理，而不是在实例化后就立马进行AOP代理。




## bean的生命周期

### **四个阶段**

1. Bean的实例化阶段
2. Bean的设置属性阶段
3. Bean的 初始化阶段
4. Bean的销毁阶段

**在初始化阶段，有个特别重要的接口BeanPostProcessor，在初始化前、后调用：**

**在设置属性阶段后，postProcessBeforeInitialization方法执行前，会执行很多Aware类型的接口，这种类型接口作用是加载资源到Spring容器中，Aware前面的名字就对应哪种资源，依次加载的是：**

1. BeanNameAware
2. BeanClassLoaderAware
3. BeanFactoryAware
4. EnvironmentAware
5. ResourceLoaderAware
6. ApplicationEventPublisherAware
7. ApplicationContextAware

**BeanFactory和ApplicationContext的区别**

BeanFactoryAware之前加载的资源都是公共的。BeanFactoryAware后面加载的资源都是ApplicationContext独有的。

**初始化方式有三个，分别是：**

1. InitializingBean的afterPropertiesSet方法
2. PostConstruct注解标注的方法
3. 配置的init-method

上面的三个方法效果都是一样的，开发中选择其中一种方式就行，一般我们选择2、3方法中的一个。

**容器销毁的方式有三个，分别是：**

1. preDestroy注解标注的方法
2. DisposableBean接口的destroy方法
3. 配置的destroy-method

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20201028180446251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzI0NDY5OA==,size_16,color_FFFFFF,t_70#pic_center) 





### 总结

综合前面的代码和分析，现在我们用大白话描述下：

Bean容器找到Spring配置文件中Bean的定义；
Bean容器利用java 反射机制实例化Bean；
Bean容器为实例化的Bean设置属性值；
如果Bean实现了BeanNameAware接口，则执行setBeanName方法；
如果Bean实现了BeanClassLoaderAware接口，则执行setBeanClassLoader方法；
如果Bean实现了BeanFactoryAware接口，则执行setBeanFactory方法；
如果 ……真的，到这我经常忘记，但前面三个Aware接口肯定能记住；
如果Bean实现了ApplicationContextAware接口，则执行setApplicationContext方法；
如果加载了BeanPostProcessor相关实现类，则执行postProcessBeforeInitialization方法；
如果Bean定义初始化方法（PostConstruct注解、配置init-method、实现了InitializingBean接口），则执行定义的初始化方法；
如果加载了BeanPostProcessor相关实现类，则执行postProcessAfterInitialization方法；
当要销毁这个Bean时，如果自定义了销毁方法（PreDestroy注解、配置destroy-method、实现了DisposableBean接口），则执行定义的销毁方法。







## bean的自动装配

在Spring框架xml配置中共有5种自动装配：

no：默认的方式是不进行自动装配的，通过手工设置ref属性来进行装配bean。

byName：通过bean的名称进行自动装配，如果一个bean的 property 与另一bean 的name 相同，就进行自动装配。

byType：通过参数的数据类型进行自动装配。

constructor：利用构造函数进行装配，并且构造函数的参数通过byType进行装配。

autodetect：自动探测，如果有构造方法，通过 construct的方式自动装配，否则使用 byType的方式自动装配。

## @Component注解

注解装配在默认情况下是不开启的，为了使用注解装配，我们必须在Spring配置文件中配置 `<context:annotation-config/>`元素

@Component：这将 java 类标记为 bean。它是任何 Spring 管理组件的通用构造型。spring 的组件扫描机制现在可以将其拾取并将其拉入应用程序环境中。

@Controller：这将一个类标记为 Spring Web MVC 控制器。标有它的 Bean 会自动导入到 IoC 容器中。

@Service：此注解是组件注解的特化。它不会对 @Component 注解提供任何其他行为。您可以在服务层类中使用 @Service 而不是 @Component，因为它以更好的方式指定了意图。

@Repository：这个注解是具有类似用途和功能的 @Component 注解的特化。它为 DAO 提供了额外的好处。它将 DAO 导入 IoC 容器，并使未经检查的异常有资格转换为 Spring DataAccessException。


## @Required 注解

这个注解表明bean的属性必须在配置的时候设置，通过一个bean定义的显式的属性值或通过自动装配，若@Required注解的bean属性未被设置，容器将抛出BeanInitializationException

## @Autowired和@Resource之间的区别

@Autowired可用于：构造函数、成员变量、Setter方法

@Autowired默认是**按照类型装配注入的**，默认情况下它**要求依赖对象必须存在**（可以设置它required属性为false）。
@Resource和@Autowired都可以用来装配bean，都可以用于字段或setter方法。

@Resource默认**按名称装配**，当找不到与名称匹配的bean时才按照类型进行装配。名称可以通过name属性指定，如果没有指定name属性，当注解写在字段上时，默认取字段名，当注解写在setter方法上时，默认取属性名进行装配。

```java
@Autowired(required = false) @Qualifier("example")
private Example example;

@Resource(name = "example")
private Example example;
```

| **注解对比** | **@Resource** | **@Autowire** |
| ------------ | ------------- | ------------- |
| 注解来源     | JDK           | Spring        |
| 装配方式     | 优先按名称    | 优先按类型    |
| 属性         | name、type    | required      |



## @Qualifier 注解

当创建多个相同类型的 bean 并希望仅使用属性装配其中一个 bean 时，您可以使用@Qualifier 注解和 @Autowired 通过指定应该装配哪个确切的 bean 来消除歧义。

## 定时任务注解

**@Scheduled(cron = “0 0 0 \* \* ?”)** （设置定时启动时间）

**@EnableScheduling** （设置定时器开关启动）

## 用到的设计模式

1、工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例；
2、单例模式：Bean默认为单例模式。
3、代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术；
4、模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。
5、观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener。

## Spring有几种配置方式

- XML配置文件。
- 基于注解的配置。
- 基于java的配置。

## Spring基于xml注入bean的几种方式

1. Set方法注入；
2. 构造器注入：①通过index设置参数的位置；②通过type设置参数类型；
3. 静态工厂注入；
4. 实例工厂；

## Spring支持的几种bean的作用域

1、singleton : bean在每个Spring ioc 容器中只有一个实例。
2、prototype：一个bean的定义可以有多个实例。
3、request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。
4、session：在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。
5、global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。

## Spring框架中的单例bean是线程安全的吗？

不是，Spring框架中的单例bean不是线程安全的。

spring 中的 bean 默认是单例模式，spring 框架并没有对单例 bean 进行多线程的封装处理。

实际上大部分时候 spring bean 无状态的（比如 dao 类），所有某种程度上来说 bean 也是安全的，但如果 bean 有状态的话（比如 view model 对象），那就要开发者自己去保证线程安全了，最简单的就是改变 bean 的作用域，把“singleton”变更为“prototype”，这样请求 bean 相当于 new Bean()了，所以就可以保证线程安全了。

有状态就是有数据存储功能。
无状态就是不会保存数据。

## Spring如何处理线程并发问题？

在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域，**因为Spring对一些Bean中非线程安全状态采用ThreadLocal进行处理**，解决线程安全问题。

ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。同步机制采用了“时间换空间”的方式，仅提供一份变量，不同的线程在访问前需要获取锁，没获得锁的线程则需要排队。而ThreadLocal采用了“空间换时间”的方式。

ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。

# Spring源码

## spring容器是什么

其实关于spring容器的话，spring官网中有一句话它翻译成中文的意思是：

1. Spring IOC容器就是一个`org.springframework.context.ApplicationContext`的实例化对象
2. 容器负责了实例化，配置以及装配一个bean

**那其实从代码层次来看：Spring容器就是一个实现了`ApplicationContext`接口的对象**，

**从功能上来看： Spring 容器是 Spring 框架的核心，是用来管理对象的。容器将创建对象，把它们连接在一起，配置它们，并管理他们的整个生命周期从创建到销毁。**

## 容器如何工作

我们直接看官网上的一张图片，如下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191217235039696.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxOTA3OTkx,size_16,color_FFFFFF,t_70)

**Spring容器通过我们提交的pojo类以及配置元数据产生一个充分配置的可以使用的系统**

这里说的配置元数据，实际上我们就是我们提供的**XML配置文件**，或者通过**注解方式**提供的一些配置信息



## 如何实例化一个Bean？

从官网上来看，主要有以下三种方法

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191217235049718.jpg)



1. **构造方法**
2. **静态工厂方法**
3. **实例工厂方法**







# Springmvc

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804094526791.png" alt="image-20210804094526791" style="zoom: 200%;" />

## Springmvc架构原理解析

1. 发起请求到前端控制器(DispatcherServlet)
2. 前端控制器请求HandlerMapping查找 Handler，可以根据xml配置、注解进行查找
3. 处理器映射器HandlerMapping向前端控制器返回Handler
4. 前端控制器调用处理器适配器去执行Handler
5. 处理器适配器去执行Handler
6. Handler执行完成给适配器返回ModelAndView
7. 处理器适配器向前端控制器返回ModelAndView，ModelAndView是springmvc框架的一个底层对象，包括 Model和view
8. 前端控制器请求视图解析器去进行视图解析，根据逻辑视图名解析成真正的视图(jsp)
9. 视图解析器向前端控制器返回View
10. 前端控制器进行视图渲染，视图渲染将模型数据(在ModelAndView对象中)填充到request域
11. 前端控制器向用户响应结果
    

## 组件

1、前端控制器DispatcherServlet（不需要程序员开发）
作用接收请求，响应结果，相当于转发器，中央处理器。
有了DispatcherServlet减少了其它组件之间的耦合度。

2、处理器映射器HandlerMapping(不需要程序员开发)
作用：根据请求的url查找Handler

3、处理器适配器HandlerAdapter
作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler

4、处理器Handler(需要程序员开发)
注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler

5、视图解析器View resolver(不需要程序员开发)
作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）

6、视图View(需要程序员开发jsp)
View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…）

# Mybatis

## Mybatis中的设计模式

1. Builder模式，例如SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder；
2. 工厂模式，例如SqlSessionFactory、ObjectFactory、MapperProxyFactory；
3. 单例模式，例如ErrorContext和LogFactory；
4. 代理模式，Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果；
5. 组合模式，例如SqlNode和各个子类ChooseSqlNode等；
6. 模板方法模式，例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler；
7. 适配器模式，例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现；
8. 装饰者模式，例如Cache包中的cache.decorators子包中等各个装饰者的实现；
9. 迭代器模式，例如迭代器模式PropertyTokenizer；

### 1、Builder模式

Builder模式的定义是“将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。”，它属于创建类模式，一般来说，如果一个对象的构建比较复杂，超出了构造函数所能包含的范围，就可以使用工厂模式和Builder模式，相对于工厂模式会产出一个完整的产品，Builder应用于更加复杂的对象的构建，甚至只会构建产品的一个部分。

![image-20210910075820926](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910075820926.png)

在Mybatis环境的初始化过程中，SqlSessionFactoryBuilder会调用XMLConfigBuilder读取所有的MybatisMapConfig.xml和所有的*Mapper.xml文件，构建Mybatis运行的核心对象Configuration对象，然后将该Configuration对象作为参数构建一个SqlSessionFactory对象。

其中XMLConfigBuilder在构建Configuration对象时，也会调用XMLMapperBuilder用于读取*Mapper文件，而XMLMapperBuilder会使用XMLStatementBuilder来读取和build所有的SQL语句。

在这个过程中，有一个相似的特点，就是这些Builder会读取文件或者配置，然后做大量的XpathParser解析、配置或语法的解析、反射生成对象、存入结果缓存等步骤，这么多的工作都不是一个构造函数所能包括的，因此大量采用了Builder模式来解决。

对于builder的具体类，方法都大都用build*开头，比如SqlSessionFactoryBuilder为例，它包含以下方法：

![image-20210910075853510](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910075853510.png)

即根据不同的输入参数来构建SqlSessionFactory这个工厂对象。

## 执行流程

### 概要

在MyBatis中，利用编程式进行数据查询，主要就是下面几行代码：

```
SqlSession session = sqlSessionFactory.openSession();
UserMapper userMapper = session.getMapper(UserMapper.class);
List<LwUser> userList = userMapper.listUserByUserName("孤狼1号");
```

第一行是获取一个SqlSession对象，想要详细了解的可以点击这里，第二行就是获取UserMapper接口，第三行一行代码就实现了整个查询语句的流程，接下来我们就来仔细分析一下第二和第三步。

### 获取Mapper接口(getMapper)

第二步是通过SqlSession对象是获取一个Mapper接口

![image-20210910080531095](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910080531095.png)

1、在调用了getMapper之后，会去Configuration对象中获取Mapper对象，因为在项目启动的时候就会把Mapper接口加载并解析存储到Configuration对象

![image-20210910080630838](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910080630838.png)



2、通过Configuration对象中的MapperRegistry对象属性，继续调用getMapper方法

![image-20210910080750181](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910080750181.png)



3、根据type类型，从MapperRegistry对象中的knownMappers获取到当前类型对应的代理工厂类，然后通过代理工厂类生成对应Mapper的代理类

![image-20210910080833831](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910080833831.png)

4、最终获取到我们接口对应的代理类MapperProxy对象

其实MapperProxy是实现了InvocationHandler接口，使用的就是JDK动态代理。

![image-20210910081314541](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910081314541.png)

至此获取Mapper流程结束了，那么就有一个问题了MapperRegistry对象内的HashMap属性knownMappers中的数据是什么时候存进去的呢？

### Mapper接口和映射文件是何时关联的

Mapper接口及其映射文件是在加载mybatis-config配置文件的时候存储进去的，下面就是时序图：

![image-20210910081529222](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910081529222.png)

1、首先我们要手动调用SqlSessionFactoryBuilder方法中的build()方法：

2、然后会构造一个XMLConfigBuilder对象，并调用其parse方法：

![image-20210910081758525](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910081758525.png)

3、然后会继续调用自己的parseConfiguration来解析配置文件，这里面就会分别去解析全局配置文件的顶级节点，其他的我们先不看，我们直接看最后解析mappers节点

![image-20210910081813024](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910081813024.png)

![image-20210910081957157](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910081957157.png)

4、继续调用自己的mapperElement来解析mappers文件，可以看到，这里面分了四种方式来解析mappers节点的配置，对应了**「4种mapper配置方式」**，而其中红框内的两种方式是直接配置的xml映射文件，蓝框内的两种方式是解析直接配置Mapper接口的方式，从这里也可以说明，**「不论配置哪种方式，最终MyBatis都会将xml映射文件和Mapper接口进行关联」**。

![image-20210910082050921](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082050921.png)

5、先看第2种和第3中（直接配置xml映射文件的解析方式），会构建一个XMLMapperBuilder对象并调用其parse方法。

![image-20210910082137066](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082137066.png)

问题，如果有多重继承或者多重依赖时在这里是可能会无法被完全解析的，比如说三个映射文件互相依赖，那么if里面(假设是最坏情况)只能加载1个，**「失败2个」**，然后走到下面if之外的代码又只能加载1个，**「还有1个会失败」**(如下代码中，只会处理1次，再次失败并不会继续加入incompleteResultMaps)：

6、解析完映射文件之后，调用自身方法bindMapperForNamespace，开始绑定Mapper接口和映射文件：

![image-20210910082437831](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082437831.png)

7、调用Configuration对象的addMapper

![image-20210910082503408](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082503408.png)

8、调用Configuration对象的属性MapperRegistry内的addMapper方法，这个方法就是正式将Mapper接口添加到knownMappers，所以上面getMapper可以直接获取：

![image-20210910082522377](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082522377.png)

到这里我们就完成了Mapper接口和xml映射文件的绑定

## sql执行流程分析

### 寻找sql

![image-20210910082630855](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082630855.png)

1、了解代理模式的应该都知道，调用被代理对象的方法之后实际上执行的就是代理对象的invoke方法

![image-20210910082838070](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082838070.png)

2、因为我们这里并没有调用Object类中的方法，所以肯定走的else。else中会继续调用MapperProxy内部类MapperMethodInvoker中的方法cachedInvoker，这里面会有一个判断，判断一下我们是不是default方法，因为Jdk1.8中接口中可以新增default方法，而default方法是并不是一个抽象方法，所以也需要特殊处理

![image-20210910082921871](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082921871.png)

3、接下来，是构造一个MapperMethod对象,这个对象封装了Mapper接口中对应的方法信息以及对应的sql语句信息：

![image-20210910082946487](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910082946487.png)

执行的sql语句，请求参数，方法返回值全部解析封装成MapperMethod对象，然后后面就可以开始准备执行sql语句了。




# Tomcat

tomcat是一个servlet容器，但是在tomcat中起到servlet容器作用的是**Catalina**

## **servlet服务器请求处理流程**

当客户请求某个资源时，HTTP服务器会用一个ServletRequest对象把客户的请求信息封 装，然后调用Servlet容器的service方法，Servlet容器拿到请求后，根据请求的URL 和Servlet的映射关系，找到相应的Servlet，如果Servlet还没有被加载，就用反射机制创 建这个Servlet，并调用Servlet的init方法来完成初始化，接着调用Servlet的service方法 来处理请求，把ServletResponse对象返回给HTTP服务器，HTTP服务器会把响应发送给 客户端

以上就是servlet容器的整个工作过程，但是到达servlet容器并处理请求，整个过程是由许多个小的步骤，各个组件的配合共同完成的，让我们分别来做了解

## Tomcat整体架构

我们知道如果要设计一个系统，首先是要了解需求，我们已经了解了Tomcat要实现两个 核心功能

1） 处理Socket连接，负责网络字节流与Request和Response对象的转化
2） 加载和管理Servlet，以及具体处理Request请求

Coyote 将Socket 输 入转换封装为 Request 对象，交由Catalina 容器进行处理，处理请求完成后, Catalina 通 过Coyote 提供的Response 对象将结果写入输出流，可以说，Coyote提供了一个类似中间人的角色，承接着socket的http请求到httpServletRequest请求的转化传递，

研究tomcat的过程中，个人认为最好是从`server.xml`文件看起，这个文件的层次结构可以说很大一部分程度上反映了tomcat逻辑上的各个组件的结构，主要是这个文件的层次感太强了，组件之间的嵌套关系一眼便知，下面贴出了tomcat8X版本的srver.xml的配置文件，去掉了注释

**一个容器可能对接多个连接器**但是单独**的连接器或者容器都不能对外提供服务**，需要把它们组装起来才能工作，**组装后这个整体叫作Service组件**。这里注意，Service本身没有做什 么事情，只是在连接器和容器外面多包了一层，把它们组装在一起。Tomcat内可能有多个Service，这样的设计也是出于灵活性的考虑。通过在Tomcat中配置多个 Service，可以实现通过不同的端口号来访问同一台机器上部署的不同应用。这就解释了我们可以在webapps下部署多个不同的war包了吧，因为它们归属于不同的 service

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201123225109516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nY29uZ3lpNDIw,size_16,color_FFFFFF,t_70#pic_center)

EndPoint

EndPoint ： Coyote 通信端点，即通信监听的接口，是具体Socket接收和发送处理 器，是对传输层的抽象，因此EndPoint用来实现TCP/IP协议的
Tomcat 并没有EndPoint 接口，而是提供了一个抽象类AbstractEndpoint ， 里面定 义了两个内部类：Acceptor和SocketProcessor。Acceptor用于监听Socket连接请求。 SocketProcessor用于处理接收到的Socket请求，它实现Runnable接口，在Run方法里 调用协议处理组件Processor进行处理。为了提高处理能力，SocketProcessor被提交到 线程池来执行。而这个线程池叫作执行器（Executor)，我在后面的专栏会详细介绍 Tomcat如何扩展原生的Java线程池
Processor

Coyote 协议处理接口 ，如果说EndPoint是用来实现TCP/IP协议的，那么 Processor用来实现HTTP协议，Processor接收来自EndPoint的Socket，读取字节流解 析成Tomcat Request和Response对象，并通过Adapter将其提交到容器处理， Processor是对应用层协议的抽象

ProtocolHandler

Coyote 协议接口， 通过Endpoint 和 Processor ， 实现针对具体协 议的处理能力。Tomcat 按照协议和I/O 提供了6个实现类 ： AjpNioProtocol ， AjpAprProtocol， AjpNio2Protocol ， Http11NioProtocol ，Http11Nio2Protocol ， Http11AprProtocol。我们在配置tomcat/conf/server.xml 时 ， 至少要指定具体的 ProtocolHandler , 当然也可以指定协议名称 ， 如 ： HTTP/1.1 ，如果安装了APR，那么 将使用Http11AprProtocol ， 否则使用 Http11NioProtocol

Adapter

由于协议不同，客户端发过来的请求信息也不尽相同，Tomcat定义了自己的Request类 来“存放”这些请求信息。ProtocolHandler接口负责解析请求并生成Tomcat Request类。 但是这个Request对象不是标准的ServletRequest，也就意味着，不能用Tomcat Request作为参数来调用容器。Tomcat设计者的解决方案是引入CoyoteAdapter，这是 适配器模式的经典运用，连接器调用CoyoteAdapter的Sevice方法，传入的是Tomcat Request对象，CoyoteAdapter负责将Tomcat Request转成ServletRequest，再调用容 器的Service方法

## **容器 - Catalina**



![在这里插入图片描述](https://img-blog.csdnimg.cn/20201123230527668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nY29uZ3lpNDIw,size_16,color_FFFFFF,t_70#pic_center)

Catalina负责管理Server，而Server表示着整个服务器。Server下面有多个 服务Service，每个服务都包含着多个连接器组件Connector（Coyote 实现）和一个容器 组件Container。在Tomcat 启动的时候， 会初始化一个Catalina的实例

### **Catalina 各个组件的职责：**

Catalina:负责解析Tomcat的配置文件 , 以此来创建服务器Server组件，并根据 命令来对其进行管理

Server:服务器表示整个Catalina Servlet容器以及其它组件，负责组装并启动 Servlet引擎,Tomcat连接器。Server通过实现Lifecycle接口，提供了 一种优雅的启动和关闭整个系统的方式

Service:服务是Server内部的组件，一个Server包含多个Service。它将若干个 Connector组件绑定到一个Container（Engine）上

Connector:连接器，处理与客户端的通信，它负责接收客户请求，然后转给相关 的容器处理，最后向客户返回响应结果

Container:容器，负责处理用户的servlet请求，并返回对象给web用户的模块

Engine:表示整个Catalina的Servlet引擎，用来管理多个虚拟站点，一个Service 最多只能有一个Engine，但是一个引擎可包含多个Host

Host:代表一个虚拟主机，或者说一个站点，可以给Tomcat配置多个虚拟主 机地址，而一个虚拟主机下可包含多个Context

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201123231225850.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nY29uZ3lpNDIw,size_16,color_FFFFFF,t_70#pic_center)

8、Context:表示一个Web应用程序， 一个Web应用可包含多个Wrapper

9、Wrapper:表示一个Servlet，Wrapper 作为容器中的最底层，不能包含子容器

容器通过 Pipeline-Valve `责任链`，对请求一次处理，invoke 处理方法，每个容器都有一个 Pipeline，触发第一个 Valve，这个容器的 valve 都会被调到，不同容器之间通过 Pipeline 的 getBasic 方法，负责调用下层容器的第一个 Valve

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020112323144163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nY29uZ3lpNDIw,size_16,color_FFFFFF,t_70#pic_center)

## **tomcat 的IO模型**

tomcat在启动过程中，主要完成了2件事情，第一`初始化容器组件`，第二启动`相关的线程等待读写事件的接入`

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201125214206289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nY29uZ3lpNDIw,size_16,color_FFFFFF,t_70#pic_center)

从tomcat8之后，tomcat默认使用的是NIO，即异步IO，我们知道，在tomcat8之前的版本中有大多使用同步IO，同步IO和异步IO相比，在高并发的请求处理场景中性能相差非常大，这个得益于NIO的底层特殊的线程处理机制，即reactor模型

## 启动流程

调用 bin/startup.bat (在linux 目录下 , 需要调用 bin/startup.sh) ， 在startup.bat 脚本中, 调用了catalina.bat

在catalina.bat 脚本文件中，调用了BootStrap 中的main方法

在BootStrap 的main 方法中调用了 init 方法 ， 来创建Catalina 及 初始化类加载器

在BootStrap 的main 方法中调用了 load 方法 ， 在其中又调用了Catalina的load方法

在Catalina 的load 方法中 , 需要进行一些初始化的工作, 并需要构造Digester 对象, 用 于解析 XML

然后在调用后续组件的初始化操作(见时序图中的组件init过程)

加载Tomcat的配置文件，初始化容器组件 ，监听对应的端口号， 准备接受客户端请求

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201125220214175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5nY29uZ3lpNDIw,size_16,color_FFFFFF,t_70#pic_center)

## 生命周期

![image-20210416120030161](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416120030161.png)

# Springboot

## 启动流程

![image-20210416112216223](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416112216223.png)

![image-20210416112243722](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416112243722.png)

SpringBoot启动类首先进入run方法

![image-20210416112349121](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416112349121.png)

run方法中去创建了一个SpringApplication实例，在该构造方法内，我们可以发现其调用了一个初始化的initialize方法

![image-20210416112357995](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416112357995.png)

![image-20210416112424443](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416112424443.png)

里主要是为SpringApplication对象赋一些初值。构造函数执行完毕后，我们回到run方法

![image-20210416112457307](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416112457307.png)

该方法中实现了如下几个关键步骤：

1.创建了应用的监听器SpringApplicationRunListeners并开始监听

2.加载SpringBoot配置环境(ConfigurableEnvironment)，如果是通过web容器发布，会加载StandardEnvironment，其最终也是继承了ConfigurableEnvironment

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190903090534547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hmbWJvb2s=,size_16,color_FFFFFF,t_70)

PropertyResolver接口，我们平时通过environment对象获取配置文件中指定Key对应的value方法时，就是调用了propertyResolver接口的getProperty方法

3.配置环境(Environment)加入到监听器对象中(SpringApplicationRunListeners)

4.创建run方法的返回对象：ConfigurableApplicationContext(应用配置上下文)，我们可以看一下创建方法：

方法会先获取显式设置的应用上下文(applicationContextClass)，如果不存在，再加载默认的环境配置（通过是否是web environment判断），默认选择AnnotationConfigApplicationContext注解上下文（通过扫描所有注解类来加载bean），最后通过BeanUtils实例化上下文对象，并返回，ConfigurableApplicationContext类图如下：


## Spring Boot 的核心注解

启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：

@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。

@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。

@ComponentScan：Spring组件扫描。



## JavaConfig

Spring JavaConfig 是 Spring 社区的产品，它提供了**配置 Spring IoC 容器的纯Java 方法**。因此它有助于避免使用 XML 配置(但是比较复杂还是建议使用xml来配置)。使用 JavaConfig 的优点在于：

（1）面向对象的配置。由于配置被定义为 JavaConfig 中的类，因此用户可以充分利用 Java 中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean 方法等。

（2）减少或消除 XML 配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在 XML 和 Java 之间来回切换。JavaConfig 为开发人员提供了一种纯 Java 方法来配置与 XML 配置概念相似的 Spring 容器。从技术角度来讲，只使用 JavaConfig 配置类来配置容器是可行的，但实际上很多人认为将JavaConfig 与 XML 混合匹配是理想的。

（3）类型安全和重构友好。JavaConfig 提供了一种类型安全的方法来配置 Spring容器。由于 Java 5.0 对泛型的支持，现在可以按类型而不是按名称检索 bean，不需要任何强制转换或基于字符串的查找。

## Spring Boot 自动配置原理

注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，

@EnableAutoConfiguration 给容器导入META-INF/spring.factories 里定义的自动配置类。

筛选有效的自动配置类。

每一个自动配置类结合对应的 xxxProperties.java 读取配置文件进行自动配置功能

##  Spring Boot 配置加载顺序

在 Spring Boot 里面，可以使用以下几种方式来加载配置。

1）properties文件；

2）YAML文件；

3）系统环境变量；

4）命令行参数；

等等……

## YAML

也是配置文件。与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML 文件就更加结构化，而且更少混淆。可以看出 YAML 具有分层配置数据。

### 优点：

1. 配置有序，在一些特殊的场景下，配置有序很关键
2. 支持数组，数组中的元素可以是基本数据类型也可以是对象
3. 简洁

## Spring Boot 是否可以使用 XML 配置

Spring Boot 推荐使用 Java 配置而非 XML 配置，但是 Spring Boot 中也可以使用 XML 配置，通过 @ImportResource 注解可以引入一个 XML 配置。

## Spring Data

Spring Data 是 Spring 的一个子项目。用于简化数据库访问，支持NoSQL 和 关系数据存储。其主要目标是使数据库的访问变得方便快捷。Spring Data 具有如下特点：

SpringData 项目支持 NoSQL 存储：

MongoDB （文档数据库）
Neo4j（图形数据库）
Redis（键/值存储）
Hbase（列族数据库）
SpringData 项目所支持的关系数据存储技术：

JDBC
JPA
Spring Data Jpa 致力于减少数据访问层 (DAO) 的开发量. 开发者唯一要做的，就是声明持久层的接口，其他都交给 Spring Data JPA 来帮你完成！Spring Data JPA 通过规范方法的名字，根据符合规范的名字来确定方法需要实现什么样的逻辑。

# 高并发下接口幂等性解决方案

## 背景 

```
  我们实际系统中有很多操作，是不管做多少次，都应该产生一样的效果或返回一样的结果。 例如1. 前端重复提交选中的数据，应该后台只产生对应这个数据的一个反应结果；2. 我们发起一笔付款请求，应该只扣用户账户一次钱，当遇到网络重发或系统bug重发，也应该只扣一次钱；3. 发送消息，也应该只发一次，同样的短信发给用户，用户会哭的；4. 创建业务订单，一次业务请求只能创建一个，创建多个就会出大问题等等很多重要的情况都需要幂等的特性来支持。 
```

## 幂等性概念 

​      幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()和setTrue()”函数就是一个幂等函数. 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 我的理解：**幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的** 

## 技术方案 

1. 查询操作：查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作；
2. 删除操作：删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) ；
3. 唯一索引，防止新增脏数据。比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录。要点：唯一索引或唯一组合索引来防止新增数据存在脏数据（当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可）；
4. token机制，防止页面重复提交。业务要求： 页面的数据只能被点击提交一次；发生原因： 由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交；解决办法： 集群环境采用token加redis(redis单线程的，处理需要排队)；单JVM环境：采用token加redis或token加jvm内存。处理流程：1. 数据提交前要向服务的申请token，token放到redis或jvm内存，token有效时间；2. 提交后后台校验token，同时删除token，生成新的token返回。token特点：要申请，一次有效性，可以限流。注意：redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用；
5. 悲观锁——获取数据的时候加锁获取。select * from table_xxx where id='xxx' for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用； 
6. 乐观锁——乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。乐观锁的实现方式多种多样可以通过version或者其他状态条件：1. 通过版本号实现update table_xxx set name=#name#,version=version+1 where version=#version#如下图(来自网上)；2. 通过条件限制 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# >= 0要求：quality-#subQuality# >= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高；

```
 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表
```

  7.分布式锁——还是拿插入数据的例子，如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供)；



# Mysql

## 索引

###  **二叉搜索树** 

索引的实现种类繁多，比如常见的有序数组、哈希表、树等，不同的结构都有自己的适用场景和局限性，在数据库领域中，**树结构**是被广泛使用。

我们先从最基本的**二叉搜索树**说起。

二叉搜索树的特点是：**父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值**，如下图所示

![1646872128265](C:\Users\37075\AppData\Roaming\Typora\typora-user-images\1646872128265.png)

 如果要查`id=4`的数据，按照图中的搜索顺序是`索引页A -> 索引页B -> 索引页D -> 数据页0`，时间复杂度是`O(log(N))`。 

![1646872152807](C:\Users\37075\AppData\Roaming\Typora\typora-user-images\1646872152807.png)

 也就是说，搜索速度与高度有关，树越高，性能越差，假设`100`万行的表，使用二叉树来存储，树高`20`，磁盘每次随机读一个数据块需要`10ms`左右，单独访问一个行可能需要`20`个`10ms`的时间，这个查询可真够慢的。 

###  **N叉搜索树** 

为了减少磁盘随机读`IO`，就必须控制好树的高度，那就不应该使用二叉树，而是使用**N叉树**，这里的`N`代表数据块的大小。

也就说，你一个索引页存储的数据越多，树会越矮，`InnoDB`中就使用了**B+树**来实现索引。

以`InnoDB`的整数字段建立索引为例。

一个页默认`16kb`,整数（`bigint`）字段的长度为`8B`，另外还跟着`6B`的指向其子树的指针，这意味着一个索引页可以存储接近`1200`条数据(`16kb/14B ≈ 1170`)。

如果这颗**B+树**高度为`4`，就可以存`1200`的`3`次方的值，差不多`17`亿条数据。

![1646872199283](C:\Users\37075\AppData\Roaming\Typora\typora-user-images\1646872199283.png)

 考虑到树根节点总是在内存中的，树的第二层很大概率也在内存中，所以一次搜索最多只需要访问`2`次磁盘`IO`。 

可能小伙伴会有疑问，为什么树的根节点与树的第二层会在内存，第三层、第四层却没在？

道理很简单，看下数据大小就清楚了

- **树的根节点就是****`16kb`的索引页，内存完全可以放下，里面存储`1200`条索引目录**
- **树的第二层总共是****`1200`个索引页，`1200 \* 16KB = 20M`内存依然放得下的**
- **树的第三层****`1200 \* 1200 = 144w`页，`144w \* 16kB = 23G`放内存就不合适了**
- **树的第四层就是数据页了，属于完整数据了，更不可能全部加载进内存了**

![1646872276891](C:\Users\37075\Desktop\Java\1646872276891.png)

最后再感受下索引搜索的流程。

假设`1`亿数据量的表，根据主键`id`建立了`B+`树索引，现在搜索`id=2699`的数据，流程如下

- **内存中直接获取树根索引页，对树根索引页内的目录进行二分查找，定位到第二层的索引页**
- **内存中直接获取第二层的索引页，对索引页内的目录进行二分查找，定位到第三层的索引页**
- **从磁盘加载第三层的索引页到内存中，对索引页内的目录进行二分查找，定位到第四层数据页**
- **从磁盘加载第四层的数据页到内存中，数据页变成缓存页，对缓存页中的目录进行二分查找，定位到具体的行数据**

## 数据页变成索引

### 数据页

 我们都知道平时执行`crud`的时候，都会从磁盘上加载数据页到`Buffer Pool`的缓存页里去，更新缓存页后，由异步线程刷回磁盘的数据页。 

 ![img](http://m.qpic.cn/psc?/V50pxxsX2KS5dX2GGwiD0GONdJ1ifkgp/TmEUgtj9EK6.7V8ajmQrEM2r8SO8MEEer1Vn.AIOxJTnTRnCgEAe04fTlwdWs3e5Pl0aawlPz0QOyqHfEwNI67ZH6hxg.vyr1RY9fPxr8.s!/b&bo=7gLDAgAAAAADNz8!&rf=viewer_4) 

## MVCC

**数据库并发场景有三种，分别为：**

- `读-读`：不存在任何问题，也不需要并发控制
- `读-写`：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
- `写-写`：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

**MVCC**在**MySQL InnoDB**中的实现主要是为了提高数据库**并发性能**，用更好的方式去**处理读-写冲突**，因为正常我们对数据库写操作的话，会加锁，加锁以后就不可以读了。



说到MVCC，首先有两个概念

1. 当前读

2. 快照读

   

### 当前读

像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

### 快照读

像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。

**说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是`快照读`, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现**

### 当前读，快照读和MVCC的关系

准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念
而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。而相对而言，**当前读就是悲观锁的具体功能实现**
要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。**MVCC模型在MySQL中的具体实现则是由 3个隐式字段，undo日志 ，Read View 等去完成的**

### 实现原理

#### **隐式字段**

DB_TRX_ID
6byte，最近修改(修改/插入)**事务ID**：记录创建这条记录/最后一次修改该记录的事务ID(查询操作id是不会变的，只有增删改操作会+1)
DB_ROLL_PTR
7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）
DB_ROW_ID
6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
**实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了**

#### **undo日志**

就是当一个事务对一行数据进行修改的时候，会先把当前这行数据拷贝undo log日志里，然后再对当前行做出修改，修改完以后让这行的回滚指针指向刚刚拷贝到undo log日志里面的副本记录。不同事务或者相同事务的对同一记录的修改，会导致该记录的`undo log`成为一条记录版本线性表，既链表，`undo log`的链首就是最新的旧记录，链尾就是最早的旧记录

#### **Read View(读视图)**

什么是Read View，说白了Read View就是**事务进行快照读操作的时候生产的读视图(Read View)**，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，**记录并维护系统当前活跃事务的ID**(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)

所以我们知道 Read View主要是用来做**可见性判断的**, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。

Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本

#### 举例

比如说有1，2，3，4。这么四个事务。现在事务2对某行的数据进行了快照读。然后数据库就为这行数据生成一个读视图。我们假设当前快照读的这个事务的id是2。事务1和事务三都处于活跃状态(就是还没有提交事务)，事务4在事务2进行快照读的前一刻提交更新了。读视图会记录当前活跃事务的最小事务id，和事务最大id(也就是下一个即将要分配的事务id，这里就是4+1=5)，因为当前的事务2就是查看这行数据，所以事务的id依然标记的是4。先拿4和最小的事务id去做一个比较。如果比最小的事务id要小，就说明当前的数据是在快照读之前就已经提交了的。所以这行数据对当前事务是一个可见的状态。如果大于的话再去判断当前的事务id4是否大于等于5，如果大于等于5就说明当前所在的这个行记录是在读视图之后才出现的，那就去undo log日志中读取上一个版本的记录接着做上面这些判断。那对当前事务是不可见的。如果比5小的话，接下来要判断这个事务id4是不是在读视图维护的活跃事务id中，如果在的话说明我生成读视图的时候你这个事务还是在活跃的这么一个状态，还没有commit，那你修改的数据对我也是不可见的，如果发现当前事务id不在活跃的事务id中，那就说明在我生成快照读的时候你已经commit了事务，那这行数据对我来说就是可见的。

#### RC,RR

RC隔离级别每次读都进行一次快照和读视图，而在RR隔离级别下，只在第一次读的时候会产生读视图，以后的都操作用的都是第一次的读视图。

RR级别下，通过MVCC保证**同一事务内两次快照读**不出现幻读，**通过临键锁(Next-Key)保证同一事务内两次当前读不出现幻读**。但是如果是你先快照度一次，再当前读一次，如果两次读期间别的事务插入了数据并提交了的话，两次读的结果就可能不一致出现幻读.

#### 记录锁（Record Locks）

行锁在 InnoDB 中是基于`索引`实现的，所以一旦某个加锁操作没有使用索引，那么该锁就会退化为`表锁`。

记录锁就是为**某行**记录加锁，它`封锁该行的索引记录`：

```sql
SELECT * FROM table WHERE id = 1 FOR UPDATE;
```

id 为 1 的记录行会被锁住。

需要注意的是：`id` 列必须为`唯一索引列`或`主键列`，否则上述语句加的锁就会变成`临键锁`。

同时查询语句必须为`精准匹配`（`=`），不能为 `>`、`<`、`like`等，否则也会退化成`临键锁`

#### 间隙锁（Gap Locks）

**间隙锁**基于`非唯一索引`，它`锁定一段范围内的索引记录`。**使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据**。

```sql
SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE;
```

即所有在`（1，10）`区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。除了手动加锁外，在执行完某些 SQL 后，InnoDB 也会自动加**间隙锁**

#### 临键锁（Next-Key Locks）

Next-Key 可以理解为一种特殊的**间隙锁**，也可以理解为一种特殊的**算法**。通过**临建锁**可以解决`幻读`的问题。 每个数据行上的`非唯一索引列`上**都会存在**一把**临键锁**，当某个事务持有该数据行的**临键锁**时，会锁住一段**左开右闭区间**的数据。

需要强调的一点是，`InnoDB` 中`行级锁`是基于索引实现的，**临键锁**只与`非唯一索引列`有关，在`唯一索引列`（包括`主键列`）上不存在**临键锁**。

在根据`非唯一索引` 对记录行进行 `UPDATE \ FOR UPDATE \ LOCK IN SHARE MODE` 操作时，InnoDB 会获取该记录行的`临键锁` ，并同时获取该记录行下一个区间的`间隙锁`。

![image-20210416095343694](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416095343694.png)

![image-20210416095407308](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416095407308.png)

会阻塞其他的sql语句执行。

## 主从复制

### 优点

做数据的热备，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。
架构的扩展。业务量越来越大,I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的评率，提高单个机器的I/O性能。
读写分离，使数据库能支持更大的并发。在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁，保证了前台速度。

 1--在从服务器可以执行查询工作(即我们常说的读功能)，降低主服务器压力;（主库写，从库读，降压）
 2--在从主服务器进行备份，避免备份期间影响主服务器服务;（确保数据安全）
 3--当主服务器出现问题时，可以切换到从服务器。（提升性能）

### 具体过程

1、主机会开启一个binlog的二进制日志，记录一些修改数据库的事件

2、从机会开一个线程，通过mysql协议，请求获得主机上的二进制日志文件

3、主机开启一个dump Thread先检查一下自己的二进制文件中的事件，会和从机的请求位置做一个对比，如果不带请求位置参数，则主节点就会从第一个日志文件中的第一个事件一个一个发送给从节点。

4、从节点接收到主节点发送过来的数据，把它放置到中继日志(relay log)文件中，并记录该次请求到主节点的具体哪个二进制日志文件的哪个位置。

5、、从节点启动另外一个线程(sql Thread)，把中继日志中的事件读取出来，并在本地再执行一次。

复制过程中线程的作用：

主节点dump Thread：为每个从节点的 I/O Thread 启动一个 dump 线程，用于向从节点发送二进制事件。

从节点I/O Thread：从主节点请求二进制日志事件，并保存在中继日志中。

sql Thread：从中继日志中读取日志事件，在本地完成执行。

从节点需要建立二进制日志文件吗？

视情况而定，如果从节点需要作为其他节点的主节点时，是需要开启二进制日志文件的，这种情况称之为级联复制。如果只是作为从节点，则不需要建立二进制文件。

## redolog日志

主要是为了保持我们数据库持久性的这么一个操作，比如我有500块钱，我朋友也有500块钱，现在我给他转账100块钱，但是中间可能出现了网络的问题，导致事务失败了，我的钱扣了，但是我朋友的账户上却没有加钱，那这样的话redolog日志就起到作用了，这是我理解的这么一个redolog

我了解到redo log是InnoDB存储引擎层的日志，又称`重做日志文件`，用于`记录事务操作的变化`，`记录的是数据修改之后的值，不管事务是否提交都会记录下来`。在实例和介质失败（media failure）时，redo log文件就能派上用场，如`数据库掉电`，`InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。`

`在一条更新语句进行执行的时候，`InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到`WAL`即`Write Ahead logging`技术，他的关键点是先写日志，再写磁盘。

有了redo log日志，那么在数据库进行异常重启的时候，可以根据redo log日志进行恢复，也就达到了`crash-safe`。

## binlog日志模块

这个可以往主从复制上面扯

binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑，依靠binlog是没有`crash-safe`能力的

![image-20210416153510608](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416153510608.png)

## sql调优

### 避免不走索引的场景

1. 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。如下：

SELECT * FROM t WHERE username LIKE '%陈%'
优化方式：尽量在字段后面使用模糊查询。如下：

```sql
SELECT * FROM t WHERE username LIKE '陈%'
```


如果需求是要在前面使用模糊查询，

使用MySQL内置函数INSTR(str,substr) 来匹配，作用类似于java中的indexOf()，查询字符串出现的角标位置
2. 尽量避免使用in 和not in，会导致引擎走全表扫描。如下：

SELECT * FROM t WHERE id IN (2,3)
优化方式：如果是连续数值，可以用between代替。如下：

```sql
SELECT * FROM t WHERE id BETWEEN 2 AND 3
```

如果是子查询，可以用exists代替。详情见《MySql中如何用exists代替in》如下：

```sql
-- 不走索引
select * from A where A.id in (select id from B);
-- 走索引
select * from A where exists (select * from B where B.id = A.id);
```

3. 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描。如下：

```sql
SELECT * FROM t WHERE id = 1 OR id = 3
优化方式：可以用union代替or。如下：

SELECT * FROM t WHERE id = 1
   UNION
SELECT * FROM t WHERE id = 3
```

**4. 尽量避免进行null值的判断，会导致数据库引擎放弃索引进行全表扫描。**如下：

```sql
SELECT * FROM t WHERE score IS NULL
```

优化方式：可以给字段添加默认值0，对0值进行判断。如下：

```sql
SELECT * FROM t WHERE score = 0
```

5.尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描。

可以将表达式、函数操作移动到等号右侧。如下：

```sql
-- 全表扫描
SELECT * FROM T WHERE score/10 = 9
-- 走索引
SELECT * FROM T WHERE score = 10*9

```

**6. 当数据量大时，避免使用where 1=1的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描。**如下：

```sql
SELECT username, age, sex FROM T WHERE 1=1
```

优化方式：用代码拼装sql时进行判断，没 where 条件就去掉 where，有where条件就加 and。

**7. 查询条件不能用 <> 或者 !=**

使用索引列作为条件进行查询时，需要避免使用<>或者!=等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替。

### SELECT语句其他优化

1. 避免出现select *

首先，select * 操作在任何类型数据库中都不是一个好的SQL编写习惯。

使用select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的I/O,内存和CPU消耗。

建议提出业务实际需要的列数，将指定列名以取代select *


2.多表关联查询时，小表在前，大表在后。

在MySQL中，执行 from 后的表关联查询是从左往右执行的（Oracle相反），第一张表会涉及到全表扫描，所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前100行就符合返回条件并return了。

例如：表1有50条数据，表2有30亿条数据；如果全表扫描表2，你品，那就先去吃个饭再说吧是吧。

3.使用表的别名

当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。

### 增删改 DML 语句优化

1. 大批量插入数据

如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二)。这比使用分开INSERT语句快（方法一），一般情况下批量插入效率有几倍的差别。

方法一：

```sql
insert into T values(1,2); 

insert into T values(1,3); 

insert into T values(1,4);
```


方法二：

```sql
sqlInsert into T values(1,2),(1,3),(1,4); 
```

选择后一种方法的原因有三。 

- 减少SQL语句解析的操作，MySQL没有类似Oracle的share pool，采用方法二，只需要解析一次就能进行数据的插入操作；
- 在特定场景可以减少对DB连接次数
- SQL语句较短，可以减少网络传输的IO。

2. 适当使用commit

适当使用commit可以释放事务占用的资源而减少消耗，commit后能释放的资源如下：

事务占用的undo数据块；
事务在redo log中记录的数据块； 
释放事务施加的，减少锁争用影响性能。特别是在需要使用delete删除大量数据的时候，必须分解删除量并定期commit。

3. 避免重复查询更新的数据

针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。

例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现：

Update t1 set time=now() where col1=1; 

Select time from t1 where id =1;

# 缓存一致性

## 缓存TTL

简单直接又暴力的方法，如果有些数据不重要，我们读完一次数据到缓存后设置个TTL即可，等待超时后缓存自动从数据库读取下数据。

## **先更新数据库，再更新缓存**

这套方案，大家是普遍反对的。为什么呢？有如下两点原因。
- 原因一（线程安全角度）
同时有请求A和请求B进行更新操作，那么会出现
（1）线程A更新了数据库
（2）线程B更新了数据库
（3）线程B更新了缓存
（4）线程A更新了缓存

这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
- 原因二（业务场景角度）
有如下两点：
（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
（2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

接下来讨论的就是争议最大的，先删缓存，再更新数据库。还是先更新数据库，再删缓存的问题。


## **先删缓存，再更新数据库**

同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:
（1）请求A进行写操作，删除缓存
（2）请求B查询发现缓存不存在
（3）请求B去数据库查询得到旧值
（4）请求B将旧值写入缓存
（5）请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。
那么，如何解决呢？**采用延时双删策略**

伪代码如下

```java
public void write(String key,Object data){
        redis.delKey(key);

        db.updateData(data);

        Thread.sleep(1000);

        redis.delKey(key);

    }

```

转化为中文描述就是
（1）先淘汰缓存
（2）再写数据库（这两步和原来一样）
（3）休眠1秒，再次淘汰缓存

**这么做，可以将1秒内所造成的缓存脏数据，再次删除。**
**那么，这个1秒怎么确定的，具体该休眠多久呢？**
针对上面的情形，我们应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

**如果你用了mysql的读写分离架构怎么办？**
ok，在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。
（1）请求A进行写操作，删除缓存
（2）请求A将数据写入数据库了，
（3）请求B查询缓存发现，缓存没有值
（4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值
（5）请求B将旧值写入缓存
（6）数据库完成主从同步，从库变为新值
上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。

**采用这种同步淘汰策略，吞吐量降低怎么办？**

那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。

## **先更新数据库，再删缓存**

一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生
（1）缓存刚好失效
（2）请求A查询数据库，得一个旧值
（3）请求B将新值写入数据库
（4）请求B删除缓存
（5）请求A将查到的旧值写入缓存

意思就是写请求比读请求快，在删除完以后读请求才把读取的旧值放入缓存，这样还是会导致脏数据，这种情景的发生条件就是写请求比读请求快，**可是数据库的读操作的速度远快于写操作的**（不然做读写分离也没什么意义，做读写分离的意义就是因为读操作比较快，耗资源少）。

**但是问题就是缓存失败的问题都无法解决**

![image-20210910200535402](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910200535402.png)

流程如下所示
（1）更新数据库数据；
（2）缓存因为种种问题删除失败
（3）将需要删除的key发送至消息队列
（4）自己消费消息，获得需要删除的key
（5）继续重试删除操作，直到成功



然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。
方案二：

![image-20210910200611792](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910200611792.png)

流程如下图所示：
（1）更新数据库数据
（2）数据库会将操作信息写入binlog日志当中
（3）订阅程序提取出所需要的数据以及key
（4）另起一段非业务代码，获得该信息
（5）尝试删除缓存操作，发现删除失败
（6）将这些信息发送至消息队列
（7）重新从消息队列中获得该数据，重试操作。

上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能



# 一致性哈希

在分布式集群中，经常基于主从复制，读写分离的架构，然后使用负载均衡算法，将数据尽量分摊到各个节点，充分发挥分布式的优势，来提升系统缓存访问的性能。

我们在查找数据的时候如果没有固定的规则，去遍历所有的服务器，肯定是浪费时间，那如果我们使用hash的方式，数据就可以放到固定的服务器里面，查找定位也就快了

但是这种简单的方式也存在致命的问题，就是服务器扩容或者缩容的时候，容易造成缓存未命中的现象，比如原来的hash算法是对服务器数量进行取余的操作，现在多加了一台服务器，数量变了，再对数据进行同样的hash算法，肯定会导致不命中缓存的现象，严重的话可能会造成缓存穿透。

这种问题的解决方案也很有针对性就是成倍的扩容，但是这肯定是浪费资源和钱的，

**那另外一种解决方案就是一致性哈希**

一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下：  

![image-20210910194114193](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194114193.png)

整个空间按**顺时针方向组织**，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，**我们把这个由2^32个点组成的圆环称为Hash环。**

**下一步将各个服务器使用Hash进行一个哈希**，具体可以选择**服务器的IP或主机名**作为**关键字**进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将四台服务器使用IP地址哈希后在环空间的位置如下： 

![image-20210910194215516](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194215516.png)

接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，**从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！**

例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： 
![image-20210910194303380](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194303380.png)



根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。



## **一致性Hash算法的容错性和可扩展性**

现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。**一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器**（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如下所示：

![image-20210910194425259](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194425259.png)

下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：

![image-20210910194456921](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194456921.png)

此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！**一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器**（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。

综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

## **Hash环的数据倾斜问题**

一致性Hash算法在**服务节点太少时**，容易因为节点分部不均匀而造成**数据倾斜**（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： 



![image-20210910194609567](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194609567.png)

此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，**一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。**



例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点： 



![image-20210910194659508](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910194659508.png)

同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。



# Redis

## Redis的定义

首先redis是用`c语言编写`的，这一点其实我们是可以从redis的那五种基本数据类型的代码可以看出来，用的是定义一个结构体，我如果没记错这个就是c语言的标准代码，有些记不清c了，大一下学期的时候学的c语言。然后redis是纯基于内存操作的。把数据放到了内存中，和传统的mysql相比读取数据更快，因为mysql的数据是存放在磁盘上的，那从磁盘上读取数据再到内存操作，我了解的是磁盘的数据读写速度和cpu对数据的处理速度不是一个数量级的。我记得因为从磁盘读取数据的话会有一个寻道时间，磁盘上有一个一个的磁道，我大概记得寻道的算法中有scan算法，就是电梯扫描，从磁盘的一个方向寻找，这个方向没有数据了就换一个方向扫描。还有一个好像是最短寻道时间的这个一个算法，每次都是寻找离当前磁道最近的这么一个数据。大概是这样，具体不太记得了。

还有就是key-value型的数据库。非关系型（NoSQL）的键值对数据库。

Redis 可以存储键和五种不同类型的值之间的映射。`键的类型只能为字符串`，值支持五种数据类型：字符串(string)、链表(list)、集合(set)、散列表(hash)、有序集合(zset)。

## Redis的使用场景

（1）、 会话缓存（Session Cache）
最常用的一种使用 Redis 的情景是会话缓存（session cache）。 用 Redis 缓存会话比其他
存储（如 Memcached） 的优势在于： Redis 提供持久化。 当维护一个不是严格要求一致性
的缓存时， 如果用户的购物车信息全部丢失， 大部分人都会不高兴的， 现在， 他们还会这样
吗？
幸运的是， 随着 Redis 这些年的改进， 很容易找到怎么恰当的使用 Redis 来缓存会话的文
档。 甚至广为人知的商业平台 Magento 也提供 Redis 的插件。
（2）、 全页缓存（FPC）
除基本的会话 token 之外， Redis 还提供很简便的 FPC 平台。 回到一致性问题， 即使重启
了 Redis 实例， 因为有磁盘的持久化， 用户也不会看到页面加载速度的下降， 这是一个极
大改进， 类似 PHP 本地 FPC。
再次以 Magento 为例， Magento 提供一个插件来使用 Redis 作为全页缓存后端。
此外， 对 WordPress 的用户来说， Pantheon 有一个非常好的插件 wp-Redis， 这个插件
能帮助你以最快速度加载你曾浏览过的页面。
（3）、 队列
Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个
很好的消息队列平台来使用。 Redis 作为队列使用的操作， 就类似于本地程序语言（如
Python） 对 list 的 push/pop 操作。
如果你快速的在 Google 中搜索“Redis queues”， 你马上就能找到大量的开源项目， 这些
项目的目的就是利用 Redis 创建非常好的后端工具， 以满足各种队列需求。 例如， Celery
有一个后台就是使用 Redis 作为 broker， 你可以从这里去查看。
（4）、 排行榜/计数器
Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted
Set） 也使得我们在执行这些操作的时候变的非常简单， Redis 只是正好提供了这两种数据
结构。 所以， 我们要从排序集合中获取到排名最靠前的 10 个用户–我们称之为
“user_scores”， 我们只需要像下面一样执行即可：
当然， 这是假定你是根据你用户的分数做递增的排序。 如果你想返回用户及用户的分数， 你
需要这样执行：
ZRANGE user_scores 0 10 WITHSCORES
Agora Games 就是一个很好的例子， 用 Ruby 实现的， 它的排行榜就是使用 Redis 来存储
数据的， 你可以在这里看到。
（5）、 发布/订阅
最后 是 Redis 的发布/订阅功能。 发布/订阅的使用场景确实非
常多。 我已看见人们在社交网络连接中使用， 还可作为基于发布/订阅的脚本触发器， 甚至
用 Redis 的发布/订阅功能来建立聊天系统。

## Memcached VS Redis

![image-20210417194933389](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417194933389.png)

### 数据结构

Memcached：主要支持简单的 key-value 数据结构，类似于 Redis 里的 String。

Redis：总共有9种，常见的5种，高级的4种：

String：字符串，最基础的数据类型。

List：列表。

Hash：哈希对象。

Set：集合。

Sorted Set：有序集合，Set 的基础上加了个分值。

HyperLogLog：通常用于基数统计。使用少量固定大小的内存，来统计集合中唯一元素的数量。统计结果不是精确值，而是一个带有0.81%标准差（standard error）的近似值。所以，HyperLogLog适用于一些对于统计结果精确度要求不是特别高的场景，例如网站的UV统计。

Geo：redis 3.2 版本的新特性。可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作：获取2个位置的距离、根据给定地理位置坐标获取指定范围内的地理位置集合。

Bitmap：位图。

Stream：主要用于消息队列，类似于 kafka，可以认为是 pub/sub 的改进版。提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。

### IO

Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。

### 数据存储

Memcached：数据全部存在内存中，重启实例会导致数据全部丢失

Redis：通常全部存在内存中，同时支持持久化到磁盘上

### 持久化

Memcached：不支持

Redis：AOF、RDB、混合持久化

### 灾难恢复

Memcached：实例挂掉后，数据不可恢复

Redis：实例挂掉后可以通过RDB、AOF恢复 ，但是还是会有数据丢失问题

### 过期键删除策略

常见的有以下三种：

 定时删除：在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，对 CPU 时间最不友好。

 惰性删除：放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。对 CPU 时间最优化，对内存最不友好。

 定期删除：每隔一段时间，默认100ms，程序就对数据库进行一次检査，删除里面的过期键。至 于要删除多少过期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。

 Memcached：惰性删除

 Redis：惰性删除+定期删除

### 内存驱逐（淘汰）策略

当内存空间已经用满时，服务实例将将根据配置的驱逐策略，进行相应的动作。

 memcached：主要为 LRU 算法

 redis：当前总共有以下8种：

noeviction：默认策略，不淘汰任何 key，直接返回错误

allkeys-lru：在所有的 key 中，使用 LRU 算法淘汰部分 key

allkeys-lfu：在所有的 key 中，使用 LFU 算法淘汰部分 key

allkeys-random：在所有的 key 中，随机淘汰部分 key

volatile-lru：在设置了过期时间的 key 中，使用 LRU 算法淘汰部分 key

volatile-lfu：在设置了过期时间的 key 中，使用 LFU 算法淘汰部分 key

volatile-random：在设置了过期时间的 key 中，随机淘汰部分 key

volatile-ttl：在设置了过期时间的 key 中，挑选 TTL（time to live，剩余时间）短的 key 淘汰

### 性能

首先，影响性能比较的因素有很多，网络带宽、CPU、内存等等，所以其实很多测试并不能完全说明问题，可能在这个条件下 Redis 快，而在另一个条件下是 Memcached 快。

 所以两者的性能比较其实可以算一个比较开放的话题，在面试中，你只要能够自圆其说，说服面试官，那就是OK的。

 Redis 作者 antirez 在 12 年左右在 Stack Overflow 上谈过两者的性能问题，他是这么说的：由于 Redis 只使用单核，而 Memcached 可以使用多核，所以在比较上：在处理小数据时，平均每一个核上 Redis 比 Memcached 性能更高，而在 100k 左右的大数据时， Memcached 性能要高于 Redis。

 antirez 毕竟是大牛，所以他的这个说法，大部分人都是认同的，所以在面试中这么回答是可以的。

 antirez 的这个说法是按“CPU 单核”维度来比较，但是我们在实际的使用中，肯定是按“实例”维度来使用，所以接下来我们探讨下对于两者在“实例”维度的比较。

 按“实例”维度进行比较时，个人认为由于 Memcached 多线程的特性，在 Redis 6.0 之前，通常情况下 Memcached 性能是要高于 Redis 的，同时实例的 CPU 核数越多，Memcached 的性能优势越大。

 而在 Redis 6.0 支持 I/O 多线程后，当 Redis 关闭持久化后，两者在性能上可能会比较接近。


### 技术选型、如何选择

看完上面的比较，其实不难做出选择，99%的人、场景，或者说 Redis 能支持的场景，使用 Redis 基本不会有问题。

 而且就最近几年的发展来看，Redis 可谓风光无限，而 Memcached 则是已经逐渐跟不上 Redis 脚步了，这也侧面反映了当前大家的选择都是趋向于使用 Redis。

 而关于使用 Memcached 的场景，我自己了解到的一些线上真实使用场景都是对于性能有非常高的要求。

 Redis 6.0 支持的 I/O 阶段多线程目前根据官方说法至少能提升性能1倍，随着 Redis 在性能上的不断优化，可能后续 Memcached 的使用场景会越来越少了。






## 为什么要用缓存

我是觉得一个是查找数据比较快，不用去数据库中查找，因为mysql中数据和索引都是存放在物理磁盘上的。先要在磁盘上找到数据。再有就是为我们数据库减轻压力。

### 高性能

假设这么个场景，有个操作，一个请求过来，耗时 600ms 操作 mysql查出来一个结果，但是这个结果可能接下来几个小时都不会变了，或者变了也可以不会立即反馈给用户。那么此时咋办？

将折腾 600ms 查出来的结果放入缓存里，一个 key 对应一个 value，下次查找时不经过 mysql，直接从缓存里通过一个 key 查出来一个 value，2ms 搞定，性能提升 300 倍。

所以对于一些需要复杂操作耗时查出来的结果，确定后面不怎么变化，但是有很多读请求，直接将查询出来的结果放在缓存中，后面直接读缓存就好。

### 高并发

mysql 数据库对于高并发来说天然支持不好，mysql 单机支撑到 2000QPS(qps意思是每秒查询率，是`计算机中服务器每秒能够相应的查询次数`，qps是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。) 也开始容易报警了。

所以若是`系统高峰期一秒钟有1万个请求`，那么一个 mysql 单机绝对会死掉。这个时候就只能上缓存，把很多数据放入缓存，别放入 mysql。缓存功能简单，说白了就是 key-value 式操作，单机支撑的并发量一秒可达几万十几万，单机承载并发量是 mysql 单机的几十倍。

缓存是走内存的，内存天然就支撑高并发。

## 分布式缓存的问题

缓存一致性，雪崩，穿透，击穿。

![image-20210417175726741](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417175726741.png)





## 缓存分哪几种

缓存是高并发场景下提高热点数据访问性能的一个有效手段，在开发项目时会经常使用到。

其实缓存的话，我了解到的是分为本地缓存和分布式缓存和多级缓存。

#### 本地缓存：

**本地缓存**就是在进程的内存中进行缓存，以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，`生命周期随着 jvm 的销毁而结束`，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。

本地缓存是内存访问，`没有远程交互开销，性能最好`，但是受限于单机容量，一般缓存较小且无法扩展。

#### 分布式缓存：

**分布式缓存**可以很好得解决这个问题。

分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。

#### 多级缓存：

为了平衡这种情况，实际业务中一般采用**多级缓存**，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。

在目前的一线大厂中，这也是最常用的缓存方案，单考单一的缓存方案往往难以撑住很多高并发的场景。



## Redis优点

- 记得比较清楚的是好像官方给出的关于读写的性能，当时百度百科给出的是一个50个并发执行十万个请求，然后读的速度是十一万次每秒，写的速度是八万一千次每秒。
- 支持数据持久化，支持AOF和RDB两种持久化方式。因为redis的数据是放在内存中的，一旦断电或者服务宕机了或者其他一些特殊情况内存数据会丢失。那肯定要把数据持久化到磁盘上去。
- 支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。->关于事务可以提一下lua脚本。把多个命令封装成一个脚本来完成原子性的这么一个操作。
- 支持的数据结构比较多，除了支持string类型的value外还支持hash、set、zset、list等数据结构。
- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。

## Redis缺点

- 数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
- Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。
- Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

## 为什么Redis做缓存更好

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；

2、redis的数据结构是经过特殊处理的，比如string是SDS简单动态字符串，还有zset底层使用了跳表和压缩列表。

3、单线程，避免了上下文切换的这么一个耗时。

4、使用IO多路复用

## 底层数据结构以及应用场景

### string

#### 数据结构：

![image-20210417180053112](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417180053112.png)

字符串类型是redis最基础的数据结构，首先键是字符串类型，而且其他几种结构都是在字符串类型基础上构建的

1. 字符串类型实际上可以是字符串
2. （简单的字符串、复杂的字符串（xml、json）、数字（整数、浮点数）、二进制（图片、音频、视频）），
3. 但最大不能超过512M。

其实关于string的底层的数据结构我还是进行了一些了解。

在redis中没有直接使用传统的c语言的字符串。而是定义了一个SDS简单动态字符串的这样一个数据结构。

里面主要有一个char类型的buf数组，用来保存字符串。还有一个int类型的len用来表示buf数组中已经使用多少字节的数量，就是等于SDS所保存的字符串的长度。最后一个是free，用来记录buf数组中还有多少字节没有使用。

#### SDS和c语言的字符串的区别

1、SDS我们直接通过len属性就可以直接的获得到字符串的长度。时间复杂度是o(1)。

c语言的话是需要遍历这个字符串。时间复杂度是o(n)

2、SDS不会出现缓冲区溢出

因为c语言的字符串如果没有重新分配空间的话上来就直接对字符串进行一个修改。可能会造成数据溢出。

而当我们调用SDS的API对SDS进行修改的时候，会先检查SDS的空间是否满足修改的这个需求，如果不满足的话，就会自动的将SDS空间扩展到需要的大小

3、减少内存重新分配的次数

SDS其实是通过空间预分配和惰性空间释放基于这两种优化策略来减少内存的重新分配次数。

首先空间预分配通过额外分配但未使用的空间，优化了SDS字符串的增长操作。减少了连续执行字符串增长操作所需的内存分配次数。

还有就是惰性空间释放，当SDS缩短的时候，我们的程序不会立即就回收缩短后多出来的空间，而是使用free属性靖这些字节的数量记录起来。

4、二进制安全

我们在网络上传输数据的时候都是先把对象转换为二进制进行传输，这个过程叫序列化，然后服务器那边再把二进制转换成对象，这个过程叫反序列化。

还有一个问题是我记得c语言的字符串是遇到0结束，那这样就有一个问题，在存一些静态文件，如图片文件、CSS文件等转换成二进制的时候可能中间就会出0，c语言字符串就无法保证这个的安全性，因为你在第一个遇到0的地方停止，就会造成数据丢失等一些问题

- String类型是二进制安全的，可以把图片和视频文件保存在String中。
- 因为有了对字符串长度定义len, 所以在处理字符串时候不会以零值字节(\0)为字符串结尾标志.
- 进制安全就是输入任何字节都能正确处理, 即使包含零值字节.

#### 操作

![image-20210417173504959](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417173504959.png)

#### 应用场景

1. 
   缓存功能：字符串最经典的使用场景，`redis最为缓存层`，`Mysql作为储存层`，绝大部分请求数据都是redis中获取，由于redis具有支撑高并发特性，所以缓存通常能起到`加速读写和降低 后端压力的作用`。
2. 计数器：许多运用都会使用redis作为计数的基础工具，他可以实现快速计数、查询缓存的功能。同时数据可以一步落地到其他的数据源。 如：视频播放数系统就是使用redis作为视频播放数计数的基础组件。
3. 共享session：出于负载均衡的考虑，分布式服务会将用户信息的访问均衡到不同服务器上， 用户刷新一次访问可能会需要重新登录，为避免这个问题可以用redis将用户session集中管理，在这种模式下只要保证redis的高可用和扩展性的，每次获取用户更新或查询登录信息， 都直接从redis中集中获取。
4. 限速：处于安全考虑，每次进行登录时让用户输入手机验证码，为了短信接口不被频繁访问，会限制用户每分钟获取验证码的频率。



### list

#### 数据结构:

![image-20210417180028394](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417180028394.png)

Redis的列表允许从序列的`两端推入或者弹出元素`，列表由多个字符串值组成的有序可重复的序列，是链表结构，所以向列表两端添加元素的时间复杂度为0(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是极快的。List中可以包含的最大元素数量是4294967295。

#### 应用场景

List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息，没有消息就sleep一会。(也就是简单的消息队列)。redis的lpush+brpop命令组合即可实现阻塞队列，没消息就阻塞，知道队列里面有消息才被唤醒。不过最好使用 Kafka、RabbitMQ 等消息中间件。

可以通过 **List** 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。

比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

比如可以搞个简单的消息队列，从 List 头怼进去，从 List 屁股那里弄出来。

文章列表或者数据分页展示的应用。

比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用**Redis**的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。

#### 操作

![image-20210417184747292](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417184747292.png)

### hsah

#### 数据结构

![image-20210417181317849](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417181317849.png)

渐进式hash

### set

**Set** 是无序集合，会自动去重的那种。

直接基于 Set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 JVM 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于Redis进行全局的 Set 去重。

可以基于 Set 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。

反正这些场景比较多，因为对比很快，操作也简单，两个查询一个Set搞定。


#### 操作

![image-20210417184816727](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417184816727.png)



### Sorted Set

**Sorted set** 是排序的 **Set**，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

有序集合的使用场景与集合类似，但是set集合不是自动有序的，而**Sorted set**可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择**Sorted set**数据结构作为选择方案。

排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

用**Sorted Sets**来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

微博热搜榜，就是有个后面的热度值，前面就是名称

![image-20210417185036737](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417185036737.png)

### HyperLogLog

通常用于基数统计。使用少量固定大小的内存，来统计集合中唯一元素的数量。统计结果不是精确值，而是一个带有0.81%标准差（standard error）的近似值。所以，HyperLogLog适用于一些对于统计结果精确度要求不是特别高的场景，例如网站的UV统计。

### Geo

redis 3.2 版本的新特性。可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作：获取2个位置的距离、根据给定地理位置坐标获取指定范围内的地理位置集合。

### Bitmap

位图。

### Stream

主要用于消息队列，类似于 kafka，可以认为是 pub/sub 的改进版。提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。



## RDB

 描述：类似于**快照**。在某个时间点，将 Redis 在内存中的数据库状态（**数据库的键值对等信息**）保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是**经过压缩的二进制文件。**

 命令：有两个 Redis 命令可以用于生成 RDB 文件，一个是 **SAVE**，另一个是 **BGSAVE**。

 开启：使用 save point 配置，满足 save point 条件后会触发 BGSAVE 来存储一次快照，这边的 save point 检查就是在上文提到的 serverCron 中进行。 

 save point 格式：save <seconds> <changes>，含义是 Redis 如果在 seconds 秒内数据发生了 changes 次改变，就保存快照文件。例如 Redis 默认就配置了以下3个： 

```bash
save 900 1 #900秒内有1个key发生了变化，则触发保存RDB文件
save 300 10 #300秒内有10个key发生了变化，则触发保存RDB文件
save 60 10000 #60秒内有10000个key发生了变化，则触发保存RDB文件
```

  **SAVE**：生成 RDB 快照文件，但是会**阻塞主进程**，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。 

 **BGSAVE**：fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求 

 ![img](https://img-blog.csdnimg.cn/img_convert/4408a7a0979fc085e55a00517ca18fc6.png) 

fork：在 Linux 系统中，调用 fork() 时，会创建出一个新进程，称为子进程，**子进程会拷贝父进程的 page table**。如果进程占用的内存越大，进程的 page table 也会越大，那么 fork 也会占用更多的时间。**如果 Redis 占用的内存很大，那么在 fork 子进程时，则会出现明显的停顿现象。**

###  RDB 的优点： 

1）RDB 文件是是经过压缩的二进制文件，占用空间很小，它保存了 Redis 某个时间点的数据集，很适合用于做备份。 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。

 

2）RDB 非常适用于灾难恢复（disaster recovery）：**它只有一个文件，并且内容都非常紧凑**，可以（在加密后）将它传送到别的数据中心。

 

3）RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。

 

4）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

### RDB 的缺点：

1）RDB 在服务器故障时容易造成数据的丢失。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。所以通常可能设置至少5分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失5分钟数据。

 

2）RDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，fork 可能会非常耗时，造成 Redis 停止处理服务N毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。

 

3）Linux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的2倍。刚 fork 时，主进程和子进程共享内存，但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的2倍。



### Linux中CopyOnWrite实现原理

fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。




## AOF

描述：保存 Redis 服务器所执行的所有写操作命令来记录数据库状态，并在服务器启动时，通过重新执行这些命令来还原数据集。

 

开启：**AOF 持久化默认是关闭的**，可以通过配置：appendonly yes 开启。

 

关闭：使用配置 appendonly no 可以关闭 AOF 持久化。

 

AOF 持久化功能的实现可以分为三个步骤：**命令追加、文件写入、文件同步**。



 命令追加：当 AOF 持久化功能打开时，**服务器在执行完一个写命令之后**，会将被执行的写命令追加到服务器状态的 **aof 缓冲区（aof_buf）的末尾。** 



 文件写入与文件同步：可能有人不明白为什么将 aof_buf 的内容写到磁盘上需要两步操作，这边简单解释一下。 

**Linux 操作系统中为了提升性能，使用了页缓存（page cache）**。当我们将 aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 **page cache 中**，为了将 page cache 中的数据真正落盘，需要执行 **fsync / fdatasync 命令来强制刷盘**。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。

 在文章开头，我们提过 serverCron 时间事件中会触发 flushAppendOnlyFile 函数，该函数会根据服务器配置的 appendfsync 参数值，来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。 



appendfsync 参数有三个选项：

1）always：每处理一个命令都将 aof_buf 缓冲区中的所有内容写入并同步到AOF 文件，即每个命令都刷盘。

 

2）everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，即每秒刷盘1次。

 

3）no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统来决定。即不执行刷盘，让操作系统自己执行刷盘。

### AOF 的优点

1）AOF 比 RDB可靠。你可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。

 

2）AOF文件是一个纯追加的日志文件。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。

 

3）当 AOF文件太大时，Redis 会自动在后台进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。

 

4）AOF 文件有序地保存了对数据库执行的所有写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。如果你不小心执行了 FLUSHALL 命令把所有数据刷掉了，但只要 AOF 文件没有被重写，那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。



### AOF 的缺点

1）对于相同的数据集，AOF 文件的大小一般会比 RDB 文件大。

 

2）根据所使用的 fsync 策略，AOF 的速度可能会比 RDB 慢。通常 fsync 设置为每秒一次就能获得比较高的性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。

 

3）AOF 在过去曾经发生过这样的 bug ：因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。（举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug ） 。虽然这种 bug 在 AOF 文件中并不常见， 但是相较而言， RDB 几乎是不可能出现这种 bug 的。

## 持节化的时候突然断电怎么办

取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

## 跳表

### 跳跃表

跳跃表(skiplist)是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。

  跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。

  在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。

  Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员(member)是比较长的字符串时，Redis就会使用跳跃表来作为有序集合键的底层实现。

  和链表、字典等数据结构被广泛地应用在Redis内部不同，Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。

### 跳跃表的实现

Redis的跳跃表由redis.h/zskiplistNode和redis.h/zskiplist两个结构定义，其中zskiplistNode结构用于表示跳跃表节点，而zskiplist结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等等。

![image-20210804085220084](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085220084.png)

 上图展示了一个跳跃表示例，位于图片最左边的是zskiplist结构，该结构包含以下属性：

header：指向跳跃表的表头节点

tail：指向跳跃表的表尾节点

level：记录目前跳跃表内，层数最大的那个节点的层数(表头节点的层数不计算在内)

length：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量(表头节点不计算在内)

  位于zskiplist结构右方的是四个zskiplistNode结构，该结构包含以下属性：

层(level)：节点中用L1、L2、L3等字样标记节点的各个层，L1代表第一层，L2代表第二层，依次类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。

后退(backward)指针：节点中用BW字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。

分值(score)：各个节点中的1.0、2.0和3.0是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。

成员对象(obj)：各个节点中的o1、o2和o3是节点所保存的成员对象。
  注意表头节点和其他节点的构造是一样的：表头节点也有后退指针、分值和成员对象，不过表头节点的这些属性都不会被用到，所以图中省略了这些部分，只显示了表头节点的各个层。

### **跳跃表节点**

 跳跃表节点的实现由redis.h/zskiplistNode结构定义：

```c
/* ZSETs use a specialized version of Skiplists */
typedef struct zskiplistNode {
    robj *obj;  /*成员对象*/
    double score;   /*分值*/
    struct zskiplistNode *backward; /*后退指针*/
    struct zskiplistLevel { /*层*/
        struct zskiplistNode *forward;  /*前进指针*/
        unsigned int span;  /*跨度*/
    } level[];
} zskiplistNode;
```

 1、分值和成员

  节点的分值(score属性)是一个double类型的浮点数，跳跃表中的所有节点都按分值从小到大来排序。

  节点的成员对象(obj属性)是一个指针，它指向一个字符串对象，而字符串对象则保存着一个SDS值。

  在同一个跳跃表中，各个节点保存的成员对象必须是唯一的，但是多个节点保存的分值却可以是相同的：分至相同的节点将按照成员对象在字典中的大小来进行排序，成员对象较小的节点会排在前面(靠近表头的方向)，而成员对象较大的节点则会排在后面(靠近表尾的方向)。

  举个例子，在下图中所示的跳跃表中，三个跳跃表节点都保存了相同的分值10086.0，但保存成员对象o1的节点却排在保存成员对象o2和o3的节点的前面，而保存成员对象o2的节点又排在保存成员对象o3的节点之前，由此可见，o1、o2、o3三个成员对象在字典中的排序为o1<=o2<=o3。


![image-20210804085419501](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085419501.png)

 2、后退指针

  节点的后退指针(backward属性)用于从表尾向表头方向访问节点：跟可以一次跳过多个节点的前进指针不同，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。

  下图用虚线展示了如何从表尾向表头遍历跳跃表中的所有节点：程序首先通过跳跃表的tail指针访问表尾节点，然后通过后退指针访问倒数第二个节点，之后再沿着后退指针访问倒数第三个节点，再之后遇到指向NULL的后退指针，于是访问结束。
![image-20210804085444483](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085444483.png)

 3、层

  跳跃表节点的level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，程序可以通过这些层来加快访问其他节点的速度，一般来说，层的数量越多，访问其他节点的速度就越快。

  每次创建一个新跳跃表节点的时候，程序根据幂次定律(power law，越大的数出现的概率越小)随机生成一个介于1和32之间的值作为level数组的大小，这个大小就是层的“高度”。

  下图分别展示了三个高度为1层、3层和5层的节点，因为C语言的数组索引总是从0开始的，所以节点的第一层是level[0]，而第二层是level[1]，依次类推。
![image-20210804085501387](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085501387.png)

 4、前进指针

  每个层都有一个指向表尾方向的前进指针(level[i].forward属性)，用于从表头向表尾方向访问节点。下图用虚线表示出了程序从表头向表尾方向，遍历跳跃表中所有节点的路径：

![image-20210804085515321](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085515321.png)

 1) 迭代程序首先访问跳跃表的第一个节点(表头)，然后从第四层的前进指针移动到表中的第二个节点。
  2) 在第二个节点时，程序沿着第二层的前进指针移动到表中的第三个节点。
  3) 在第三个节点时，程序同样沿着第二层的前进指针移动到表中的第四个节点。
  4) 当程序再次沿着第四个节点的前进指针移动时，它碰到一个NULL，程序知道这时已经到达了跳跃表的表尾，于是结束这次遍历。


  5、跨度

  层的跨度(level[i].span属性)用于记录两个节点之间的距离：

两个节点之间的跨度越大，它们相距得就越远。
指向NULL的所有前进指针的跨度都为0，因为它们没有连向任何节点。
  初看上去，很容易以为跨度和遍历操作有关，但实际上并不是这样的，遍历操作只使用前进指针就可以完成了，跨度实际上是用来计算排位(rank)的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。

  举个例子，下图用虚线标记了在跳跃表中查找分值为3.0、成员对象为o3的节点时，沿途经历的层：查找的过程只经过了一个层，并且层的跨度为3，所以目标节点在跳跃表中的排位为3。
![image-20210804085551321](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085551321.png)

### **跳跃表**

  仅靠多个跳跃表节点就可以组成一个跳跃表，如下图所示：

![image-20210804085621202](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085621202.png)

  但通过使用一个zskiplist结构来持有这些节点，程序可以更方便地对整个跳跃表进行处理，比如快速访问跳跃表的表头节点和表尾节点，或者快速地获取跳跃表节点的数量(也即是跳跃表的长度)等信息，如下图所示：

![image-20210804085642142](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085642142.png)

 zskiplist结构的定义如下：

```c
typedef struct zskiplist {
    struct zskiplistNode *header, *tail;    //header指向跳跃表的表头节点，tail指向跳跃表的表尾节点
    unsigned long length;   //记录跳跃表的长度，也即是，跳跃表目前包含节点的数量(表头节点不计算在内)
    int level;  //记录目前跳跃表内，层数最大的那个节点的层数(表头节点的层数不计算在内)
} zskiplist;
```

这样获取表头、表尾节点，表长，以及表中最高层数的复杂度均为O(1)。





## 压缩列表

### 传统的数组

同之前的底层数据一样，压缩列表也是由Redis设计的一种数据存储结构。

他有点类似于数组，都是通过一片连续的内存空间来存储数据。但是其和数组也有点区别，数组存储不同长度的字符时，会选择最大的字符长度作为每个节点的内存大小。

如下图，一共五个元素，每个元素的长度都是不一样的，这个时候选择最大值5作为每个元素的内存大小，如果选择小于5的，那么第一个元素hello，第二个元素world就不能完整存储，数据会丢失。


![image-20210804085752246](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085752246.png)

### 存在的问题

上面已经提到了需要用最大长度的字符串大小作为整个数组所有元素的内存大小，如果只有一个元素的长度超大，但是其他的元素长度都比较小，那么我们所有元素的内存都用超大的数字就会导致内存的浪费。

那么我们应该如何改进呢？

### 引出压缩列表

Redis引入了压缩列表的概念，即多大的元素使用多大的内存，一切从实际出发，拒绝浪费。

如下图，根据每个节点的实际存储的内容决定内存的大小，即第一个节点占用5个字节，第二个节点占用5个字节，第三个节点占用1个字节，第四个节点占用4个字节，第五个节点占用3个字节。


![image-20210804085823820](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085823820.png)

还有一个问题，我们在遍历的时候不知道每个元素的大小，无法准确计算出下一个节点的具体位置。实际存储不会出现上图的横线，我们并不知道什么时候当前节点结束，什么时候到了下一个节点。所以在redis中添加length属性，用来记录前一个节点的长度。

如下图，如果需要从头开始遍历，取某个节点后面的数字，比如取“hello”的起始地址，但是不知道其结束地址在哪里，我们取后面数字5，即可知道"hello"占用了5个字节，即可顺利找到下一节点“world”的起始位置。
![image-20210804085842859](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085842859.png)

### 压缩列表图解分析

![image-20210804085902086](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085902086.png)

### 表头

表头包括四个部分，分别是内存字节数zlbytes，尾节点距离起始地址的字节数zltail_offset，节点数量zllength，标志结束的记号zlend。

![image-20210804085925465](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804085925465.png)

zlbytes：记录整个压缩列表占用的内存字节数。

zltail_offset：记录压缩列表尾节点距离压缩列表的起始地址的字节数（目的是为了直接定位到尾节点，方便反向查询）。

zllength：记录了压缩列表的节点数量。即在上图中节点数量为2。

zlend：保存一个常数255(0xFF)，标记压缩列表的末端。

### 数据节点

数据节点包括三个部分，分别是前一个节点的长度prev_entry_len，当前数据类型和编码格式encoding，具体数据指针value。

![image-20210804090002066](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804090002066.png)

- prev_entry_len：记录**前驱节点的长度。**
- encoding：记录当前数据类型和编码格式**。**
- value：存放具体的数据。

### 压缩列表的构成

Redis并没有像之前的字符串SDS，字典，跳跃表等结构一样，封装一个结构体来保存压缩列表的信息。而是通过定义一系列宏来对数据进行操作。

也就是说压缩列表是一堆字节码，咱也看不懂，Redis通过字节之间的定位和计算来获取数据的。

```c
//返回整个压缩列表的总字节
#define ZIPLIST_BYTES(zl)       (*((uint32_t*)(zl)))
 
//返回压缩列表的tail_offset变量，方便获取最后一个节点的位置
#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t))))
 
//返回压缩列表的节点数量
#define ZIPLIST_LENGTH(zl)      (*((uint16_t*)((zl)+sizeof(uint32_t)*2)))
 
//返回压缩列表的表头的字节数
//（内存字节数zlbytes，最后一个节点地址ztail_offset,节点总数量zllength）
#define ZIPLIST_HEADER_SIZE     (sizeof(uint32_t)*2+sizeof(uint16_t))
 
//返回压缩列表最后结尾的字节数
#define ZIPLIST_END_SIZE        (sizeof(uint8_t))
 
//返回压缩列表首节点地址
#define ZIPLIST_ENTRY_HEAD(zl)  ((zl)+ZIPLIST_HEADER_SIZE)
 
//返回压缩列表尾节点地址
#define ZIPLIST_ENTRY_TAIL(zl)  ((zl)+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl)))
 
//返回压缩列表最后结尾的地址
#define ZIPLIST_ENTRY_END(zl)   ((zl)+intrev32ifbe(ZIPLIST_BYTES(zl))-1)
```

### 压缩列表节点的构成

我们看下面的代码，重点看注释，Note that this is not how the data is actually encoded，这句话说明这并不是数据的实际存储格式。

是不是有点逗，定义了却没使用。

因为，这个结构存储实在是太浪费空间了。这个结构32位机占用了25（int类型5个，每个int占4个字节，char类型1个，每个char占用1个字节，char*类型1个，每个char*占用4个字节，所以总共5*4+1*1+1*4=25）个字节，在64位机占用了29（int类型5个，每个int占4个字节，char类型1个，每个char占用1个字节，char*类型1个，每个char*占用8个字节，所以总共5*4+1*1+1*8=29个字节）。这不符合压缩列表的设计目的。

```c
/* We use this function to receive information about a ziplist entry.
 * Note that this is not how the data is actually encoded, is just what we
 * get filled by a function in order to operate more easily. */
typedef struct zlentry {
    unsigned int prevrawlensize; //记录prevrawlen需要的字节数
    unsigned int prevrawlen;    //记录上个节点的长度
    unsigned int lensize;        //记录len需要的字节数
    unsigned int len;           //记录节点长度
    unsigned int headersize;   //prevrawlensize+lensize 
    unsigned char encoding;   //编码格式
    unsigned char *p;       //具体的数据指针
} zlentry;
```



所以Redis对上述结构进行了改进了，抽象合并了三个参数。

prev_entry_len:prevrawlensize和prevrawlen的总和。

如果前一个节点长度小于254字节，那么prev_entry_len使用一个字节表示。

如果前一个节点长度大于等于254字节，那么prev_entry_len使用五个字节表示。第一个字节为常数oxff，后面四位为真正的前一个节点的长度。

encoding：lensize和len的总和。Redis通过设置了一组宏定义，使其能够具有lensize和len两种功能。（具体即不展开了）

value：具体的数据。

### 压缩列表的优点

节约内存。

### 压缩列表的缺点

因为压缩表是紧凑存储的，没有多余的空间。这就意味着插入一个新的元素就需要调用函数扩展内存。过程中可能需要重新分配新的内存空间，并将之前的内容一次性拷贝到新的地址。

如果数据量太多，重新分配内存和拷贝数据会有很大的消耗。所以压缩表不适合存储大型字符串，并且数据元素不能太多。

### 压缩列表的连锁更新过程图解（重点）

前面提到每个节点entry都会有一个prevlen字段存储前一个节点entry的长度，如果内容小于254，prevlen用一个字节存储，如果大于254，就用五个字节存储。这意味着如果某个entry经过操作从253字节变成了254字节，那么他的下一个节点entry的pervlen字段就要更新，从1个字节扩展到5个字节；如果这个entry的长度本来也是253字节，那么后面entry的prevlen字段还得继续更新。

如果每个节点entry都存储的253个字节的内容，那么第一个entry修改后会导致后续所有的entry的级联更新，这是一个比较损耗资源的操作。

所以，发生级联更新的前提是有连续的250-253字节长度的节点。

### 步骤一

比如一开始的压缩表呈现下图所示（XXXX表示字符串），现在想要把第二个数据的改大点，哪个时候就会发生级联更新了。

![image-20210804090239960](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804090239960.png)

### 步骤二

我们想要分配四个长度的大小给第三个数据的prevlen，因为第二个元素的prevlen字段是表示他前一个元素的大小。

![image-20210804090255856](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804090255856.png)

### 步骤三

调整完发现第三个元素的长度增加了，所以第四个元素的prevlen字段也需要修改。

![image-20210804090313959](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804090313959.png)

步骤四

调整完发现第四个元素的长度增加了，所以把第五个元素的prevlen字段也需要修改。

![image-20210804090332531](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804090332531.png)

### 压缩列表的源码分析

主要的步骤是分配内存空间，初始化属性，设置结束标记为常量，最后返回压缩表。

```c
unsigned char *ziplistNew(void) {
    //表头加末端大小
    unsigned int bytes = ZIPLIST_HEADER_SIZE+1;
 
    //为上面两部分（表头和末端）分配空间
    unsigned char *zl = zmalloc(bytes);
 
    //初始化表属性
    ZIPLIST_BYTES(zl) = intrev32ifbe(bytes);
    ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE);
    ZIPLIST_LENGTH(zl) = 0;
 
    //设置模块，赋值为常量
    zl[bytes-1] = ZIP_END;
 
    return zl;
}
```

### 级联更新（重点）

```c
unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) {
    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize;
    size_t offset, noffset, extra;
    unsigned char *np;
    zlentry cur, next;
 
    //while循环，当到最后一个节点的时候结束循环
    while (p[0] != ZIP_END) {
        //将节点数据保存在cur中
        zipEntry(p, &cur);
        //取前节点长度编码所占字节数，和当前节点长度编码所占字节数，在加上当前节点的value长度
        //rawlen = prev_entry_len + encoding + value
        rawlen = cur.headersize + cur.len;
        rawlensize = zipStorePrevEntryLength(NULL,rawlen);
 
        //如果没有下一个节点则跳出循环
        if (p[rawlen] == ZIP_END) break;
        //取出后面一个节点放在next中
        zipEntry(p+rawlen, &next);
 
        //当next的prevrawlen，即保存的上一个节点等于rawlen，说明不需要调整，现在的长度合适
        if (next.prevrawlen == rawlen) break;
 
        //如果next对前一个节点长度的编码所需的字节数next.prevrawlensize小于上一个节点长度进行编码所需要的长度
        //因此要对next节点的header部分进行扩展，以便能够表示前一个节点的长度
        if (next.prevrawlensize < rawlensize) {
            //记录当前指针的偏移量
            offset = p-zl;
            ///需要扩展的字节数
            extra = rawlensize-next.prevrawlensize;
            //调整压缩列表的空间大小            
            zl = ziplistResize(zl,curlen+extra);
            //还原p指向的位置
            p = zl+offset;
 
           //next节点的新地址
            np = p+rawlen;
            //记录next节点的偏移量
            noffset = np-zl;
 
          //更新压缩列表的表头tail_offset成员，如果next节点是尾节点就不用更新
            if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) {
                ZIPLIST_TAIL_OFFSET(zl) =
                    intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra);
            }
 
           //移动next节点到新地址，为前驱节点cur腾出空间
            memmove(np+rawlensize,
                np+next.prevrawlensize,
                curlen-noffset-next.prevrawlensize-1);
            //将next节点的header以rawlen长度进行重新编码，更新prevrawlensize和prevrawlen
            zipStorePrevEntryLength(np,rawlen);
 
            //更新p指针，移动到next节点，处理next的next节点
            p += rawlen;
            //更新压缩列表的总字节数
            curlen += extra;
        } else {
            // 如果需要的内存反而更少了则强制保留现有内存不进行缩小
            // 仅浪费一点内存却省去了大量移动复制操作而且后续增大时也无需再扩展
            if (next.prevrawlensize > rawlensize) {
                zipStorePrevEntryLengthLarge(p+rawlen,rawlen);
            } else {
             
                zipStorePrevEntryLength(p+rawlen,rawlen);
            }
 
            /* Stop here, as the raw length of "next" has not changed. */
            break;
        }
    }
    return zl;
}
```





## Redis分布式锁

先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。

这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？

这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要`抓一抓自己得脑袋，故作思考片刻`，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！

Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。

当且仅当 key 不存在，将 key 的值设为 value。 若给定的 key 已经存在，则 SETNX 不做任何动作

SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。

返回值：设置成功，返回 1 。设置失败，返回 0 。

![image-20210417195549810](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210417195549810.png)



使用SETNX完成同步锁的流程及事项如下：

使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功

为了防止获取锁后程序出现异常，导致其他线程/进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间

释放锁，使用DEL命令将锁数据删除

## 如何解决 Redis 的并发竞争 Key 问题

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！

推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）

基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。

在实践中，当然是从以可靠性为主。所以首推Zookeeper。

## Redis的内存用完了会发生什么

使用Redis 服务时，很多情况下某些键值对只会在特定的时间内有效，为了防止这种类型的数据一直占有内存，我们可以给键值对设置有效期。Redis 中可以通过 4 个独立的命令来给一个键设置过期时间：



- expire key ttl：将 key 值的过期时间设置为 ttl 秒。
- pexpire key ttl：将 key 值的过期时间设置为 ttl 毫秒。
- expireat key timestamp：将 key 值的过期时间设置为指定的 timestamp 秒数。
- pexpireat key timestamp：将 key 值的过期时间设置为指定的 timestamp 毫秒数。



PS：不管使用哪一个命令，最终 Redis 底层都是使用 pexpireat 命令来实现的。

另外，set 等命令也可以设置 key 的同时加上过期时间，这样可以保证设值和设过期时间的原子性。



**设置了有效期后，可以通过 ttl 和 pttl 两个命令来查询剩余过期时间（如果未设置过期时间则下面两个命令返回 -1，如果设置了一个非法的过期时间，则都返回 -2）：**



- ttl key 返回 key 剩余过期秒数。
- pttl key 返回 key 剩余过期的毫秒数。



### **过期策略**



如果将一个过期的键删除，我们一般都会有三种策略：



- 定时删除：为每个键设置一个定时器，一旦过期时间到了，则将键删除。这种策略对内存很友好，但是对 CPU 不友好，因为每个定时器都会占用一定的 CPU 资源。



- 惰性删除：不管键有没有过期都不主动删除，等到每次去获取键时再判断是否过期，如果过期就删除该键，否则返回键对应的值。这种策略对内存不够友好，可能会浪费很多内存。



- 定期扫描：系统每隔一段时间就定期扫描一次，发现过期的键就进行删除。这种策略相对来说是上面两种策略的折中方案，需要注意的是这个定期的频率要结合实际情况掌控好，使用这种方案有一个缺陷就是可能会出现已经过期的键也被返回。

 在 Redis 当中，其选择的是策略 2 和策略 3 的综合使用。不过 Redis 的定期扫描只会扫描设置了过期时间的键，因为设置了过期时间的键 Redis 会单独存储，所以不会出现扫描所有键的情况： 

```c

typedef struct redisDb {
    dict *dict; //所有的键值对
    dict *expires; //设置了过期时间的键值对
   dict *blocking_keys; //被阻塞的key,如客户端执行BLPOP等阻塞指令时
   dict *watched_keys; //WATCHED keys
   int id; //Database ID
   //... 省略了其他属性
} redisDb;
```

###  **LRU 算法**



LRU 全称为：Least Recently Used。即：最近最长时间未被使用。这个主要针对的是使用时间。



### Redis 改进后的 LRU 算法



在 Redis 当中，并没有采用传统的 LRU 算法，因为传统的 LRU 算法存在 2 个问题：



- 需要额外的空间进行存储。
- 可能存在某些 key 值使用很频繁，但是最近没被使用，从而被 LRU 算法删除。



为了避免以上 2 个问题，Redis 当中对传统的 LRU 算法进行了改造，通过抽样的方式进行删除。



配置文件中提供了一个属性 maxmemory_samples 5，默认值就是 5，表示随机抽取 5 个 key 值，然后对这 5 个 key 值按照 LRU 算法进行删除，所以很明显，key 值越大，删除的准确度越高。



对抽样 LRU 算法和传统的 LRU 算法，Redis 官网当中有一个对比图：



- 浅灰色带是被删除的对象。
- 灰色带是未被删除的对象。
- 绿色是添加的对象。







## Redis如何做内存优化

可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。`比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面`


## Redis事务支持隔离性吗

Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，**Redis 的事务是总是带有隔离性的**。

## Redis事务保证原子性吗，支持回滚吗

Redis中，单条命令是原子性执行的，但**事务不保证原子性，且没有回滚**。事务中任意命令执行失败，其余的命令仍会被执行。

## Redis事务其他实现

1、基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，
其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完
2、基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐



## Redis是单线程，计算机现在都是多核会不会浪费

是的他是单线程的，但是，我们可以通过在单机开多个**Redis实例**嘛。









## 主从复制

### 主从复制的三个阶段

- 建立连接过程：这个过程就是slave跟master连接的过程
- 数据同步过程：是master给slave同步数据的过程
- 命令传播过程：是反复同步数据

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200531230125375.png)

### 第一阶段：建立连接过程

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200531233524414.png)

上图是一个完整主从复制建立连接工作流程。然后使用简短的话语来描述上边的工作流程。

1. 设置master的地址和端口，保存master的信息
2. 建立socket连接（这个连接做的事情下文会说）
3. 持续发送ping命令
4. 身份验证
5. 发送slave端口信息
6. 在建立连接的过程中，从节点会保存master的地址和端口、主节点master保存从节点slave的端口。
   

###  第二阶段：数据同步阶段过程

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200601150500247.png)



当从节点**第一次连接**主节点时，先会执行一次全量复制这次的全量复制是无法避免的。

全量复制执行完成后，主节点就会发送**复制积压缓冲区的数据**，然后从节点就会执行bgrewriteaof恢复数据，这也就是部分复制。

在这个阶段提到了三个新点，全量复制、部分复制、复制缓冲积压区。

### 第三阶段：命令传播阶段

当master数据库被修改后，主从服务器的数据不一致后，此时就会让主从数据同步到一致，这个过程称之为命令传播。

master会将接收到的数据变更命令发送给slave，slave接收命令后执行命令，让主从数据达到一致。

**命令传播阶段的部分复制**

在命令传播阶段出现断网的情况，或者网络抖动时会导致连接断开（connection lost）

这个时候主节点master还是会继续往replbackbuffer（复制缓冲积压区）写数据

从节点会继续尝试连接主机（connect to master）

当从节点把自己的runid和复制偏移量发送给主节点，并且执行pysnc命令同步

如果master判断偏移量是在复制缓冲区范围内，就会返回continue命令。并且发送复制缓冲区的数据给从节点。

从节点接收数据执行bgrewriteaof，恢复数据


### 主从复制详细

1. 从节点发送指令psync ? 1 psync runid offset 找对应的runid索取数据。但是这里可以考虑一下，当从节点第一次连接的时候根本就不知道主节点的runid 和 offset 。所以第一次发送的指令是psync ？ 1意思就是主节点的数据我全要。

2. 主节点开始执行bgsave生成RDB文件，记录当前的复制偏移量offset

3. 主节点这个时候会把自己的runid 和 offset 通过 +FULLRESYNC runid offset 指令 通过socket发送RDB文件给从节点。

4. 从节点接收到+FULLRESYNC 保存主节点的runid和offset 然后清空当前所有数据，通过socket接收RDB文件，开始恢复RDB数据。

5. 在全量复制后，从节点已经获取到了主节点的runid和offset，开始发送指令 psync runid offset
   主节点接收指令，判断runid是否匹配，判断offset是否在复制缓冲区中。

6. 主节点判断runid和offset有一个不满足，就会在返回到步骤2继续执行全量复制。这里的runid不匹配只有的可能是从节点重启了这个问题后边会解决，offset（偏移量）不匹配就是复制积压缓冲区溢出了。 如果runid或offset校验通过，从节点的offset和主节点的offset相同时则忽略。 如果runid或offset检验通过，从节点的offset与offset不相同，则会发送 +CONTINUE offset(这个offset为主节点的)，通过socket发送复制缓冲区中从节点offset到主节点offset的数据。

7. 从节点收到+CONTINUE 保存master的offset 通过socket接收到信息后，执行bgrewriteaof，恢复数据。

   ### 心跳机制

   在命令传播阶段是，**主节点与从节点之间一直都需要进行信息互换**，使用心跳机制进行维护，**实现主节点和从节点连接保持在线。**

   **master心跳**

   指令：ping
   默认10秒进行一次，是由参数repl-ping-slave-period决定的
   主要做的事情就是判断从节点是否在线
   可以使用info replication 来查看从节点租后一次连接时间的间隔，lag为0或者为1就是正常状态。
   slave心跳任务

   指令：replconf ack {offset}
   每秒执行一次
   主要做的事情是给主节点发送自己的复制偏移量，从主节点获取到最新的数据变更命令，还做一件事情就是判断主节点是否在线。


### 复制积压缓冲区

复制缓冲积压区是一个**先进先出的队列**，用户存储master**收集数据的命令记录**。复制缓冲区的默认存储空间是1M。

可以在配置文件修改`repl-backlog-size 1mb`来控制缓冲区大小，这个比例可以根据自己的服务器内存来修改，咔咔这边是预留出了30%左右。

**复制缓冲区到底存储的是什么？**

当执行一个命令为`set name kaka`时，我们可以查看持久化文件查看
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200601164415631.png)
那么复制积压缓冲区就是存储的aof持久化的数据，并且以字节分开，并且每个字节都有自己的偏移量。这个偏移量也就是复制偏移量（offset）
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020060116425459.png)

那为什么会说复制缓冲积压区有可能会导致全量复制呢

在命令传播阶段，**主节点会把收集的数据存储到复制缓冲区**中，然后在**发送给从节点**。就是这里出现了问题，**当主节点数据量在一瞬间特别大的时候，超出了复制缓冲区的内存**，就会有**一部分数据会被挤出去**，从而导致主节点和从节点的数据不一致。从而进行全量复制。如果这个**缓冲区大小设置不合理**那么很大可能会造成死循环，从节点就会**一直全量复制**，清空数据，全量复制。




## LUA脚本







## 缓存穿透

缓存穿透就是比如我们正常数据库id都是从1开始存的。但是如果前端用户来一个查询id=-1的这么一个请求，那数据库中肯定是没有的。那一个两个这样的非法请求数据库还可以接受，但是如果这样的请求多了数据库可能就扛不住了。

`缓存穿透`我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。

`这里我想提的一点就是，我们在开发程序的时候都要有一颗“不信任”的心，就是不要相信任何调用方，比如你提供了API接口出去，你有这几个参数，那我觉得作为被调用方，任何可能的参数情况都应该被考虑到，做校验，因为你不相信调用你的人，你不知道他会传什么参数给你。`

举个简单的例子，你这个接口是分页查询的，但是你没对分页参数的大小做限制，调用的人万一一口气查 Integer.MAX_VALUE 一次请求就要你几秒，多几个并发你不就挂了么？是公司同事调用还好大不了发现了改掉，但是如果是黑客或者竞争对手呢？在你双十一当天就调你这个接口会发生什么，就不用我说了吧。这是之前的Leader跟我说的，我觉得大家也都应该了解下。


解决方案：

1：对查询结果为空的情况也进行缓存，这样，再次访问时，缓存层会直接返回空值。缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。

2、布隆过滤器。我们先把所有的数据放到布隆过滤器里面，布隆过滤器是一个很长的数组，里面的数组默认是0。然后我们把数据通过hash算法进行一个在数组上的映射，映射到哪个位置就把这个数组的位置标记为1.那这样再查询数据的时候，先对这个数据进行hash算法找到对应映射到的数组下标，只要其中有一个下标为0，就说明没有这个数据，就直接返回没有就好了，不用再去数据库中查询了。有问题就是可能存在hash冲突，比如一个数不存在，但是在用hash映射的时候和别的数据产生了hash冲突，结果发现映射到的数组下标也都是1，但是这个数据本身是不存在的，所以有一定的误判率。

## 缓存击穿

场景是，当热点数据的Key失效后，假如瞬间突然涌入大量的请求，来请求同一个Key，这些请求不会命中Redis，都会请求到DB，导致数据库压力过大，甚至扛不住，挂掉。

解决办法

1、设置热点Key，自动检测热点Key，将热点Key的过期时间加大或者设置为永不过期，或者设置为逻辑上永不过期

2、加互斥锁。当发现没有命中Redis，去查数据库的时候，在执行更新缓存的操作上加锁，当一个线程访问时，其它线程等待，这个线程访问过后，缓存中的数据会被重建，这样其他线程就可以从缓存中取值。

## 缓存雪崩

是指大量Key同时失效，对这些Key的请求又会打到DB上，同样会导致数据库压力过大甚至挂掉。

解决办法

1）让Key的失效时间分散开，可以在统一的失效时间上再加一个随机值，或者使用更高级的算法分散失效时间。setRedis（Key，value，time + Math.random() * 10000）；

2）构建多个redis实例，个别节点挂了还有别的可以用。

3）多级缓存：比如增加本地缓存，减小redis压力。

4）对存储层增加限流措施，当请求超出限制，提供降级服务（一般就是返回错误即可）

## 缓存预热

缓存预热就是系统上线后，将相关的`缓存数据直接加载到缓存系统`。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

解决方案

直接写个缓存刷新页面，上线时手工操作一下；

数据量不大，可以在项目启动的时候自动进行加载；

定时刷新缓存；

## 为什么要做Redis分区

分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。

## 有哪些Redis分区实现方案

客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。
代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy
查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。

## Redis分区有什么缺点

1、涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。

2、同时操作多个key,则不能使用Redis事务.

3、分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）

4、当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。

5、分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。





## 什么是 RedLock

`Redis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock`，此种方式比原先的单节点的方法更安全。它可以保证以下特性：

安全特性：互斥访问，即永远只有一个 client 能拿到锁
避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
容错性：只要大部分 Redis 节点存活就可以正常提供服务

## Redis如何做大量数据插入

Redis2.6开始redis-cli支持一种新的被称之为pipe mode的新模式用于执行大量数据插入工作。

## Redis官方为什么不提供Windows版本？

因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。

## 如果有大量的key需要设置同一时间过期，一般需要注意什么？

如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象(原因是这个时候缓存过期了，都去数据库中查，肯定要慢的)。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。

电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点大量用户涌入，就有可能造成缓存雪崩


## 1亿个key，其中有10w个key是以某个固定的已知的前缀开头的

使用`keys`指令可以扫出指定模式的key列表。

对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？

这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

不过，增量式迭代命令也不是没有缺点的： 举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。

## Redis做异步队列

一般使用list结构作为队列，`rpush`生产消息，`lpop`消费消息。当lpop没有消息的时候会造成cpu空耗的这么一个情况，要适当sleep一会再重试。

如果对方追问可不可以不用sleep呢？

list还有个指令叫`blpop`，在没有消息的时候，它会阻塞住直到消息到来才被唤醒。

如果对方接着追问能不能生产一次消费多次呢？

使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。

##  pub/su b有什么缺点？

在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如`RocketMQ`等。

## Redis如何实现延时队列

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用`zrangebyscore`指令获取N秒之前的数据轮询进行处理。







## 为什么是删除缓存，而不是更新缓存？


# RPC

## 什么是分布式?

我理解的分布式，其实就是把一个复杂的系统，比如一个电商系统可以拆分成订单系统，商品系统，登陆系统等等，而且我觉得一个成熟的电商系统的业务应该绝不止这些吧。那我们现在把这些服务分别部署在不同的机器上，如果某个服务访问量比较大的话，我们还可以把这个服务同时部署在多台机器上。那这样是不是就很好的减轻了单体服务的这个压力，同时也提高了并发的这样的一个性能。像电商系统高峰期的时候比如双十一，可能有上亿的并发量，如果不分布式部署的话，那服务器肯定扛不住，瞬间崩掉。

![image-20210428101248499](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428101248499.png)

![image-20210428101310816](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428101310816.png)

## 分布式的优点

我觉得业务差分后，代码没有集中在一起，开发效率这一块会有提升，同时后期的代码维护也相对容易。主要还是提高了整体这个系统的性能。

## RPC和HTTP的区别

### 传输协议

- RPC，可以基于TCP然后自定义协议(毕竟适合自己的才是最好的)，也可以基于HTTP协议
- HTTP，基于HTTP协议

### 传输效率

- RPC，使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以很好的减少报文的体积，提高传输效率
- HTTP，如果是基于HTTP1.1的协议，请求中会包含很多无用的内容，如果是基于HTTP2.0，那么简单的封装一下是可以作为一个RPC来使用的，这时标准RPC框架更多的是服务治理

### 性能消耗，主要在于序列化和反序列化的耗时

- RPC，可以基于thrift实现高效的二进制传输
- HTTP，大部分是通过json来实现的，字节大小和序列化耗时都比thrift要更消耗性能

### 负载均衡

- RPC，基本都自带了负载均衡策略
- HTTP，需要配置Nginx，HAProxy来实现

### 总结：

  RPC主要用于公司内部的服务调用，性能消耗低，传输效率高，服务治理方便。HTTP主要用于对外的异构环境，浏览器接口调用，APP接口调用，第三方接口调用等。

RPC协议一般都有注册中心.有丰富的监控机制.

## 分布式事务



### 2PC

2PC（Two-phase commit protocol），中文叫二阶段提交。 二阶段提交是一种强一致性设计，2PC 引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备（投票）和提交两个阶段。

注意这只是协议或者说是理论指导，只阐述了大方向，具体落地还是有会有差异的。

让我们来看下两个阶段的具体流程。

准备阶段协调者会给各参与者发送准备命令，你可以把准备命令理解成除了提交事务之外啥事都做完了。

同步等待所有资源的响应之后就进入第二阶段即提交阶段（注意提交阶段不一定是提交事务，也可能是回滚事务）。

假如在第一阶段所有参与者都返回准备成功，那么协调者则向所有参与者发送提交事务命令，然后等待所有事务都提交成功之后，返回事务执行成功。

![image-20210428101825103](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428101825103.png)



如在第一阶段有一个参与者返回失败，那么协调者就会向所有参与者发送回滚事务的请求，即分布式事务执行失败。

![image-20210428101845683](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428101845683.png)



那可能就有人问了，那第二阶段提交失败的话呢？

这里有两种情况。

第一种是第二阶段执行的是回滚事务操作，那么答案是不断重试，直到所有参与者都回滚了，不然那些在第一阶段准备成功的参与者会一直阻塞着。

第二种是第二阶段执行的是提交事务操作，那么答案也是不断重试，因为有可能一些参与者的事务已经提交成功了，这个时候只有一条路，就是头铁往前冲，不断的重试，直到提交成功，到最后真的不行只能人工介入处理。

大体上二阶段提交的流程就是这样，我们再来看看细节。

首先 2PC 是一个同步阻塞协议，像第一阶段协调者会等待所有参与者响应才会进行下一步操作，当然第一阶段的协调者有超时机制，假设因为网络原因没有收到某参与者的响应或某参与者挂了，那么超时后就会判断事务失败，向所有参与者发送回滚命令。

在第二阶段协调者的没法超时，因为按照我们上面分析只能不断重试！

协调者故障分析
协调者是一个单点，存在单点故障问题。

假设协调者在发送准备命令之前挂了，还行等于事务还没开始。

假设协调者在发送准备命令之后挂了，这就不太行了，有些参与者等于都执行了处于事务资源锁定的状态。不仅事务执行不下去，还会因为锁定了一些公共资源而阻塞系统其它操作。

假设协调者在发送回滚事务命令之前挂了，那么事务也是执行不下去，且在第一阶段那些准备成功参与者都阻塞着。

假设协调者在发送回滚事务命令之后挂了，这个还行，至少命令发出去了，很大的概率都会回滚成功，资源都会释放。但是如果出现网络分区问题，某些参与者将因为收不到命令而阻塞着。

假设协调者在发送提交事务命令之前挂了，这个不行，傻了！这下是所有资源都阻塞着。

假设协调者在发送提交事务命令之后挂了，这个还行，也是至少命令发出去了，很大概率都会提交成功，然后释放资源，但是如果出现网络分区问题某些参与者将因为收不到命令而阻塞着。

协调者故障，通过选举得到新协调者
因为协调者单点问题，因此我们可以通过选举等操作选出一个新协调者来顶替。

如果处于第一阶段，其实影响不大都回滚好了，在第一阶段事务肯定还没提交。

如果处于第二阶段，假设参与者都没挂，此时新协调者可以向所有参与者确认它们自身情况来推断下一步的操作。

假设有个别参与者挂了！这就有点僵硬了，比如协调者发送了回滚命令，此时第一个参与者收到了并执行，然后协调者和第一个参与者都挂了。

此时其他参与者都没收到请求，然后新协调者来了，它询问其他参与者都说OK，但它不知道挂了的那个参与者到底O不OK，所以它傻了。

问题其实就出在每个参与者自身的状态只有自己和协调者知道，因此新协调者无法通过在场的参与者的状态推断出挂了的参与者是什么情况。

虽然协议上没说，不过在实现的时候我们可以灵活的让协调者将自己发过的请求在哪个地方记一下，也就是日志记录，这样新协调者来的时候不就知道此时该不该发了？

### 3PC

3PC 的出现是为了解决 2PC 的一些问题，相比于 2PC 它在参与者中也引入了超时机制，并且新增了一个阶段使得参与者可以利用这一个阶段统一各自的状态。

让我们来详细看一下。

3PC 包含了三个阶段，分别是准备阶段、预提交阶段和提交阶段，对应的英文就是：CanCommit、PreCommit 和 DoCommit。

看起来是把 2PC 的提交阶段变成了预提交阶段和提交阶段，但是 3PC 的准备阶段协调者只是询问参与者的自身状况，比如你现在还好吗？负载重不重？这类的。

而预提交阶段就是和 2PC 的准备阶段一样，除了事务的提交该做的都做了。

提交阶段和 2PC 的一样，让我们来看一下图。

![image-20210428102020415](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428102020415.png)

不管哪一个阶段有参与者返回失败都会宣布事务失败，这和 2PC 是一样的（当然到最后的提交阶段和 2PC 一样只要是提交请求就只能不断重试）。

我们先来看一下 3PC 的阶段变更有什么影响。

首先准备阶段的变更成不会直接执行事务，而是会先去询问此时的参与者是否有条件接这个事务，因此不会一来就干活直接锁资源，使得在某些资源不可用的情况下所有参与者都阻塞着。

而预提交阶段的引入起到了一个统一状态的作用，它像一道栅栏，表明在预提交阶段前所有参与者其实还未都回应，在预处理阶段表明所有参与者都已经回应了。

假如你是一位参与者，你知道自己进入了预提交状态那你就可以推断出来其他参与者也都进入了预提交状态。

但是多引入一个阶段也多一个交互，因此性能会差一些，而且绝大部分的情况下资源应该都是可用的，这样等于每次明知可用执行还得询问一次。

我们再来看下参与者超时能带来什么样的影响。

我们知道 2PC 是同步阻塞的，上面我们已经分析了协调者挂在了提交请求还未发出去的时候是最伤的，所有参与者都已经锁定资源并且阻塞等待着。

那么引入了超时机制，参与者就不会傻等了，如果是等待提交命令超时，那么参与者就会提交事务了，因为都到了这一阶段了大概率是提交的，如果是等待预提交命令超时，那该干啥就干啥了，反正本来啥也没干。

然而超时机制也会带来数据不一致的问题，比如在等待提交命令时候超时了，参与者默认执行的是提交事务操作，但是有可能执行的是回滚操作，这样一来数据就不一致了。

当然 3PC 协调者超时还是在的，具体不分析了和 2PC 是一样的。

从维基百科上看，3PC 的引入是为了解决提交阶段 2PC 协调者和某参与者都挂了之后新选举的协调者不知道当前应该提交还是回滚的问题。

新协调者来的时候发现有一个参与者处于预提交或者提交阶段，那么表明已经经过了所有参与者的确认了，所以此时执行的就是提交命令。

所以说 3PC 就是通过引入预提交阶段来使得参与者之间的状态得到统一，也就是留了一个阶段让大家同步一下。

但是这也只能让协调者知道该如果做，但不能保证这样做一定对，这其实和上面 2PC 分析一致，因为挂了的参与者到底有没有执行事务无法断定。

所以说 3PC 通过预提交阶段可以减少故障恢复时候的复杂性，但是不能保证数据一致，除非挂了的那个参与者恢复。

让我们总结一下， 3PC 相对于 2PC 做了一定的改进：引入了参与者超时机制，并且增加了预提交阶段使得故障恢复之后协调者的决策复杂度降低，但整体的交互过程更长了，性能有所下降，并且还是会存在数据不一致问题。

所以 2PC 和 3PC 都不能保证数据100%一致，因此一般都需要有定时扫描补偿机制。

我再说下 3PC 我没有找到具体的实现，所以我认为 3PC 只是纯的理论上的东西，而且可以看到相比于 2PC 它是做了一些努力但是效果甚微，所以只做了解即可。

### TCC

2PC 和 3PC 都是数据库层面的，而 TCC 是业务层面的分布式事务，就像我前面说的分布式事务不仅仅包括数据库的操作，还包括发送短信等，这时候 TCC 就派上用场了！

TCC 指的是Try - Confirm - Cancel。

Try 指的是预留，即资源的预留和锁定， 注意是预留。
Confirm 指的是确认操作，这一步其实就是真正的执行了。
Cancel 指的是撤销操作，可以理解为把预留阶段的动作撤销了。
其实从思想上看和 2PC 差不多，都是先试探性的执行，如果都可以那就真正的执行，如果不行就回滚。

比如说一个事务要执行A、B、C三个操作，那么先对三个操作执行预留动作。如果都预留成功了那么就执行确认操作，如果有一个预留失败那就都执行撤销动作。

我们来看下流程，TCC模型还有个事务管理者的角色，用来记录TCC全局事务状态并提交或者回滚事务。

![image-20210428102113484](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428102113484.png)

可以看到流程还是很简单的，难点在于业务上的定义，对于每一个操作你都需要定义三个动作分别对应Try - Confirm - Cancel。

因此 TCC 对业务的侵入较大和业务紧耦合，需要根据特定的场景和业务逻辑来设计相应的操作。

还有一点要注意，撤销和确认操作的执行可能需要重试，因此还需要保证操作的幂等。

相对于 2PC、3PC ，TCC 适用的范围更大，但是开发量也更大，毕竟都在业务上实现，而且有时候你会发现这三个方法还真不好写。不过也因为是在业务上实现的，所以TCC可以跨数据库、跨不同的业务系统来实现事务。



# ZooKeeper

- ZooKeeper主要**服务于分布式系统**，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。
- 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够**通用**解决这些问题的中间件就应运而生了。

ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗**树**，每个节点叫做**ZNode**。每一个节点可以通过**路径**来标识，结构图如下：

![image-20210910143259857](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143259857.png)

那ZooKeeper这颗"树"有什么特点呢？？ZooKeeper的节点我们称之为**Znode**，Znode分为**两种**类型：

- **短暂/临时(Ephemeral)**：当客户端和服务端断开连接后，所创建的Znode(节点)**会自动删除**
- **持久(Persistent)**：当客户端和服务端断开连接后，所创建的Znode(节点)**不会删除**

**ZooKeeper和Redis一样，也是C/S结构(分成客户端和服务端)**



![image-20210910143350416](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143350416.png)

##  监听器

在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了**监听器**才能够做那么多事的。

**常见**的监听场景有以下两项：

- 监听Znode节点的**数据变化**
- 监听子节点的**增减变化**

![image-20210910143434275](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143434275.png)

通过**监听+Znode节点(持久/短暂[临时])**，ZooKeeper就可以玩出这么多花样了。

## 统一配置管理

比如我们现在有三个系统A、B、C，他们有三份配置，分别是`ASystem.yml、BSystem.yml、CSystem.yml`，然后，这三份配置又非常类似，很多的配置项几乎都一样。

- 此时，**如果我们要改变其中一份配置项的信息，很可能其他两份都要改**。并且，改变了配置项的信息**很可能就要重启系统**

于是，我们希望把`ASystem.yml、BSystem.yml、CSystem.yml`相同的配置项抽取出来成一份**公用**的配置`common.yml`，并且即便`common.yml`改了，也不需要系统A、B、C重启。

![image-20210910143528395](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143528395.png)

做法：我们可以将`common.yml`这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，**及时**响应。

![image-20210910143613010](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143613010.png)

## 统一命名服务

统一命名服务的理解其实跟**域名**一样，是我们为这某一部分的资源给它**取一个名字**，别人通过这个名字就可以拿到对应的资源。

比如说，现在我有一个域名`www.java3y.com`，但我这个域名下有多台机器：

- 192.168.1.1
- 192.168.1.2
- 192.168.1.3
- 192.168.1.4

别人访问`www.java3y.com`即可访问到我的机器，而不是通过IP去访问。



![image-20210910143654648](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143654648.png)

## 分布式锁

我们可以使用ZooKeeper来实现分布式锁，那是怎么做的呢？？下面来看看：

系统A、B、C都去访问`/locks`节点

![image-20210910143748958](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143748958.png)

访问的时候会创建**带顺序号的临时/短暂**(`EPHEMERAL_SEQUENTIAL`)节点，比如，系统A创建了`id_000000`节点，系统B创建了`id_000002`节点，系统C创建了`id_000001`节点。

![image-20210910143810924](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143810924.png)

## 集群状态

还是以我们三个系统A、B、C为例，在ZooKeeper中创建**临时节点**即可：

![image-20210910143922907](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910143922907.png)

只要系统A挂了，那`/groupMember/A`这个节点就会删除，通过**监听**`groupMember`下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)

除了能够感知节点的上下线变化，ZooKeeper还可以实现**动态选举Master**的功能。(如果集群是主从架构模式下)

原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带**顺序号的临时节点**(`EPHEMERAL_SEQUENTIAL`)就好了。

- Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让**新的最小编号作为Master**，这样就可以实现动态选举的功能了。



# RocketMQ

![img](https://tva1.sinaimg.cn/large/006y8mN6ly1g9908d8kj5j30nb0fwdh9.jpg)



**Tip**：我们可以看到**RocketMQ**啥都是**集群**部署的，这是他**吞吐量大**，**高可用**的原因之一，集群的模式也很花哨，可以支持多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。



## 消息去重

去重原则：使用业务端逻辑保持幂等性

**幂等性**：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用，数据库的结果都是唯一的，不可变的。

只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样，需要业务端来实现。

**去重策略**：保证每条消息都有唯一编号(**比如唯一流水号)**，且保证消息处理成功与去重表的日志同时出现。

建立一个消息表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键（primary key）或者唯一约束，那么就算出现重复消费的情况，就会导致主键冲突，那么就不再处理这条消息。

## 消息重复

消息领域有一个对消息投递的QoS定义，分为：

- 最多一次（At most once）
- 至少一次（At least once）
- 仅一次（ Exactly once）

QoS：Quality of Service，服务质量

几乎所有的MQ产品都声称自己做到了At least once。

既然是至少一次，那避免不了消息重复，尤其是在分布式网络环境下。

比如：网络原因闪断，ACK返回失败等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。

不同的消息队列发送的确认信息形式不同，例如`RabbitMQ是发送一个ACK确认消息`，`RocketMQ是返回一个CONSUME_SUCCESS成功标志`，Kafka实际上有个offset的概念。

RocketMQ没有内置消息去重的解决方案，最新版本是否支持还需确认。


## 消息的可用性

当我们选择好了集群模式之后，那么我们需要关心的就是怎么去`存储和复制这个数据`，RocketMQ对消息的刷盘提供了同步和异步的策略来满足我们的，当我们选择同步刷盘之后，如果刷盘超时会给返回FLUSH_DISK_TIMEOUT，如果是异步刷盘不会返回刷盘相关信息，选择同步刷盘可以尽最大程度满足我们的消息不会丢失。

除了存储有选择之后，我们的主从同步提供了同步和异步两种模式来进行复制，当然选择同步可以提升可用性，但是消息的发送RT时间会下降10%左右。

RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。

而Kafka采用的是独立型的存储结构，每个队列一个文件。

这里帅丙认为，RocketMQ采用混合型存储结构的缺点在于，会存在较多的随机读操作，因此读的效率偏低。同时消费消息需要依赖ConsumeQueue，构建该逻辑消费队列需要一定开销。

## RocketMQ 刷盘实现

Broker 在消息的存取时直接操作的是内存（内存映射文件），这可以提供系统的吞吐量，但是无法避免机器掉电时数据丢失，所以需要持久化到磁盘中。

刷盘的最终实现都是使用NIO中的 MappedByteBuffer.force() 将映射区的数据写入到磁盘，如果是同步刷盘的话，在Broker把消息写到CommitLog映射区后，就会等待写入完成。

异步而言，只是唤醒对应的线程，不保证执行的时机，流程如图所示。

## 顺序消息

我简单的说一下我们使用的RocketMQ里面的一个简单实现吧。

Tip：为啥用RocketMQ举例呢，这玩意是阿里开源的，我问了下身边的朋友很多公司都有使用，所以读者大概率是这个的话我就用这个举例吧，具体的细节我后面会在RocketMQ和Kafka各自章节说到。

生产者消费者一般需要保证顺序消息的话，可能就是一个业务场景下的，比如订单的创建、支付、发货、收货。

那这些东西是不是一个订单号呢？一个订单的肯定是一个订单号的说，那简单了呀。

**一个topic下有多个队列，为了保证发送有序，RocketMQ提供了MessageQueueSelector队列选择机制**，他有三种实现:

我们可使用Hash取模法，让同一个订单发送到同一个队列中，再使用同步发送，只有同个订单的创建消息发送成功，再发送支付消息。这样，我们保证了发送有序。

RocketMQ的topic内的队列机制,可以保证存储满足FIFO（First Input First Output 简单说就是指先进先出）,剩下的只需要消费者顺序消费即可。

RocketMQ仅保证顺序发送，顺序消费由消费者业务保证!!!

这里很好理解，一个订单你发送的时候放到一个队列里面去，你同一个的订单号Hash一下是不是还是一样的结果，那肯定是一个消费者消费，那顺序是不是就保证了？

## 分布式事务

**是指暂不能被Consumer消费的消息**。Producer 已经把消息成功发送到了 Broker 端，但此消息被标记为`暂不能投递`状态，处于该种状态下的消息称为半消息。需要 Producer

对消息的`二次确认`后，Consumer才能去消费它。

消息回查
由于网络闪段，生产者应用重启等原因。导致 Producer 端一直没有对 Half Message(半消息) 进行 二次确认。这是Brock服务器会定时扫描长期处于半消息的消息，会

主动询问 Producer端 该消息的最终状态(Commit或者Rollback),该消息即为 消息回查。

## 消息过滤

Broker端消息过滤　　
在Broker中，按照Consumer的要求做过滤，优点是减少了对于Consumer无用消息的网络传输。缺点是增加了Broker的负担，实现相对复杂。
Consumer端消息过滤
这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到Consumer端。

## 消息堆积

消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要求消息中间件具有一定的消息堆积能力，消息堆积分以下两种情况：

消息堆积在内存Buffer，一旦超过内存Buffer，可以根据一定的丢弃策略来丢弃消息，如CORBA Notification规范中描述。适合能容忍丢弃消息的业务，这种情况消息的堆积能力主要在于内存Buffer大小，而且消息堆积后，性能下降不会太大，因为内存中数据多少对于对外提供的访问能力影响有限。
消息堆积到持久化存储系统中，例如DB，KV存储，文件记录形式。 当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。
评估消息堆积能力主要有以下四点：
消息能堆积多少条，多少字节？即消息的堆积容量。
消息堆积后，发消息的吞吐量大小，是否会受堆积影响？
消息堆积后，正常消费的Consumer是否会受影响？
消息堆积后，访问堆积在磁盘的消息时，吞吐量有多大？



## 中间件选型

![img](https://tva1.sinaimg.cn/large/006y8mN6ly1g93o256nqtj30mq0puwih.jpg)

# JAVA

## 接口存在的意义

使用JDBC接口连接数据库的第一步：加载连接数据库的驱动即Driver到JVM. Driver接口是由数据库厂家提供的，对于我们java开发者而言，**只需要使用Driver接口就可以了**.SUN公司只提供JDBC接口，具体实现交由各个数据库厂商实现具体的连接类。



我们在用Java连接数据库的时候，由于有许多的数据库厂商，比如mysql的，MongoDB的，Oracle的，但是我们只需要通过Java提供的接口去连接就可以了，因为不同的数据库厂商都

比如有个网站， 需要保存不同客户的信息， 有些客户从 Web 网站来， 有些客户从手机客户端来， 有些客户直接从后台管理系统录入。假设不同来源的客户有不同的处理业务流程， 这个时候我们定义接口来提供一个保存客户信息的方法，然后不同的平台实现我们这个保存客户信息的接口，以后保存客户信息的话， 我们只需要知道这个接口就可以了，具体调用的方法被封装成了黑盒子，这也就是 Java 的多态的体现，**「接口帮助我们对这些有相同功能的方法做了统一管理」**。

![image-20211123145537395](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211123145537395.png)

再比如说，我们要做一个画板程序，其中里面有一个面板类，主要负责绘画功能，然后你就定义了这个类，可是在不久的将来，你突然发现这个类满足不了你了，然后你又要重新设计这个类，更糟糕是你可能要废弃这个现有的类，那么其他引用这个类的地方也需要做出修改，显然这样非常麻烦。

如果你一开始定义了一个接口，把绘画功能放在这个接口里，然后定义类时实现这个接口，那么你只需要用这个接口去引用实现它的类就行了，以后要修改的话只不过是引用另一个类而已。**「接口的使用提高了代码的可维护性和可扩展性」**。

另外，从这两个例子我们也能看出，接口不仅**「降低了代码的耦合度」**，而且仅仅描叙了程序对外的服务，不涉及任何具体的实现细节，这样也就比较**「安全」**一些。



## 深浅拷贝

### **引用拷贝**

创建一个指向对象的引用变量的拷贝。

```java
public class QuoteCopy {
    public static void main(String[] args) {
        Teacher teacher = new Teacher("riemann", 28);
        Teacher otherTeacher = teacher;
        System.out.println(teacher);
        System.out.println(otherTeacher);
    }
}

class Teacher {
    private String name;
    private int age;

    public Teacher(String name, int age) {
        this.name = name;
        this.age = age;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }
}

```

输出结果：

```java
com.test.Teacher@28a418fc
com.test.Teacher@28a418fc

```

结果分析：由输出结果可以看出，它们的地址值是相同的，那么它们肯定是同一个对象。`teacher`和`otherTeacher`的`只是引用而已`，他们都指向了一个相同的对象`Teacher(“riemann”,28)`。 这就叫做`引用拷贝`。

![image-20211108172837701](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211108172837701.png)

### **对象拷贝**

创建对象本身的一个副本。

```java
public class ObjectCopy {
    public static void main(String[] args) throws CloneNotSupportedException {
        Teacher teacher = new Teacher("riemann", 28);
        Teacher otherTeacher = (Teacher) teacher.clone();
        System.out.println(teacher);
        System.out.println(otherTeacher);
    }
}

class Teacher implements Cloneable {
    private String name;
    private int age;

    public Teacher(String name, int age) {
        this.name = name;
        this.age = age;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    public Object clone() throws CloneNotSupportedException {
        Object object = super.clone();
        return object;
    }
}

```

输出结果：

```java
com.test.Teacher@28a418fc
com.test.Teacher@5305068a
```

结果分析：由输出结果可以看出，它们的`地址是不同的`，也就是说`创建了新的对象`， 而不是把原对象的地址赋给了一个新的引用变量,这就叫做对象拷贝。

![image-20211108173021670](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211108173021670.png)

**注：深拷贝和浅拷贝都是对象拷贝**

### 浅拷贝

被复制对象的**所有变量都含有与原来的对象相同的值**，而所有的**对其他对象的引用仍然指向原来的对象**。即对象的浅拷贝会对“主”对象进行拷贝，但**不会复制主对象里面的对象**。”里面的对象“会在原来的对象和它的副本之间共享。

**浅拷贝仅仅复制所考虑的对象，而不复制它所引用的对象。**

```java
public class ShallowCopy {
    public static void main(String[] args) throws CloneNotSupportedException {
        Teacher teacher = new Teacher();
        teacher.setName("riemann");
        teacher.setAge(28);

        Student student1 = new Student();
        student1.setName("edgar");
        student1.setAge(18);
        student1.setTeacher(teacher);

        Student student2 = (Student) student1.clone();
        System.out.println("-------------拷贝后-------------");
        System.out.println(student2.getName());
        System.out.println(student2.getAge());
        System.out.println(student2.getTeacher().getName());
        System.out.println(student2.getTeacher().getAge());

        System.out.println("-------------修改老师的信息后-------------");
        // 修改老师的信息
        teacher.setName("jack");
        System.out.println("student1的teacher为： " + student1.getTeacher().getName());
        System.out.println("student2的teacher为： " + student2.getTeacher().getName());

    }
}

class Teacher implements Cloneable {
    private String name;
    private int age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }
}

class Student implements Cloneable {
    private String name;
    private int age;
    private Teacher teacher;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    public Teacher getTeacher() {
        return teacher;
    }

    public void setTeacher(Teacher teacher) {
        this.teacher = teacher;
    }

    public Object clone() throws CloneNotSupportedException {
        Object object = super.clone();
        return object;
    }
}

```

输出结果：

```java
-------------拷贝后-------------
edgar
18
riemann
28
-------------修改老师的信息后-------------
student1的teacher为： jack
student2的teacher为： jack
```

结果分析： 两个引用`student1`和`student2`指向不同的两个对象，但是两个引用`student1`和`student2`中的两个`teacher`**引用指向的是同一个对象**，所以说明是`浅拷贝`。

![image-20211108173440477](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211108173440477.png)

### 深拷贝

深拷贝是一个整个独立的对象拷贝，深拷贝会拷贝所有的属性,并拷贝属性指向的动态分配的内存。当对象和它所引用的对象一起拷贝时即发生深拷贝。深拷贝相比于浅拷贝速度较慢并且花销较大。

`深拷贝把要复制的对象所引用的对象都复制了一遍。`

```java
public class DeepCopy {
    public static void main(String[] args) throws CloneNotSupportedException {
        Teacher teacher = new Teacher();
        teacher.setName("riemann");
        teacher.setAge(28);

        Student student1 = new Student();
        student1.setName("edgar");
        student1.setAge(18);
        student1.setTeacher(teacher);

        Student student2 = (Student) student1.clone();
        System.out.println("-------------拷贝后-------------");
        System.out.println(student2.getName());
        System.out.println(student2.getAge());
        System.out.println(student2.getTeacher().getName());
        System.out.println(student2.getTeacher().getAge());

        System.out.println("-------------修改老师的信息后-------------");
        // 修改老师的信息
        teacher.setName("jack");
        System.out.println("student1的teacher为： " + student1.getTeacher().getName());
        System.out.println("student2的teacher为： " + student2.getTeacher().getName());
    }
}

class Teacher implements Cloneable {
    private String name;
    private int age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    public Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
}

class Student implements Cloneable {
    private String name;
    private int age;
    private Teacher teacher;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    public Teacher getTeacher() {
        return teacher;
    }

    public void setTeacher(Teacher teacher) {
        this.teacher = teacher;
    }

    public Object clone() throws CloneNotSupportedException {
        // 浅复制时：
        // Object object = super.clone();
        // return object;

        // 改为深复制：
        Student student = (Student) super.clone();
        // 本来是浅复制，现在将Teacher对象复制一份并重新set进来
        student.setTeacher((Teacher) student.getTeacher().clone());
        return student;

    }
}

```

输出结果：

```java
-------------拷贝后-------------
edgar
18
riemann
28
-------------修改老师的信息后-------------
student1的teacher为： jack
student2的teacher为： riemann
```



结果分析：
两个引用`student1`和`student2`指向不同的两个对象，两个引用`student1`和`student2`中的两个`teacher`引用指向的是两个对象，但对`teacher`对象的修改只能影响`student1`对象,所以说是`深拷贝`。

![image-20211108173557128](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211108173557128.png)











## 动态代理

### 代理模式的优缺点

1、代理模式能将代理对象与真实被调用的目标对象分离。

2、一定程度上降低了系统的耦合度，扩展性好。

3、可以起到保护目标对象的作用。

4、可以对目标对象的功能增强。

当然，代理模式也是有缺点的：

1、代理模式会造成系统设计中类的数量增加。

2、在客户端和目标对象增加一个代理对象，会造成请求处理速度变慢。

3、增加了系统的复杂度。



### 静态代理

那我先说一下和动态代理相对应的静态代理吧

静态：**最大的区别是静态是编译期就决定了**，在程序运行之前，代理类的.class文件已经存在了。被代理类是什么，代理类实现方式。

举个栗子：

我现在有个接口，是把Json字符串解析成Object 对象，接口如下：

```java
public interface IProvider {
   
  Object getData(String json);
  
}
```

接口实现类如下：

```java
public class SimpleProvider implements IProvider {
    @Override
    public Object getData(String json) {
        //解析json 拿到数据
        return parseJson(json);
    }
```

那现在有个需求，需要对 getData 方法做限流，指定用静态代理的方式。

```Java
public class ProviderProxy implements IProvider{

    //持有一个被代理对象的引用（在这里是SimpleProvider）
    IProvider iProvider;

    public StaticProviderProxy(IProvider iProvider){
        this.iProvider = iProvider;
    }

    @Override
    public Object getData(String json) {
        //做限流检查
        if(callSpeed > flowLimt) {
          //流量超限
           throw FlowLimitException();
        }
        Object object = iProvider.getData(json);
        return object;
    }
}
//main 
public static void main(String[] args) {
  IProvider provider = new ProviderProxy(new SimpleProvider());
    provider.getData("{\"data\":{}}");
}
```

这就是静态代理，**代理类（ProviderProxy）实现和需要做方法增强的被代理类（SimpleProvider）实现同一个接口（IProvider）**，方法具体实现上做增强，这里是限流检查。

### 动态代理

Java 动态代理

- 动态代理类：在程序运行时，通过反射机制动态生成。
- 动态代理类通常代理接口下的所有类。静态一般指定某个类代理。
- 动态代理事先不知道要代理的是什么，只有在运行的时候才能确定。静态是编译期确定的。

还是以`IProvider` 接口为例，同样是要对 `SimpleProvider` 做增强，如下：

```Java
public class ProviderHandler implements InvocationHandler {
    Object target;

    public Object bind(Object target){
        this.target = target;
        //这里生成了代理对象
        return Proxy.newProxyInstance(target.getClass().getClassLoader(),
                target.getClass().getInterfaces(), this);
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        //限流
        flowLimit(args);
        Object obj = method.invoke(target, args);
        //打印日志
        logger.info("print log...");
        return obj;
    }
}
//main
public static void main(String[] args) {
   ProviderHandler providerHandler = new ProviderHandler();
   IProvider iProvider = (IProvider) providerHandler.bind(new SimpleProvider());
   iProvider.getData("weibo.data");
}
```

这里有三个对象：

1. SimpleProvider 对象 , 我们称之为被代理对象
2. ProviderHandler 对象,我们称之为执行者对象
3. Proxy对象 （通过在ProviderHandler bind方法中使用Proxy.newProxyInstance生成的对象） 我们称之为代理对象

Proxy是真正的代理类，SimpleProvider是被代理类，ProviderHandler是执行方法增强的执行者。

我们是为了增强SimpleProvider （被代理对象）的`getData`方法，就Proxy对象来代理被代理对象的执行，Proxy不亲自来做这件事，而是交给执行者对象ProviderHandler 来实现增加的目录，执行调用前的限流校验。

#### newProxyInstance源码

```Java

public static Object newProxyInstance(ClassLoader loader,
                                          Class<?>[] interfaces,
                                          InvocationHandler h)
        throws IllegalArgumentException
    {
        //对 Invocationhandler做判空处理
        Objects.requireNonNull(h);
        //复制[IProvider接口]
        final Class<?>[] intfs = interfaces.clone();

       //根据IProvider的类加载器IProvider接口生成了Proxy类,关键：根据类加载器和接口对象在JVM缓存中生成一个类对象
        Class<?> cl = getProxyClass0(loader, intfs);
        //获取构造器
        final Constructor<?> cons = cl.getConstructor(constructorParams);
        //保存InvocationHandler的引用
        final InvocationHandler ih = h;
        //通过构造器实例化Proxy代理对象
        return cons.newInstance(new Object[]{h});
    
```

生成的Proxy对象是怎样调用执行者的invoke函数的。

这个地方通过这段代码将Proxy0的class字节码输出到文件。

反编译Proxy0如下：

```Java
//Proxy0 是动态生成的类，继承自Proxy，实现了IProvider接口
public final class $Proxy0 extends Proxy implements IProvider {
    private static Method m1;
    private static Method m2;
    private static Method m3;
    private static Method m0;

    public $Proxy0(InvocationHandler var1) throws  {
        super(var1);
    }

    public final boolean equals(Object var1) throws  {
        try {
            return ((Boolean)super.h.invoke(this, m1, new Object[]{var1})).booleanValue();
        } catch (RuntimeException | Error var3) {
            throw var3;
        } catch (Throwable var4) {
            throw new UndeclaredThrowableException(var4);
        }
    }

    public final String toString() throws  {
        try {
            return (String)super.h.invoke(this, m2, (Object[])null);
        } catch (RuntimeException | Error var2) {
            throw var2;
        } catch (Throwable var3) {
            throw new UndeclaredThrowableException(var3);
        }
    }

    public final String getData(String var1) throws  {
        try {
            //m3就是IProvider 接口的getData方法 
            //super.h 是父类java.lang.reflect.Proxy的属性 InvocationHandler
            return (String)super.h.invoke(this, m3, new Object[]{var1});
        } catch (RuntimeException | Error var3) {
            throw var3;
        } catch (Throwable var4) {
            throw new UndeclaredThrowableException(var4);
        }
    }

    public final int hashCode() throws  {
        try {
            return ((Integer)super.h.invoke(this, m0, (Object[])null)).intValue();
        } catch (RuntimeException | Error var2) {
            throw var2;
        } catch (Throwable var3) {
            throw new UndeclaredThrowableException(var3);
        }
    }

    static {
        try {
            m1 = Class.forName("java.lang.Object").getMethod("equals", new Class[]{Class.forName("java.lang.Object")});
            m2 = Class.forName("java.lang.Object").getMethod("toString", new Class[0]);
            //m3就是IProvider 接口的getData方法
            m3 = Class.forName("aop.IProvider").getMethod("getData", new Class[]{Class.forName("java.lang.String")});
            m0 = Class.forName("java.lang.Object").getMethod("hashCode", new Class[0]);
        } catch (NoSuchMethodException var2) {
            throw new NoSuchMethodError(var2.getMessage());
        } catch (ClassNotFoundException var3) {
            throw new NoClassDefFoundError(var3.getMessage());
        }
    }
}
```

重点在 `return (String)super.h.invoke(this, m3, new Object[]{var1});`代码。



$Proxy0继承Proxy类，实现了IProvider接口，所以也有getData()函数，而getData函数调用的是执行者InvocationHandler的invoke方法，m3是通过反射拿到的Method对象，所以看getData调用invoke传递的。三个参数，第一个是Proxy对象，第二个是getData方法对象，第三个是参数。

总结一下：

- 动态代理的本质就是，生成一个继承自Proxy的类，然后实现被代理接口(IProvider)的类 - Proxy0。
- Proxy0 持有InvocationHandler实例，InvocationHandler 持有SimpleProvider实例。Proxy0调用接口 getData方法时，先传递给InvocationHandler，InvocationHandler再传递给SimpleProvider实例。

动态代理实际上就是帮我们在JVM内存中直接重新生成了代理类class和对应类对象，然后通过执行者InvocationHandler调用被代理对象SimpleProvider。

## unsafe类

Unsafe类是一个位于`sun.misc`包下的类，它提供了一些相对底层方法，能够让我们接触到一些更接近操作系统底层的资源，如系统的内存资源、cpu指令等。

### Unsafe 基础

查看Unsafe类的源码，可以看到它被`final`修饰不允许被继承，并且构造函数为`private`类型，即不允许我们手动调用构造方法进行实例化，只有在`static`静态代码块中，以单例的方式初始化了一个Unsafe对象：

```java
public final class Unsafe {
    private static final Unsafe theUnsafe;
    ...
    private Unsafe() {
    }
    ...
    static {
        theUnsafe = new Unsafe();
    }   
}
```

在Unsafe类中，提供了一个静态方法`getUnsafe`

```java
@CallerSensitive
public static Unsafe getUnsafe() {
    Class var0 = Reflection.getCallerClass();
    if (!VM.isSystemDomainLoader(var0.getClassLoader())) {
        throw new SecurityException("Unsafe");
    } else {
        return theUnsafe;
    }
}
```

但是如果我们直接调用这个静态方法，会抛出异常：

```java
Exception in thread "main" java.lang.SecurityException: Unsafe
 at sun.misc.Unsafe.getUnsafe(Unsafe.java:90)
 at com.cn.test.GetUnsafeTest.main(GetUnsafeTest.java:12)
```

异常的原因是，在`getUnsafe`这个方法中，会对调用者的`classLoader`进行检查，然后判断一下当前类是否由`Bootstrap classLoader`加载，如果不是的话那么就会抛出一个`SecurityException`异常。也就是说，只有启动类加载器加载的类才能够调用Unsafe类中的方法，来防止这些方法在不可信的代码中被调用。

那么，为什么要对Unsafe类进行这么谨慎的使用限制呢，说到底，还是因为它实现的功能过于底层，例如直接进行内存操作、绕过jvm的安全检查创建对象等等，概括的来说，Unsafe类实现功能可以被分为下面8类：

![image-20210910085646534](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910085646534.png)

### 创建实例

那么如果我们执意想要在自己的代码中调用Unsafe类的方法，应该怎么获取一个它的实例对象呢，答案是利用反射获得Unsafe类中已经实例化完成的单例对象：

```java
public static Unsafe getUnsafe() throws IllegalAccessException {
    Field unsafeField = Unsafe.class.getDeclaredField("theUnsafe");
    //Field unsafeField = Unsafe.class.getDeclaredFields()[0]; //也可以这样，作用相同
    unsafeField.setAccessible(true);
    Unsafe unsafe =(Unsafe) unsafeField.get(null);
    return unsafe;
}
```



在获取到Unsafe的实例对象后，我们就可以使用它为所欲为了，先来尝试使用它对一个对象的属性进行读写：

```java
public void fieldTest(Unsafe unsafe) throws NoSuchFieldException {
    User user=new User();
    long fieldOffset = unsafe.objectFieldOffset(User.class.getDeclaredField("age"));
    System.out.println("offset:"+fieldOffset);
    unsafe.putInt(user,fieldOffset,20);
    System.out.println("age:"+unsafe.getInt(user,fieldOffset));
    System.out.println("age:"+user.getAge());
}
```

运行代码输出如下，可以看到通过Unsafe类的`objectFieldOffset`方法获取了对象中字段的偏移地址，这个偏移地址不是内存中的绝对地址而是一个相对地址，之后再通过这个偏移地址对`int`类型字段的属性值进行了读写操作，通过结果也可以看到Unsafe的方法和类中的`get`方法获取到的值是相同的。

### native方法

java中，这类方法被称为`native`方法（`Native Method`），简单的说就是由java调用非java代码的接口，被调用的方法是由非java 语言实现的，例如它可以由C或C++语言来实现，并编译成DLL，然后直接供java进行调用。`native`方法是通过JNI（`Java Native Interface`）实现调用的，从 java1.1开始 JNI 标准就是java平台的一部分，它允许java代码和其他语言的代码进行交互。

![image-20210910085928982](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910085928982.png)

Unsafe类中的很多基础方法都属于`native`方法，那么为什么要使用`native`方法呢？原因可以概括为以下几点：

- 需要用到 java 中不具备的依赖于操作系统的特性，**java在实现跨平台的同时要实现对底层的控制**，需要借助其他语言发挥作用
- 对于其他语言已经完成的一些现成功能，可以使用java直接调用
- **程序对时间敏感或对性能要求非常高时**，有必要使用更加底层的语言，例如C/C++甚至是汇编

在`juc`包的很多并发工具类在实现并发机制时，都调用了`native`方法，通过它们打破了java运行时的界限，**能够接触到操作系统底层的某些功能**。对于同一个`native`方法，**不同的操作系统可能会通过不同的方式来实现，但是对于使用者来说是透明的，最终都会得到相同的结果**

### Unsafe 应用

#### 内存屏障

**编译器和CPU会在保证程序输出结果一致的情况下，会对代码进行重排序**，从指令优化角度提升性能。而指令重排序可能会带来一个不好的结果，导致CPU的高速缓存和内存中数据的不一致，而**内存屏障（`Memory Barrier`）就是通过组织屏障两边的指令重排序从而避免编译器和硬件的不正确优化情况。**

在硬件层面上，内存屏障是CPU为了防止代码进行重排序而提供的指令，不同的硬件平台上实现内存屏障的方法可能并不相同。在java8中，引入了3个内存屏障的函数，它屏蔽了操作系统底层的差异，允许在代码中定义、并统一由jvm来生成内存屏障指令，来实现内存屏障的功能。Unsafe中提供了下面三个内存屏障相关方法：

```java
public native void loadFence();
//禁止写操作重排序
public native void storeFence();
//禁止读、写操作重排序
public native void fullFence();
```

#### CAS操作

在`juc`包的并发工具类中大量地使用了CAS操作，其作为乐观锁在并发工具类中广泛发挥了作用。在Unsafe类中，提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的CAS操作。以`compareAndSwapInt`方法为例：

```java
public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x);
```

参数中`o`为需要更新的对象，`offset`是对象`o`中整形字段的偏移量，如果这个字段的值与`expected`相同，则将字段的值设为`x`这个新值，并且此更新是不可被中断的，也就是一个原子操作。下面是一个使用`compareAndSwapInt`的例子：

```java
private volatile int a;
public static void main(String[] args){
    CasTest casTest=new CasTest();
    new Thread(()->{
        for (int i = 1; i < 5; i++) {
            casTest.increment(i);
            System.out.print(casTest.a+" ");
        }
    }).start();
    new Thread(()->{
        for (int i = 5 ; i <10 ; i++) {
            casTest.increment(i);
            System.out.print(casTest.a+" ");
        }
    }).start();
}

private void increment(int x){
    while (true){
        try {
            long fieldOffset = unsafe.objectFieldOffset(CasTest.class.getDeclaredField("a"));
            if (unsafe.compareAndSwapInt(this,fieldOffset,x-1,x))
                break;
        } catch (NoSuchFieldException e) {
            e.printStackTrace();
        }
    }
}
```



#### 线程调度

Unsafe类中提供了`park`、`unpark`、`monitorEnter`、`monitorExit`、`tryMonitorEnter`方法进行线程调度

```java
public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    UNSAFE.park(false, 0L);
    setBlocker(t, null);
}
public static void unpark(Thread thread) {
    if (thread != null)
        UNSAFE.unpark(thread);
}
```

LockSupport的`park`方法调用了Unsafe的`park`方法来阻塞当前线程，此方法将线程阻塞后就不会继续往后执行，直到有其他线程调用`unpark`方法唤醒当前线程。下面的例子对Unsafe的这两个方法进行测试：

```java
public static void main(String[] args) {
    Thread mainThread = Thread.currentThread();
    new Thread(()->{
        try {
            TimeUnit.SECONDS.sleep(5);
            System.out.println("subThread try to unpark mainThread");
            unsafe.unpark(mainThread);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }).start();

    System.out.println("park main mainThread");
    unsafe.park(false,0L);
    System.out.println("unpark mainThread success");
}
程序输出为：
```

程序运行的流程也比较容易看懂，子线程开始运行后先进行睡眠，确保主线程能够调用`park`方法阻塞自己，子线程在睡眠5秒后，调用`unpark`方法唤醒主线程，使主线程能继续向下执行。整个流程如下图所示：

![image-20210910090723332](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910090723332.png)

此外，Unsafe源码中`monitor`相关的三个方法已经被标记为`deprecated`，不建议被使用：

```java
//获得对象锁
@Deprecated
public native void monitorEnter(Object var1);
//释放对象锁
@Deprecated
public native void monitorExit(Object var1);
//尝试获得对象锁
@Deprecated
public native boolean tryMonitorEnter(Object var1);
```

`monitorEnter`方法用于获得对象锁，`monitorExit`用于释放对象锁，如果对一个没有被`monitorEnter`加锁的对象执行此方法，会抛出`IllegalMonitorStateException`异常。`tryMonitorEnter`方法尝试获取对象锁，如果成功则返回`true`，反之返回`false`。



## 内存泄漏

### JAVA 中的内存泄露

   在C++中，所有被分配了内存的对象，不再使用后，都必须程序员手动的释放他们。所以，每个类，都会含有一个析构函数，作用就是完成清理工作，如果我们忘记了某些对象的释放，就会造成内存泄露。

    但是在Java中，我们不用（也没办法）自己释放内存，无用的对象由GC自动清理，这也极大的简化了我们的编程工作。但，实际有时候一些不再会被使用的对象，在GC看来不能被释放，就会造成内存泄露。
    
    我们知道，对象都是有生命周期的，有的长，有的短，如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露
```java
public class Simple {
 
    Object object;
 
    public void method1(){
        object = new Object();
    //...其他代码
    }
}
```

 这里的object实例，其实我们期望它只作用于method1()方法中，且其他地方不会再用到它，但是，当method1()方法执行完成后，object对象所分配的内存不会马上被认为是可以被释放的对象，只有在Simple类创建的对象被释放后才会被释放，严格的说，这就是一种内存泄露。解决方法就是将object作为method1()方法中的局部变量。当然，如果一定要这么写，可以改为这样：

```java
public class Simple {
 
    Object object;
 
    public void method1(){
        object = new Object();
        //...其他代码
        object = null;
    }
}
```

  这样，之前“new Object()”分配的内存，就可以被GC回收。

### 一些容易发生内存泄露的例子和解决方法

    像上面例子中的情况很容易发生，也是我们最容易忽略并引发内存泄露的情况，解决的原则就是尽量减小对象的作用域（比如android studio中，上面的代码就会发出警告，并给出的建议是将类的成员变量改写为方法内的局部变量）以及手动设置null值。
    
    至于作用域，需要在我们编写代码时多注意；null值的手动设置，我们可以看一下Java容器LinkedList源码
```java
//删除指定节点并返回被删除的元素值
E unlink(Node<E> x) {
    //获取当前值和前后节点
    final E element = x.item;
    final Node<E> next = x.next;
    final Node<E> prev = x.prev;
    if (prev == null) {
        first = next; //如果前一个节点为空(如当前节点为首节点)，后一个节点成为新的首节点
    } else {
        prev.next = next;//如果前一个节点不为空，那么他先后指向当前的下一个节点
        x.prev = null;
    }
    if (next == null) {
        last = prev; //如果后一个节点为空(如当前节点为尾节点)，当前节点前一个成为新的尾节点
    } else {
        next.prev = prev;//如果后一个节点不为空，后一个节点向前指向当前的前一个节点
        x.next = null;
    }
    x.item = null;
    size--;
    modCount++;
    return element;
}
```

  除了修改节点间的关联关系，我们还要做的就是赋值为null的操作，不管GC何时会开始清理，我们都应及时的将无用的对象标记为可被清理的对象。

###  各种提供了close()方法的对象

    比如数据库连接（dataSourse.getConnection()），网络连接(socket)和io连接，以及使用其他框架的时候，除非其显式的调用了其close()方法（或类似方法）将其连接关闭，否则是不会自动被GC回收的。其实原因依然是长生命周期对象持有短生命周期对象的引用。
    
    可能很多人使用过Hibernate，我们操作数据库时，通过SessionFactory获取一个session：
```java
Session session=sessionFactory.openSession();
```

  完成后我们必须调用close()方法关闭：

    SessionFactory就是一个长生命周期的对象，而session相对是个短生命周期的对象，但是框架这么设计是合理的：它并不清楚我们要使用session到多久，于是只能提供一个方法让我们自己决定何时不再使用。
    
    因为在close()方法调用之前，可能会抛出异常而导致方法不能被调用，我们通常使用try语言，然后再finally语句中执行close()等清理工作：
```java
try{
    session=sessionFactory.openSession();
    //...其他操作
}finally{
    session.close();
}
```

### 单例模式导致的内存泄露

 单例模式，很多时候我们可以把它的生命周期与整个程序的生命周期看做差不多的，所以是一个长生命周期的对象。如果这个对象持有其他对象的引用，也很容易发生内存泄露。

  总的来说，内存泄露问题，还是编码不认真导致的，我们并不能责怪JVM没有更合理的清理。

## 接口

首先最重要的一点从oop的七大原则上考虑，接口分离原则

接口的含义：接口就是提供一种统一的’协议’,而接口中的属性也属于’协议’中的成员.它们是公共的,静态的,最终的常量.相当于全局常量。并且java中允许多继承接口，那好几个类实现了这个接口，这个类对这个变量改一下，那个类对这个变量改一下，那这个变量就有问题，无法做到统一。前面也说到，接口更多的是一种统一的协议和规范，常量就相当于是具体的一个规范，实现我接口的所有类都不可以对这个规范做出修改。

抽象类是不’完全’的类,相当于是接口和具体类的一个中间层.即满足接口的抽象,也满足具体的实现.

**接口的设计原则**：接口的设计应该遵循最小接口原则，不要把用户不使用的方法塞进同一个接口里。如果一个接口的方法没有被使用到，则说明该接口过胖，应该将其分割成几个功能专一的接口。

**接口的依赖（继承）原则**：如果一个接口a继承另一个接口b，则接口a相当于继承了接口b的方法，那么继承了接口b后的接口a也应该遵循上述原则：不应该包含用户不使用的方法。 反之，则说明接口a被b给污染了，应该重新设计它们的关系。

1. **一个类对一个类的依赖应该建立在最小的接口上**
2. **建立单一接口，不要建立庞大臃肿的接口**
3. **尽量细化接口，接口中的方法尽量少**

1、我觉得接口更多的话是一种规范，比如我们一个汽车的接口，那具体实现的类不同就用不同的形态，可以说是多态吧

2、接口不能被实例化，接口连构造函数都不可以有。抽象类可以有构造函数，通过创建子类的时候会把父类先进行一个加载

3、接口中的成员不能加“访问修饰符”，接口中的成员访问修饰符默认为public ，变量的修饰符是stati final

4、接口中的方法是不能有方法体的，我个人觉得从JVM虚拟机的这个角度来说，我们要加载的肯定是一个完整的类，而接口只是定义了一个方法，里面没有任何的实现，可以说算是一个不完整的类。所以虚拟机拒绝加载。

5、接口中只有方法、属性、索引器、事件，不能够有“字段”。

6、接口与接口之间可以继承，并且可以多继承。

7、实现接口的自雷必须实现该接口的全部成员。所以接口要遵循接口隔离原则，降低功能之间的耦合度。

8、一个类可以同时继承多个接口，如果一个类继承接口的同时，也继承了类，则先继承类，再写集成的接口。

9、当一个抽象类实现接口的时候，如果不想实现接口的成员，可以把该成员实现为abstract.

10、显示实现接口，只能用接口变量来调用，因为（显示接口后成员会变成private);

## String类

### **为什么String要设计成不可变**

**这个问题，困扰过很多人，甚至有人直接问过Java的创始人James Gosling。**

在一次采访中James Gosling被问到什么时候应该使用不可变变量，他给出的回答是:

```
I would use an immutable whenever I can.
```

主要是从缓存、安全性、线程安全和性能等角度触发的。

**缓存** 

字符串是使用最广泛的数据结构。大量的字符串的创建是非常耗费资源的，所以，Java提供了对字符串的缓存功能，可以大大的节省堆空间。

JVM中专门开辟了一部分空间来存储Java字符串，那就是字符串池。

通过字符串池，两个内容相同的字符串变量，可以从池中指向同一个字符串对象，从而节省了关键的内存资源。

String s = "abcd";
String s2 = s;

对于这个例子，s和s2都表示"abcd"，所以他们会指向字符串池中的同一个字符串对象：

![image-20210910100329123](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910100329123.png)但是，之所以可以这么做，主要是因为字符串的不变性。试想一下，如果字符串是可变的，我们一旦修改了s的内容，那必然导致s2的内容也被动的改变了，这显然不是我们想看到的。

#### 安全性 

字符串在Java应用程序中广泛用于存储敏感信息，如用户名、密码、连接url、网络连接等。JVM类加载器在加载类的时也广泛地使用它。

因此，保护String类对于提升整个应用程序的安全性至关重要。

当我们在程序中传递一个字符串的时候，如果这个字符串的内容是不可变的，那么我们就可以相信这个字符串中的内容。

但是，如果是可变的，那么这个字符串内容就可能随时都被修改。那么这个字符串内容就完全可信了。这样整个系统就没有安全性可言了。

#### 线程安全

不可变会自动使字符串成为线程安全的，因为当从多个线程访问它们时，它们不会被更改。

因此，一般来说，不可变对象可以在同时运行的多个线程之间共享。它们也是线程安全的，因为如果线程更改了值，那么将在字符串池中创建一个新的字符串，而不是修改相同的值。因此，字符串对于多线程来说是安全的。

### 如何实现不可变

1）首先，char 数组是 private 的，并且 `String` 类没有对外提供修改这个数组的方法，所以它初始化之后外界没有有效的手段去改变它；

2）其次，`String` 类被 final 修饰的，也就是不可继承，避免被他人继承后破坏；

3）最重要的！是因为 Java 作者在 `String` 的所有方法里面，都很小心地避免去修改了 char 数组中的数据，**涉及到对 char 数组中数据进行修改的操作全部都会重新创建一个 `String` 对象**。你可以随便翻个源码看看来验证这个说法，比如 substring 方法：

![image-20211123154713240](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211123154713240.png)















## 128陷阱

```
	int int1 = 10;
        int int2 = 10;

        Integer integer1 = new Integer(10);
        Integer integer2 = new Integer(10);
        Integer integer3 = new Integer(127);

        Integer a1 = 127; //或者写成Integer a1 = Integer.valueOf(127);
        Integer a2 = 127;//或者写成Integer a2 = Integer.valueOf(127);

        Integer a = 128;
        Integer b = 128;

        System.out.println(int1 == int2);
        System.out.println(int1 == integer1);
        System.out.println(integer1 == integer2);
        System.out.println(integer3 == a1);
        System.out.println(a1 == a2);
        System.out.println(a == b);
```

![image-20210416121236365](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416121236365.png)

## Arraylist

ArrayList是Vector的翻版，区别在于ArrayList是线程不安全的，而Vector则是线程安全的。但是Vector是一个较老的集合，具有很多缺点，不建议使用，这里我们就不对其进行分析了。

ArrayList 可以说是我们使用最多的 List 集合，它有以下特点：

它是基于数组实现的List类
可以动态地调整容量
有序的（元素输出顺序与输入顺序一致）
元素可以为 null
不同步，非线程安全，效率高
查询快，增删慢
占用空间更小，对比 LinkedList，不用占用额外空间维护链表结构
ArrayList 为什么有这些优点呢？我们通过源码来分析分析。在阅读源码前先来看看ArrayList继承关系。

### 继承关系图

![image-20210804091227350](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804091227350.png)

#### 

可以看到，ArrayList是AbstractList的子类，同时实现了List接口。除此之外，它还实现了三个标识型接口，这几个接口都没有任何方法，仅作为标识表示实现类具备某项功能。RandomAccess表示实现类支持快速随机访问，Cloneable表示实现类支持克隆，具体表现为重写了clone方法，java.io.Serializable则表示支持序列化，如果需要对此过程自定义，可以重写writeObject与readObject方法。

### 成员变量

```java
// 序列号
private static final long serialVersionUID = 8683452581122892189L;
// 数组初始容量为 10
private static final int DEFAULT_CAPACITY = 10;
// 空对象数组
private static final Object[] EMPTY_ELEMENTDATA = {};
// 缺省空对象数组
private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
// 底层数据结构，数组
transient Object[] elementData;
// 数组元素个数，默认为0
private int size;
// 最大数组容量
private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

```



### 构造方法

```java
//默认构造方法，初始为空数组。
//只有插入一条数据后才会扩展为10，而实际上默认是空的
 public ArrayList() {
    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
}

//根据指定容量创建对象数组
public ArrayList(int initialCapacity) {
    if (initialCapacity > 0) {
        //创建initialCapacity大小的数组
        this.elementData = new Object[initialCapacity];
    } else if (initialCapacity == 0) {
        //创建空数组
        this.elementData = EMPTY_ELEMENTDATA;
    } else {
        throw new IllegalArgumentException("Illegal Capacity: "+
                                               initialCapacity);
    }
}

/**
 * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。
 */
public ArrayList(Collection<? extends E> c) {
    //转换最主要的是toArray()，这在Collection中就定义了
    elementData = c.toArray();
    if ((size = elementData.length) != 0) {
        // c.toArray 有可能不返回一个 Object 数组
        if (elementData.getClass() != Object[].class)
            //使用 Arrays.copy 方法拷创建一个 Object 数组
            elementData = Arrays.copyOf(elementData, size, Object[].class);
    } else {
        // 替换为空数组
        this.elementData = EMPTY_ELEMENTDATA;
    }
}

```

以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。

### 内部类

```java
(1)private class Itr implements Iterator<E>  
(2)private class ListItr extends Itr implements ListIterator<E>  
(3)private class SubList extends AbstractList<E> implements RandomAccess  
(4)static final class ArrayListSpliterator<E> implements Spliterator<E>  

```

ArrayList有四个内部类，其中的Itr是实现了Iterator接口，同时重写了里面的hasNext()， next()， remove() 等方法；其中的ListItr 继承 Itr，实现了ListIterator接口，同时重写了hasPrevious()， nextIndex()， previousIndex()， previous()， set(E e)， add(E e) 等方法，所以这也可以看出了 Iterator和ListIterator的区别：ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。

### add()方法（有四个）

```java
//添加一个特定的元素到list的末尾
public boolean add(E e) {
    //先确保elementData数组的长度足够，size是数组中数据的个数，因为要添加一个元素，所以size+1，先判断size+1的这个个数数组能否放得下，在这个方法中去判断数组长度是否够用
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    //在数据中正确的位置上放上元素e，并且size++
    elementData[size++] = e;
    return true;
}

//在指定位置添加一个元素
public void add(int index, E element) {
    rangeCheckForAdd(index);

    //先确保elementData数组的长度足够
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    //将数据整体向后移动一位，空出位置之后再插入，效率不太好
    System.arraycopy(elementData, index, elementData, index + 1,
                         size - index);
    elementData[index] = element;
    size++;
}

// 校验插入位置是否合理
private void rangeCheckForAdd(int index) {
    //插入的位置肯定不能大于size 和小于0
    if (index > size || index < 0)   
        //如果是，就报越界异常
        throw new IndexOutOfBoundsException(outOfBoundsMsg(index));
}

//添加一个集合
public boolean addAll(Collection<? extends E> c) {
    //把该集合转为对象数组
    Object[] a = c.toArray();
    int numNew = a.length;
    //增加容量
    ensureCapacityInternal(size + numNew);  // Increments modCount
    //挨个向后迁移
    System.arraycopy(a, 0, elementData, size, numNew);
    size += numNew;
    //新数组有元素，就返回 true
    return numNew != 0;
}

//在指定位置，添加一个集合
public boolean addAll(int index, Collection<? extends E> c) {
    rangeCheckForAdd(index);

    Object[] a = c.toArray();
    int numNew = a.length;
    ensureCapacityInternal(size + numNew);  // Increments modCount

    int numMoved = size - index;
    //原来的数组挨个向后迁移
    if (numMoved > 0)
        System.arraycopy(elementData, index, elementData, index + numNew,
                         numMoved);
    //把新的集合数组 添加到指定位置
    System.arraycopy(a, 0, elementData, index, numNew);
    size += numNew;
    return numNew != 0;
}

```

虽说 System.arraycopy 是底层方法，但每次添加都后移一位还是不太好。

### 对数组的容量进行调整

以上两种添加数据的方式都调用到了`ensureCapacityInternal`这个方法，我们看看它是如何完成工作的

```java
//确保内部容量够用
private void ensureCapacityInternal(int minCapacity) {
    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
}

//计算容量。判断初始化的elementData是不是空的数组,如果是空的话，返回默认容量10与minCapacity=size+1的较大值者。
private static int calculateCapacity(Object[] elementData, int minCapacity) {
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        return Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    return minCapacity;
}

//确认实际的容量，这个方法就是真正的判断elementData是否够用
private void ensureExplicitCapacity(int minCapacity) {
    modCount++;

    //minCapacity如果大于了实际elementData的长度，那么就说明elementData数组的长度不够用，不够用那么就要增加elementData的length。这里有的小伙伴就会模糊minCapacity到底是什么呢，这里解释一下

/**
     * 当我们要 add 进第1个元素到 ArrayList 时，elementData.length 为0 （因为还是一个空的 list），因为执行了 `ensureCapacityInternal()` 方法 ，所以 minCapacity 此时为10。此时，`minCapacity - elementData.length > 0 `成立，所以会进入 `grow(minCapacity)` 方法。
     * 当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，`minCapacity - elementData.length > 0 ` 不成立，所以不会进入 （执行）`grow(minCapacity)` 方法。
     * 添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。
     * 直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。
     */
    // overflow-conscious code
    if (minCapacity - elementData.length > 0)
        //ArrayList能自动扩展大小的关键方法就在这里了
        grow(minCapacity);
}

//扩容核心方法
private void grow(int minCapacity) {
    //将扩充前的elementData大小给oldCapacity
    // overflow-conscious code
    int oldCapacity = elementData.length;
    //新容量newCapacity是1.5倍的旧容量oldCapacity
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    //这句话就是适应于elementData就空数组的时候，length=0，那么oldCapacity=0，newCapacity=0，所以这个判断成立，在这里就是真正的初始化elementData的大小了，就是为10。
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    //如果newCapacity超过了最大的容量限制，就调用hugeCapacity，也就是将能给的最大值给newCapacity
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    //新的容量大小已经确定好了，就copy数组，改变容量大小。
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}

//这个就是上面用到的方法，很简单，就是用来赋最大值。
private static int hugeCapacity(int minCapacity) {
    if (minCapacity < 0) // overflow
        throw new OutOfMemoryError();
    //如果minCapacity都大于MAX_ARRAY_SIZE，那么就Integer.MAX_VALUE返回，反之将MAX_ARRAY_SIZE返回。因为maxCapacity是三倍的minCapacity，可能扩充的太大了，就用minCapacity来判断了。
	//Integer.MAX_VALUE:2147483647   MAX_ARRAY_SIZE：2147483639  也就是说最大也就能给到第一个数值。还是超过了这个限制，就要溢出了。相当于arraylist给了两层防护。
    return (minCapacity > MAX_ARRAY_SIZE) ?
        Integer.MAX_VALUE :
    MAX_ARRAY_SIZE;
}

```

至此，我们彻底明白了`ArrayList`的扩容机制了。首先创建一个空数组**elementData**，第一次插入数据时直接扩充至10，然后如果**elementData**的长度不足，就扩充至1.5倍，如果扩充完还不够，就使用需要的长度作为**elementData**的长度。

### 大数据插入问题

这样的方式显然比我们例子中好一些，但是在遇到大量数据时还是会频繁的拷贝数据。那么如何缓解这种问题呢，ArrayList为我们提供了两种可行的方案：

使用ArrayList(int initialCapacity)这个有参构造，在创建时就声明一个较大的大小，这样解决了频繁拷贝问题，但是需要我们提前预知数据的数量级，也会一直占有较大的内存。
除了添加数据时可以自动扩容外，我们还可以在插入前先进行一次扩容。只要提前预知数据的数量级，就可以在需要时直接一次扩充到位，与ArrayList(int initialCapacity)相比的好处在于不必一直占有较大内存，同时数据拷贝的次数也大大减少了。这个方法就是ensureCapacity(int minCapacity)，其内部就是调用了ensureCapacityInternal(int minCapacity)。

我们这里使用ensureCapacity()方法测试

```java
public class EnsureCapacityTest {
	public static void main(String[] args) {
        ArrayList<Object> list = new ArrayList<Object>();
        final int N = 10000000;
        long startTime = System.currentTimeMillis();
        for (int i = 0; i < N; i++) {
            list.add(i);
        }
        long endTime = System.currentTimeMillis();
        System.out.println("使用ensureCapacity方法前：" + (endTime - startTime));

        list = new ArrayList<Object>();
        long startTime1 = System.currentTimeMillis();
        list.ensureCapacity(N);
        for (int i = 0; i < N; i++) {
            list.add(i);
        }
        long endTime1 = System.currentTimeMillis();
        System.out.println("使用ensureCapacity方法后：" + (endTime1 - startTime1));
    }
}

```

![image-20210804091842859](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804091842859.png)

通过运行结果，我们可以很明显的看出向 ArrayList 添加大量元素之前最好先使用`ensureCapacity` 方法，以减少增量重新分配的次数

### remove()方法

其实这几个删除方法都是类似的。

```java
//根据索引删除指定位置的元素
public E remove(int index) {
    //检查index的合理性
    rangeCheck(index);
	//这个作用很多，比如用来检测快速失败的一种标志。
    modCount++;
    //通过索引直接找到该元素
    E oldValue = elementData(index);

    //计算要移动的位数。
    int numMoved = size - index - 1;
    if (numMoved > 0)
        //移动元素，挨个往前移一位。
        System.arraycopy(elementData, index+1, elementData, index,
                         numMoved);
    //将--size上的位置赋值为null，让gc(垃圾回收机制)更快的回收它。
    elementData[--size] = null; // clear to let GC do its work
	//返回删除的元素。
    return oldValue;
}

//从此列表中删除指定元素的第一个匹配项，如果存在，则删除。通过元素来删除该元素，就依次遍历，如果有这个元素，就将该元素的索引传给fastRemobe(index)，使用这个方法来删除该元素，fastRemove(index)方法的内部跟remove(index)的实现几乎一样，这里最主要是知道arrayList可以存储null值
public boolean remove(Object o) {
    if (o == null) {
        //挨个遍历找到目标
        for (int index = 0; index < size; index++)
            if (elementData[index] == null) {
                //快速删除
                fastRemove(index);
                return true;
            }
    } else {
        for (int index = 0; index < size; index++)
            if (o.equals(elementData[index])) {
                fastRemove(index);
                return true;
            }
    }
    return false;
}

//内部方法，“快速删除”，就是把重复的代码移到一个方法里
private void fastRemove(int index) {
    modCount++;
    int numMoved = size - index - 1;
    if (numMoved > 0)
        System.arraycopy(elementData, index+1, elementData, index,
                         numMoved);
    elementData[--size] = null; // clear to let GC do its work
}

//删除或者保留指定集合中的元素
//用于两个方法，一个removeAll()：它只清除指定集合中的元素，retainAll()用来测试两个集合是否有交集。　
private boolean batchRemove(Collection<?> c, boolean complement) {
    //将原集合，记名为A
    final Object[] elementData = this.elementData;
    //r用来控制循环，w是记录有多少个交集
    int r = 0, w = 0;
    boolean modified = false;
    try {
        //遍历 ArrayList 集合
        for (; r < size; r++)
            //参数中的集合c一次检测集合A中的元素是否有
            if (c.contains(elementData[r]) == complement)
                //有的话，就给集合A
                elementData[w++] = elementData[r];
    } finally {
        //发生了异常，直接把 r 后面的复制到 w 后面
        if (r != size) {
            //将剩下的元素都赋值给集合A
            System.arraycopy(elementData, r,
                             elementData, w,
                             size - r);
            w += size - r;
        }
        if (w != size) {
            //这里有两个用途，在removeAll()时，w一直为0，就直接跟clear一样，全是为null。
            //retainAll()：没有一个交集返回true，有交集但不全交也返回true，而两个集合相等的时候，返回false，所以不能根据返回值来确认两个集合是否有交集，而是通过原集合的大小是否发生改变来判断，如果原集合中还有元素，则代表有交集，而元集合没有元素了，说明两个集合没有交集。
            // 清除多余的元素，clear to let GC do its work
            for (int i = w; i < size; i++)
                elementData[i] = null;
            modCount += size - w;
            size = w;
            modified = true;
        }
    }
    return modified;
}


//保留公共的
public boolean retainAll(Collection<?> c) {
    Objects.requireNonNull(c);
    return batchRemove(c, true);
}

//将elementData中每个元素都赋值为null，等待垃圾回收将这个给回收掉
public void clear() {
    modCount++;
    //并没有直接使数组指向 null,而是逐个把元素置为空，下次使用时就不用重新 new 了
    for (int i = 0; i < size; i++)
        elementData[i] = null;

    size = 0;
}

```

总结：根据索引删除指定位置的元素，此时会把指定下标到数组末尾的元素挨个向前移动一个单位，并且会把数组最后一个元素设置为null，这样是为了方便之后将整个数组不被使用时，会被GC，可以作为小的技巧使用。

### get()方法

```java
public E get(int index) {
    // 检验索引是否合法
    rangeCheck(index);

    return elementData(index);
}

private void rangeCheck(int index) {
    if (index >= size)
        throw new IndexOutOfBoundsException(outOfBoundsMsg(index));
}

```

说明：get函数会检查索引值是否合法（只检查是否大于size，而没有检查是否小于0），值得注意的是，在get函数中存在element函数，element函数用于返回具体的元素，具体函数如下：

```java
E elementData(int index) {
    return (E) elementData[index];
}

```

说明：返回的值都经过了向下转型（Object -> E），这些是对我们应用程序屏蔽的小细节。

### set()方法

```java
//设定指定下标索引的元素值
public E set(int index, E element) {
    // 检验索引是否合法
    rangeCheck(index);
    // 旧值
    E oldValue = elementData(index);
    // 赋新值
    elementData[index] = element;
    // 返回旧值
    return oldValue;
}

```

### indexOf()方法

```java
// 从首开始查找数组里面是否存在指定元素
public int indexOf(Object o) {
    // 查找的元素为空
    if (o == null) { 
        // 遍历数组，找到第一个为空的元素，返回下标
        for (int i = 0; i < size; i++) 
            if (elementData[i]==null)
                return i;
    } else { 
        // 查找的元素不为空
        // 遍历数组，找到第一个和指定元素相等的元素，返回下标
        for (int i = 0; i < size; i++) 
            if (o.equals(elementData[i]))
                return i;
    } 
    // 没有找到，返回空
    return -1;
}

//返回列表中指定元素最后一次出现的索引，倒着遍历
public int lastIndexOf(Object o) {
    if (o == null) {
        for (int i = size-1; i >= 0; i--)
            if (elementData[i]==null)
                return i;
    } else {
        for (int i = size-1; i >= 0; i--)
            if (o.equals(elementData[i]))
                return i;
    }
    return -1;
}

```

说明：从头开始查找与指定元素相等的元素，需要注意的是可以查找null元素，意味着ArrayList中可以存放null元素的。与此函数对应的lastIndexOf，表示从尾部开始查找。

### contains()方法

```java
//判断是否含有某个元素
public boolean contains(Object o) {
    return indexOf(o) >= 0;
}

```

### toArray()方法

```java
/**
     以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。 
     */
public Object[] toArray() {
    //elementData：要复制的数组；size：要复制的长度
    return Arrays.copyOf(elementData, size);
}

public <T> T[] toArray(T[] a) {
    //如果只是要把一部分转换成数组
    if (a.length < size)
        // Make a new array of a's runtime type, but my contents:
        return (T[]) Arrays.copyOf(elementData, size, a.getClass());
    //全部元素拷贝到 数组 a
    System.arraycopy(elementData, 0, a, 0, size);
    if (a.length > size)
        a[size] = null;
    return a;
}

```



### System.arraycopy()和 Arrays.copyOf()方法

阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、E remove(int index)、toArray() 等方法中都用到了该方法！


### System.arraycopy()方法

System.arraycopy(…)：将指定源数组中的数组从指定位置开始复制到目标数组的指定位置。

```java
// src：源对象
// srcPos：源对象对象的起始位置
// dest：目标对象
// destPost：目标对象的起始位置
// length：从起始位置往后复制的长度。
// 这段的大概意思就是解释这个方法的用法，复制src到dest，复制的位置是从src的srcPost开始，到srcPost+length-1的位置结束，复制到destPost上，从destPost开始到destPost+length-1的位置上
public static void arraycopy(Object src, int srcPos, Object dest, int destPos,
             int length)

```

简单的方法测试以下：

```java
public class ArraycopyTest {

	public static void main(String[] args) {
        int[] a = new int[10];
        a[0] = 0;
        a[1] = 1;
        a[2] = 2;
        a[3] = 3;
        System.arraycopy(a, 2, a, 3, 3);
        a[2] = 99;
        for (int i = 0; i < a.length; i++) {
            System.out.print(a[i] + " ");
        }
    }

}

```



### Arrays.copyOf()方法

Array.copyOf() 选择指定的数组，截断或填充空值（如果需要），使副本具有指定的长度。以达到扩容的目的

```java
//Arrays的copyOf()方法传回的数组是新的数组对象，改变传回数组中的元素值，不会影响原来的数组。
//copyOf()的第二个自变量指定要建立的新数组长度，如果新数组的长度超过原数组的长度，则保留数组默认值
public static <T> T[] copyOf(T[] original, int newLength) {
    return (T[]) copyOf(original, newLength, original.getClass());
}

/**
 * @Description 复制指定的数组, 如有必要用 null 截取或填充，以使副本具有指定的长度
 * 对于所有在原数组和副本中都有效的索引，这两个数组相同索引处将包含相同的值
 * 对于在副本中有效而在原数组无效的所有索引，副本将填充 null，当且仅当指定长度大于原数组的长度时，这些索引存在
 * 返回的数组属于 newType 类
 *
 * @param original 要复制的数组
 * @param newLength 副本的长度
 * @param newType 副本的类
 * 
 * @return T 原数组的副本，截取或用 null 填充以获得指定的长度
 * @throws NegativeArraySizeException 如果 newLength 为负
 * @throws NullPointerException 如果 original 为 null
 * @throws ArrayStoreException 如果从 original 中复制的元素不属于存储在 newType 类数组中的运行时类型
 */

public static <T,U> T[] copyOf(U[] original, int newLength, Class<? extends T[]> newType) {
    @SuppressWarnings("unchecked")
    T[] copy = ((Object)newType == (Object)Object[].class)
        ? (T[]) new Object[newLength]
        : (T[]) Array.newInstance(newType.getComponentType(), newLength);
    System.arraycopy(original, 0, copy, 0,
                     Math.min(original.length, newLength));
    return copy;
}

```

### 两者联系与区别

#### 联系：

看两者源代码可以发现copyOf()内部调用了System.arraycopy()方法

#### 区别：

arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置
copyOf()是系统自动在内部新建一个数组，并返回该数组。

## LinkedList(JDK1.8)

### 概述

LinkedList 是 Java 集合框架中一个重要的实现，其底层采用的双向链表结构。和 ArrayList 一样，LinkedList 也支持空值和重复值。由于 LinkedList 基于链表实现，存储元素过程中，无需像 ArrayList 那样进行扩容。但有得必有失，LinkedList 存储元素的节点需要额外的空间存储前驱和后继的引用。另一方面，LinkedList 在链表头部和尾部插入效率比较高，但在指定位置进行插入时，效率一般。原因是，在指定位置插入需要定位到该位置处的节点，此操作的时间复杂度为`O(N)`。最后，LinkedList 是非线程安全的集合类，并发环境下，多个线程同时操作 LinkedList，会引发不可预知的错误。

以上是对 LinkedList 的简单介绍，接下来，我将会对 LinkedList 常用操作展开分析，继续往下看吧。

### 继承体系

LinkedList 的继承体系较为复杂，继承自 AbstractSequentialList，同时又实现了 List 和 Deque 接口。继承体系图如下（删除了部分实现的接口）：

![image-20210804092553950](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804092553950.png)

LinkedList 继承自 AbstractSequentialList，AbstractSequentialList 又是什么呢？从实现上，AbstractSequentialList 提供了一套基于顺序访问的接口。通过继承此类，子类仅需实现部分代码即可拥有完整的一套访问某种序列表（比如链表）的接口。深入源码，AbstractSequentialList 提供的方法基本上都是通过 ListIterator 实现的，比如：

```java
public E get(int index) {
    try {
        return listIterator(index).next();
    } catch (NoSuchElementException exc) {
        throw new IndexOutOfBoundsException("Index: "+index);
    }
}

public void add(int index, E element) {
    try {
        listIterator(index).add(element);
    } catch (NoSuchElementException exc) {
        throw new IndexOutOfBoundsException("Index: "+index);
    }
}

// 留给子类实现
public abstract ListIterator<E> listIterator(int index);

```

所以只要继承类实现了 listIterator 方法，它不需要再额外实现什么即可使用。对于随机访问集合类一般建议继承 AbstractList 而不是 AbstractSequentialList。LinkedList 和其父类一样，也是基于顺序访问。所以 LinkedList 继承了 AbstractSequentialList，但 LinkedList 并没有直接使用父类的方法，而是重新实现了一套的方法。

另外，LinkedList 还实现了 Deque (double ended queue)，Deque 又继承自 Queue 接口。这样 LinkedList 就具备了队列的功能。比如，我们可以这样使用：

```java
Queue<T> queue = new LinkedList<>();

```

### 查找

LinkedList 底层基于链表结构，无法向 ArrayList 那样随机访问指定位置的元素。LinkedList 查找过程要稍麻烦一些，需要从链表头结点（或尾节点）向后查找，时间复杂度为 `O(N)`。相关源码如下：

```java
public E get(int index) {
    checkElementIndex(index);
    return node(index).item;
}

Node<E> node(int index) {
    /*
     * 则从头节点开始查找，否则从尾节点查找
     * 查找位置 index 如果小于节点数量的一半，
     */    
    if (index < (size >> 1)) {
        Node<E> x = first;
        // 循环向后查找，直至 i == index
        for (int i = 0; i < index; i++)
            x = x.next;
        return x;
    } else {
        Node<E> x = last;
        for (int i = size - 1; i > index; i--)
            x = x.prev;
        return x;
    }
}

```

上面的代码比较简单，主要是通过遍历的方式定位目标位置的节点。获取到节点后，取出节点存储的值返回即可。这里面有个小优化，即通过比较 index 与节点数量 size/2 的大小，决定从头结点还是尾节点进行查找。查找操作的代码没什么复杂的地方，这里先讲到这里。

### 遍历

链表的遍历过程也很简单，和上面查找过程类似，我们从头节点往后遍历就行了。但对于 LinkedList 的遍历还是需要注意一些，不然可能会导致代码效率低下。通常情况下，我们会使用 foreach 遍历 LinkedList，而 foreach 最终转换成迭代器形式。所以分析 LinkedList 的遍历的核心就是它的迭代器实现，相关代码如下：

```java
public ListIterator<E> listIterator(int index) {
    checkPositionIndex(index);
    return new ListItr(index);
}

private class ListItr implements ListIterator<E> {
    private Node<E> lastReturned;
    private Node<E> next;
    private int nextIndex;
    private int expectedModCount = modCount;

    /** 构造方法将 next 引用指向指定位置的节点 */
    ListItr(int index) {
        // assert isPositionIndex(index);
        next = (index == size) ? null : node(index);
        nextIndex = index;
    }

    public boolean hasNext() {
        return nextIndex < size;
    }

    public E next() {
        checkForComodification();
        if (!hasNext())
            throw new NoSuchElementException();

        lastReturned = next;
        next = next.next;    // 调用 next 方法后，next 引用都会指向他的后继节点
        nextIndex++;
        return lastReturned.item;
    }
    
    // 省略部分方法
}

```



上面的方法很简单，大家应该都能很快看懂，这里就不多说了。下面来说说遍历 LinkedList 需要注意的一个点。

我们都知道 LinkedList 不擅长随机位置访问，如果大家用随机访问的方式遍历 LinkedList，效率会很差。比如下面的代码：

```java
List<Integet> list = new LinkedList<>();
list.add(1)
list.add(2)
......
for (int i = 0; i < list.size(); i++) {
    Integet item = list.get(i);
    // do something
}

```

当链表中存储的元素很多时，上面的遍历方式对于效率来说就是灾难。原因在于，通过上面的方式每获取一个元素，LinkedList 都需要从头节点（或尾节点）进行遍历，效率不可谓不低。在电脑配置如下（MacBook Pro Early 2015, 2.7 GHz Intel Core i5）实测10万级的数据量，耗时约7秒钟。20万级的数据量耗时达到了约34秒的时间。50万级的数据量耗时约250秒。从测试结果上来看，上面的遍历方式在大数据量情况下，效率很差。大家在日常开发中应该尽量避免这种用法。

### 插入

LinkedList 除了实现了 List 接口相关方法，还实现了 Deque 接口的很多方法，所以我们有很多种方式插入元素。但这里，我只打算分析 List 接口中相关的插入方法，其他的方法大家自己看吧。LinkedList 插入元素的过程实际上就是链表链入节点的过程，学过数据结构的同学对此应该都很熟悉了。这里简单分析一下，先看源码吧：

```java
/** 在链表尾部插入元素 */
public boolean add(E e) {
    linkLast(e);
    return true;
}

/** 在链表指定位置插入元素 */
public void add(int index, E element) {
    checkPositionIndex(index);

    // 判断 index 是不是链表尾部位置，如果是，直接将元素节点插入链表尾部即可
    if (index == size)
        linkLast(element);
    else
        linkBefore(element, node(index));
}

/** 将元素节点插入到链表尾部 */
void linkLast(E e) {
    final Node<E> l = last;
    // 创建节点，并指定节点前驱为链表尾节点 last，后继引用为空
    final Node<E> newNode = new Node<>(l, e, null);
    // 将 last 引用指向新节点
    last = newNode;
    // 判断尾节点是否为空，为空表示当前链表还没有节点
    if (l == null)
        first = newNode;
    else
        l.next = newNode;    // 让原尾节点后继引用 next 指向新的尾节点
    size++;
    modCount++;
}

/** 将元素节点插入到 succ 之前的位置 */
void linkBefore(E e, Node<E> succ) {
    // assert succ != null;
    final Node<E> pred = succ.prev;
    // 1. 初始化节点，并指明前驱和后继节点
    final Node<E> newNode = new Node<>(pred, e, succ);
    // 2. 将 succ 节点前驱引用 prev 指向新节点
    succ.prev = newNode;
    // 判断尾节点是否为空，为空表示当前链表还没有节点    
    if (pred == null)
        first = newNode;
    else
        pred.next = newNode;   // 3. succ 节点前驱的后继引用指向新节点
    size++;
    modCount++;
}

```



上面是插入过程的源码，我对源码进行了比较详细的注释，应该不难看懂。上面两个 add 方法只是对操作链表的方法做了一层包装，核心逻辑在 linkBefore 和 linkLast 中。这里以 linkBefore 为例，它的逻辑流程如下：

1. 创建新节点，并指明新节点的前驱和后继
2. 将 succ 的前驱引用指向新节点
3. 如果 succ 的前驱不为空，则将 succ 前驱的后继引用指向新节点

对应于下图：

![image-20210804092907448](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804092907448.png)

### 删除

```java
public boolean remove(Object o) {
    if (o == null) {
        for (Node<E> x = first; x != null; x = x.next) {
            if (x.item == null) {
                unlink(x);
                return true;
            }
        }
    } else {
        // 遍历链表，找到要删除的节点
        for (Node<E> x = first; x != null; x = x.next) {
            if (o.equals(x.item)) {
                unlink(x);    // 将节点从链表中移除
                return true;
            }
        }
    }
    return false;
}

public E remove(int index) {
    checkElementIndex(index);
    // 通过 node 方法定位节点，并调用 unlink 将节点从链表中移除
    return unlink(node(index));
}

/** 将某个节点从链表中移除 */
E unlink(Node<E> x) {
    // assert x != null;
    final E element = x.item;
    final Node<E> next = x.next;
    final Node<E> prev = x.prev;
    
    // prev 为空，表明删除的是头节点
    if (prev == null) {
        first = next;
    } else {
        // 将 x 的前驱的后继指向 x 的后继
        prev.next = next;
        // 将 x 的前驱引用置空，断开与前驱的链接
        x.prev = null;
    }

    // next 为空，表明删除的是尾节点
    if (next == null) {
        last = prev;
    } else {
        // 将 x 的后继的前驱指向 x 的前驱
        next.prev = prev;
        // 将 x 的后继引用置空，断开与后继的链接
        x.next = null;
    }

    // 将 item 置空，方便 GC 回收
    x.item = null;
    size--;
    modCount++;
    return element;
}

```



和插入操作一样，删除操作方法也是对底层方法的一层保证，核心逻辑在底层 unlink 方法中。所以长驱直入，直接分析 unlink 方法吧。unlink 方法的逻辑如下（假设删除的节点既不是头节点，也不是尾节点）：

1. 将待删除节点 x 的前驱的后继指向 x 的后继
2. 将待删除节点 x 的前驱引用置空，断开与前驱的链接
3. 将待删除节点 x 的后继的前驱指向 x 的前驱
4. 将待删除节点 x 的后继引用置空，断开与后继的链接

对应下图：



![image-20210804092958159](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804092958159.png)

## HashMap(JDK1.8)

### 特点

HashMap 可以说是我们使用最多的 Map 集合，它有以下特点：

- 键不可重复，值可以重复
- 底层哈希表
- 线程不安全
- 允许key为null，value也可以为null

### 数据结构

在Java中，保存数据有两种比较简单的数据结构：数组和链表。**数组的特点是：寻址容易，插入和删除困难；链表的特点是：寻址困难，但插入和删除容易；\**所以我们将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做\**拉链法**的方式可以解决哈希冲突。

### JDK1.7 VS JDK1.8 比较

JDK1.8主要解决或优化了一下问题：

1. resize 扩容优化
2. 引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考
3. 解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。

![image-20210804093423712](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804093423712.png)

### 继承关系图

![image-20210804093442580](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804093442580.png)



HashMap继承抽象类AbstractMap，实现Map接口。除此之外，它还实现了两个标识型接口，这两个接口都没有任何方法，仅作为标识表示实现类具备某项功能。`Cloneable`表示实现类支持克隆，`java.io.Serializable`则表示支持序列化。

### 成员变量

```java
//默认初始化Node数组容量16
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
//最大的数组容量
static final int MAXIMUM_CAPACITY = 1 << 30;
//默认负载因子0.75
static final float DEFAULT_LOAD_FACTOR = 0.75f;
//由链表转红黑树的临界值
static final int TREEIFY_THRESHOLD = 8;
//由红黑树转链表的临界值
static final int UNTREEIFY_THRESHOLD = 6;
//桶转化为树形结构的最小容量
static final int MIN_TREEIFY_CAPACITY = 64;
//HashMap结构修改的次数，结构修改是指更改HashMap中的映射数或以其他方式修改其内部结构(例如，rehash的修改)。该字段用于在Collection-views上快速生成迭代器。
transient int modCount;  
//Node数组下一次扩容的临界值，第一次为16*0.75=12（容量*负载因子）
int threshold;
//负载因子
final float loadFactor;
//map中包含的键值对的数量
transient int size;
//表数据，即Node键值对数组，Node是单向链表，它实现了Map.Entry接口，总是2的幂次倍
//Node<K,V>是HashMap的内部类，实现Map.Entry<K,V>接口，HashMap的哈希桶数组中存放的键值对对象就是Node<K,V>。类中维护了一个next指针指向链表中的下一个元素。值得注意的是，当链表中的元素数量超过TREEIFY_THRESHOLD后会HashMap会将链表转换为红黑树，此时该下标的元素将成为TreeNode<K,V>,继承于LinkedHashMap.Entry<K,V>，而LinkedHashMap.Entry<K,V>是Node<K,V>的子类，因此HashMap的底层数组数据类型即为Node<K,V>。
transient Node<K,V>[] table;
//存放具体元素的集,可用于遍历map集合
transient Set<Map.Entry<K,V>> entrySet;

```



capacity、threshold和loadFactor之间的关系：

capacity table的容量，默认容量是16
threshold table扩容的临界值
loadFactor 负载因子，一般 threshold = capacity * loadFactor，默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改。

### 构造方法

```java
//初始化容量以及负载因子
public HashMap(int initialCapacity, float loadFactor) {
    //判断初始化数组的容量大小
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    //判断初始化的负载因子大小和是否为浮点型
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    //初始化负载因子
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);
}  

//初始化容量
public HashMap(int initialCapacity) {  
    this(initialCapacity, DEFAULT_LOAD_FACTOR);  
}  

//默认构造方法
public HashMap() {  
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted  
}  
 
//把另一个Map的值映射到当前新的Map中
public HashMap(Map<? extends K, ? extends V> m) {  
    this.loadFactor = DEFAULT_LOAD_FACTOR;  
    putMapEntries(m, false);  
}  

```

其中主要有两种形式：

定义初始容量大小（table数组的大小，缺省值为16），定义负载因子（缺省值为0.75）的形式

直接拷贝别的HashMap的形式，在此不作讨论

值得注意的是，当我们自定义HashMap初始容量大小时，构造函数并非直接把我们定义的数值当做HashMap容量大小，而是把该数值当做参数调用方法tableSizeFor，然后把返回值作为HashMap的初始容量大小

### **tableSizeFor()方法说明**

```java
//HashMap 中 table 角标计算及table.length 始终为2的幂，即 2 ^ n
//返回大于initialCapacity的最小的二次幂数值
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}

```



### 静态内部类

### Node

HashMap将hash，key，value，next已经封装到一个静态内部类Node上。它实现了`Map.Entry<K,V>`接口。

```java
static class Node<K,V> implements Map.Entry<K,V> {
    // 哈希值，HashMap根据该值确定记录的位置
    final int hash;
    // node的key
    final K key;
    // node的value
    V value;
    // 链表下一个节点
    Node<K,V> next;

    // 构造方法
    Node(int hash, K key, V value, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }

    // 返回 node 对应的键
    public final K getKey()        { return key; }
    // 返回 node 对应的值
    public final V getValue()      { return value; }
    public final String toString() { return key + "=" + value; }

    public final int hashCode() {
        return Objects.hashCode(key) ^ Objects.hashCode(value);
    }

    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }

    //作用：判断2个Entry是否相等，必须key和value都相等，才返回true
    public final boolean equals(Object o) {
        if (o == this)
            return true;
        if (o instanceof Map.Entry) {
            Map.Entry<?,?> e = (Map.Entry<?,?>)o;
            if (Objects.equals(key, e.getKey()) &&
                Objects.equals(value, e.getValue()))
                return true;
        }
        return false;
    }
}

```

### TreeNode

继承于LinkedHashMap.Entry<K,V>，而LinkedHashMap.Entry<K,V>是Node<K,V>的子类，因此HashMap的底层数组数据类型即为Node<K,V>

```java
/**
  * 红黑树节点 实现类：继承自LinkedHashMap.Entry<K,V>类
  */
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {  

    // 属性 = 父节点、左子树、右子树、删除辅助节点 + 颜色
    TreeNode<K,V> parent;  
    TreeNode<K,V> left;   
    TreeNode<K,V> right;
    TreeNode<K,V> prev;   
    boolean red;   

    // 构造函数
    TreeNode(int hash, K key, V val, Node<K,V> next) {  
        super(hash, key, val, next);  
    }  

    // 返回当前节点的根节点  
    final TreeNode<K,V> root() {  
        for (TreeNode<K,V> r = this, p;;) {  
            if ((p = r.parent) == null)  
                return r;  
            r = p;  
        }  
    }
}

```

### hash()算法

JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用。HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) & hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。

所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法是为了防止一些实现比较差的 hashCode() 方法，换句话说使用扰动函数之后可以减少碰撞。

JDK 1.8 HashMap 的 hash 方法源码:

JDK 1.8 的 hash方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。



```java
// 取key的hashCode值、高位运算、取模运算
// 在JDK1.8的实现中，优化了高位运算的算法，
// 通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，
// 主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，
// 也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

```



（1）首先获取对象的hashCode()值，然后将hashCode值右移16位，然后将右移后的值与原来的hashCode做异或运算，返回结果。（其中h>>>16，在JDK1.8中，优化了高位运算的算法，使用了零扩展，无论正数还是负数，都在高位插入0）。

（2）在putVal源码中，通过(n-1)&hash获取该对象的键在hashmap中的位置。（其中hash的值就是（1）中获得的值）其中n表示的是hash桶数组的长度，并且该长度为2的n次方，这样(n-1)&hash就等价于hash%n。因为&运算的效率高于%运算。

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                boolean evict) {
    ...

    if ((p = tab[i = (n - 1) & hash]) == null)//获取位置
        tab[i] = newNode(hash, key, value, null);
    ...
}

```

tab即是table，n是map集合的容量大小，hash是上面方法的返回值。因为通常声明map集合时不会指定大小，或者初始化的时候就创建一个容量很大的map对象，所以这个通过容量大小与key值进行hash的算法在开始的时候只会对低位进行计算，虽然容量的2进制高位一开始都是0，但是key的2进制高位通常是有值的，因此先在hash方法中将key的hashCode右移16位在与自身异或，使得高位也可以参与hash，更大程度上减少了碰撞率。

下面举例说明下，n为table的长度。


![image-20210804093848356](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804093848356.png)

对比一下 JDK1.7的 HashMap 的 hash 方法源码。



```java
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).
    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}

```



相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。

```java
//将m的所有元素存入本HashMap实例中
final void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {
    int s = m.size();
    if (s > 0) {
        // 判断table是否已经初始化
        if (table == null) { // pre-size
            // 未初始化，s为m的实际元素个数
            float ft = ((float)s / loadFactor) + 1.0F;
            int t = ((ft < (float)MAXIMUM_CAPACITY) ?
                    (int)ft : MAXIMUM_CAPACITY);
            // 计算得到的t大于阈值，则初始化阈值
            if (t > threshold)
                threshold = tableSizeFor(t);
        }
        // 已初始化，并且m元素个数大于阈值，进行扩容处理
        else if (s > threshold)
            resize();
        // 将m中的所有元素添加至HashMap中
        for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {
            K key = e.getKey();
            V value = e.getValue();
            putVal(hash(key), key, value, false, evict);
        }
    }
}

```

### put()方法

当我们put的时候，首先计算 key的hash值，这里调用了 hash方法，hash方法实际是让key.hashCode()与key.hashCode()>>>16进行异或操作，高16bit补0，一个数和0异或不变，所以 hash 函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或，目的是减少碰撞。按照函数注释，因为bucket数组大小是2的幂，计算下标index = (table.length - 1) & hash，如果不做 hash 处理，相当于散列生效的只有几个低 bit 位，为了减少散列的碰撞，设计者综合考虑了速度、作用、质量之后，使用高16bit和低16bit异或来简单处理减少碰撞，而且JDK8中用了复杂度 O（logn）的树结构来提升碰撞下的性能。

putVal方法执行流程图
![image-20210804093946108](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210804093946108.png)

```java

public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

//实现Map.put和相关方法
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 步骤①：tab为空则创建 
    // table未初始化或者长度为0，进行扩容
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 步骤②：计算index，并对null做处理  
    // (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    // 桶中已经存在元素
    else {
        Node<K,V> e; K k;
        // 步骤③：节点key存在，直接覆盖value 
        // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
                // 将第一个元素赋值给e，用e来记录
                e = p;
        // 步骤④：判断该链为红黑树 
        // hash值不相等，即key不相等；为红黑树结点
        // 如果当前元素类型为TreeNode，表示为红黑树，putTreeVal返回待存放的node, e可能为null
        else if (p instanceof TreeNode)
            // 放入树中
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        // 步骤⑤：该链为链表 
        // 为链表结点
        else {
            // 在链表最末插入结点
            for (int binCount = 0; ; ++binCount) {
                // 到达链表的尾部
                
                //判断该链表尾部指针是不是空的
                if ((e = p.next) == null) {
                    // 在尾部插入新结点
                    p.next = newNode(hash, key, value, null);
                    //判断链表的长度是否达到转化红黑树的临界值，临界值为8
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        //链表结构转树形结构
                        treeifyBin(tab, hash);
                    // 跳出循环
                    break;
                }
                // 判断链表中结点的key值与插入的元素的key值是否相等
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    // 相等，跳出循环
                    break;
                // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表
                p = e;
            }
        }
        //判断当前的key已经存在的情况下，再来一个相同的hash值、key值时，返回新来的value这个值
        if (e != null) { 
            // 记录e的value
            V oldValue = e.value;
            // onlyIfAbsent为false或者旧值为null
            if (!onlyIfAbsent || oldValue == null)
                //用新值替换旧值
                e.value = value;
            // 访问后回调
            afterNodeAccess(e);
            // 返回旧值
            return oldValue;
        }
    }
    // 结构性修改
    ++modCount;
    // 步骤⑥：超过最大容量就扩容 
    // 实际大小大于阈值则扩容
    if (++size > threshold)
        resize();
    // 插入后回调
    afterNodeInsertion(evict);
    return null;
}

```

①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；

②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；

③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；

④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；

⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；

⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

### resize()方法

①.在jdk1.8中，resize方法是在hashmap中的键值对大于阀值时或者初始化时，就调用resize方法进行扩容；

②.每次扩展的时候，都是扩展2倍；

③.扩展后Node对象的位置要么在原位置，要么移动到原偏移量两倍的位置。

在putVal()中，我们看到在这个函数里面使用到了2次resize()方法，resize()方法表示的在进行第一次初始化时会对其进行扩容，或者当该数组的实际大小大于其临界值值(第一次为12),这个时候在扩容的同时也会伴随的桶上面的元素进行重新分发，这也是JDK1.8版本的一个优化的地方，在1.7中，扩容之后需要重新去计算其Hash值，根据Hash值对其进行分发，但在1.8版本中，则是根据在同一个桶的位置中进行判断(e.hash & oldCap)是否为0，重新进行hash分配后，该元素的位置要么停留在原始位置，要么移动到原始位置+增加的数组大小这个位置上

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;//oldTab指向hash桶数组
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {//如果oldCap不为空的话，就是hash桶数组不为空
        if (oldCap >= MAXIMUM_CAPACITY) {//如果大于最大容量了，就赋值为整数最大的阀值
            threshold = Integer.MAX_VALUE;
            return oldTab;//返回
        }//如果当前hash桶数组的长度在扩容后仍然小于最大容量 并且oldCap大于默认值16
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold 双倍扩容阀值threshold
    }
    // 旧的容量为0，但threshold大于零，代表有参构造有cap传入，threshold已经被初始化成最小2的n次幂
    // 直接将该值赋给新的容量
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    // 无参构造创建的map，给出默认容量和threshold 16, 16*0.75
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    // 新的threshold = 新的cap * 0.75
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    // 计算出新的数组长度后赋给当前成员变量table
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];//新建hash桶数组
    table = newTab;//将新数组的值复制给旧的hash桶数组
    // 如果原先的数组没有初始化，那么resize的初始化工作到此结束，否则进入扩容元素重排逻辑，使其均匀的分散
    if (oldTab != null) {
        // 遍历新数组的所有桶下标
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                // 旧数组的桶下标赋给临时变量e，并且解除旧数组中的引用，否则就数组无法被GC回收
                oldTab[j] = null;
                // 如果e.next==null，代表桶中就一个元素，不存在链表或者红黑树
                if (e.next == null)
                    // 用同样的hash映射算法把该元素加入新的数组
                    newTab[e.hash & (newCap - 1)] = e;
                // 如果e是TreeNode并且e.next!=null，那么处理树中元素的重排
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                // e是链表的头并且e.next!=null，那么处理链表中元素重排
                else { // preserve order
                    // loHead,loTail 代表扩容后不用变换下标，见注1
                    Node<K,V> loHead = null, loTail = null;
                    // hiHead,hiTail 代表扩容后变换下标，见注1
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    // 遍历链表
                    do {             
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                // 初始化head指向链表当前元素e，e不一定是链表的第一个元素，初始化后loHead
                                // 代表下标保持不变的链表的头元素
                                loHead = e;
                            else                                
                                // loTail.next指向当前e
                                loTail.next = e;
                            // loTail指向当前的元素e
                            // 初始化后，loTail和loHead指向相同的内存，所以当loTail.next指向下一个元素时，
                            // 底层数组中的元素的next引用也相应发生变化，造成lowHead.next.next.....
                            // 跟随loTail同步，使得lowHead可以链接到所有属于该链表的元素。
                            loTail = e;                           
                        }
                        else {
                            if (hiTail == null)
                                // 初始化head指向链表当前元素e, 初始化后hiHead代表下标更改的链表头元素
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 遍历结束, 将tail指向null，并把链表头放入新数组的相应下标，形成新的映射。
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}

```



### treeifyBin()方法

在putVal()方法中，我们能够看到，当链表的长度大于TREEIFY_THRESHOLD这个临界值时，这个时候就会调用treeifyBin()方法，将链表的结构转化为红黑树结构，这也是JDK1.8版本新优化的功能点

在此方法中主要做了：

 1、判断桶是否初始化、或者判断桶中的元素个数是否达到MIN_TREEIFY_CAPACITY阈值，没有的话则去进行初始化或者扩容

 2、若不符合上述条件，则会对其进行树形化，首先会先去遍历桶中链表的元素，并创建相同的树节点，接着会根据桶的第一个元素而去创建树的头结点，并以此建立联系

```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        resize();
    //开始树形化
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        TreeNode<K,V> hd = null, tl = null;
        //对桶Node中的链表元素进行循环，从链表的头节点开始将链表的头元素改为树的头节点
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                //树的头节点不为空时
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        //将桶中的元素与树的头节点进行连接
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}

```

### get()方法

说明：HashMap同样并没有直接提供getNode接口给用户调用，而是提供的get方法，而get方法就是通过getNode来取得元素的。

```java
public V get(Object key) {
    Node<k,v> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

```



```java
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    // table已经初始化，长度大于0，根据hash寻找table中的项也不为空
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 桶中第一项(数组元素)相等
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        // 桶中不止一个结点
        if ((e = first.next) != null) {
            // 为红黑树结点
            if (first instanceof TreeNode)
                // 在红黑树中查找
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            // 否则，在链表中查找
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}

```

### remove()方法

```java
/**
* 从HashMap中删除掉指定key对应的键值对，并返回被删除的键值对的值
* 如果返回空，说明key可能不存在，也可能key对应的值就是null
* 如果想确定到底key是否存在可以使用containsKey方法
*/
public V remove(Object key) {
    Node<K,V> e; // 定义一个节点变量，用来存储要被删除的节点（键值对）
    return (e = removeNode(hash(key), key, null, false, true)) == null ?
        null : e.value; // 调用removeNode方法
}

```



可以发现remove方法底层实际上是调用了removeNode方法来删除键值对节点，并且根据返回的节点对象取得key对应的值，那么我们再来详细分析下removeNode方法的代码

```java
/**
* 方法为final，不可被覆写，子类可以通过实现afterNodeRemoval方法来增加自己的处理逻辑（解析中有描述）
*
* @param hash key的hash值，该值是通过hash(key)获取到的
* @param key 要删除的键值对的key
* @param value 要删除的键值对的value，该值是否作为删除的条件取决于matchValue是否为true
* @param matchValue 如果为true，则当key对应的键值对的值equals(value)为true时才删除；否则不关心value的值
* @param movable 删除后是否移动节点，如果为false，则不移动
* @return 返回被删除的节点对象，如果没有删除任何节点则返回null
*/
final Node<K,V> removeNode(int hash, Object key, Object value,
                            boolean matchValue, boolean movable) {
    Node<K,V>[] tab; Node<K,V> p; int n, index; // 声明节点数组、当前节点、数组长度、索引值
    /*
     * 如果 节点数组tab不为空、数组长度n大于0、根据hash定位到的节点对象p（该节点为 树的根节点 或 链表的首节点）不为空
     * 需要从该节点p向下遍历，找到那个和key匹配的节点对象
     */
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (p = tab[index = (n - 1) & hash]) != null) {
        Node<K,V> node = null, e; K k; V v; // 定义要返回的节点对象，声明一个临时节点变量、键变量、值变量
 
        // 如果当前节点的键和key相等，那么当前节点就是要删除的节点，赋值给node
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            node = p;
 
        /*
         * 到这一步说明首节点没有匹配上，那么检查下是否有next节点
         * 如果没有next节点，就说明该节点所在位置上没有发生hash碰撞, 就一个节点并且还没匹配上，也就没得删了，最终也就返回null了
         * 如果存在next节点，就说明该数组位置上发生了hash碰撞，此时可能存在一个链表，也可能是一颗红黑树
         */
        else if ((e = p.next) != null) {
            // 如果当前节点是TreeNode类型，说明已经是一个红黑树，那么调用getTreeNode方法从树结构中查找满足条件的节点
            if (p instanceof TreeNode)
                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
            // 如果不是树节点，那么就是一个链表，只需要从头到尾逐个节点比对即可    
            else {
                do {
                    // 如果e节点的键是否和key相等，e节点就是要删除的节点，赋值给node变量，调出循环
                    if (e.hash == hash &&
                        ((k = e.key) == key ||
                            (key != null && key.equals(k)))) {
                        node = e;
                        break;
                    }
 
                    // 走到这里，说明e也没有匹配上
                    p = e; // 把当前节点p指向e，这一步是让p存储的永远下一次循环里e的父节点，如果下一次e匹配上了，那么p就是node的父节点
                } while ((e = e.next) != null); // 如果e存在下一个节点，那么继续去匹配下一个节点。直到匹配到某个节点跳出 或者 遍历完链表所有节点
            }
        }
 
        /*
         * 如果node不为空，说明根据key匹配到了要删除的节点
         * 如果不需要对比value值  或者  需要对比value值但是value值也相等
         * 那么就可以删除该node节点了
         */
        if (node != null && (!matchValue || (v = node.value) == value ||
                                (value != null && value.equals(v)))) {
            if (node instanceof TreeNode) // 如果该节点是个TreeNode对象，说明此节点存在于红黑树结构中，调用removeTreeNode方法（该方法单独解析）移除该节点
                ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
            else if (node == p) // 如果该节点不是TreeNode对象，node == p 的意思是该node节点就是首节点
                tab[index] = node.next; // 由于删除的是首节点，那么直接将节点数组对应位置指向到第二个节点即可
            else // 如果node节点不是首节点，此时p是node的父节点，由于要删除node，所有只需要把p的下一个节点指向到node的下一个节点即可把node从链表中删除了
                p.next = node.next;
            ++modCount; // HashMap的修改次数递增
            --size; // HashMap的元素个数递减
            afterNodeRemoval(node); // 调用afterNodeRemoval方法，该方法HashMap没有任何实现逻辑，目的是为了让子类根据需要自行覆写
            return node;
        }
    }
    return null;
}

```

### 遍历

HashMap的四种遍历方式

```java
//HashMap的四种遍历方式
public static void main(String[] args) {
    Map<String, String> map = new HashMap<String, String>();
    map.put("1", "value1");
    map.put("2", "value2");
    map.put("3", "value3");
    map.put("4", "value4");

    //第一种   通过Map.entrySet遍历,推荐使用,尤其是容量大时
    System.out.println("通过Map.entrySet遍历key和value: ");
    for (Map.Entry<String, String> entry : map.entrySet()) {
        System.out.println("Key: " + entry.getKey() + " - Value: " + entry.getValue());
    }

    //第二种   通过Map.entrySet使用iterator遍历
    System.out.println("\n通过Map.entrySet使用iterator遍历key和value: ");
    Iterator map1it = map.entrySet().iterator();
    while (map1it.hasNext()) {
        Map.Entry<String, String> entry = (Map.Entry<String, String>) map1it.next();
        System.out.println("Key: " + entry.getKey() + " - Value: " + entry.getValue());
    }

    //第三种   通过Map.keySet遍历,二次取值
    System.out.println("\n通过Map.keySet遍历key和value: ");
    for (String key : map.keySet()) {
        System.out.println("Key: " + key + " - Value: " + map.get(key));
    }

    //第四种   通过Map.values()遍历
    System.out.println("\n通过Map.values()遍历所有的value,但不能遍历key: ");
    for (String v : map.values()) {
        System.out.println("The value is " + v);
    }
}

```





## HashTable

我了解到是现在已经不怎么使用这个集合类了，如果不考虑线程安全的话就用hashmap，如果考虑线程安全的话就用currenthashmap。

默认构造函数，容量为**11**，加载因子为0.75

hashtable的键值对都不允许存放null值。hashmap可以，Hashtable直接调用key的hashCode()方法，因此如果key为null，则抛出空指针异常。

Hashtable扩容为原容量2倍加1

**Hashtable通过计算**key的hashCode()来得到hash值就为最终hash值。hashmap先调用hashCode方法计算出来一个hash值，再将hash与右移16位后相**异或**，从而得到**新的hash值**。

![image-20210416011507093](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416011507093.png)



#### 1、什么是哈希表？

哈希表（HashTable）又叫做散列表，是根据关键码值（即键值对）而直接访问的数据结构。也就是说，它通过把关键码映射到表中一个位置来访问记录，以加快查找速度。看到这里你可能比较疑惑，它是怎么加快查找速度的？下一节就有说明！这个映射函数就叫做散列（哈希）函数，存放记录的数组叫做散列表。

#### 2、为什么哈希表的速度快？

在数据结构中，我们对两种数据结构应该会非常熟悉：数组与链表。数组的特点就是查找容易，插入删除困难；而链表的特点就是查找困难，但是插入删除容易。既然两者各有优缺点，那么我们就将两者的有点结合起来，让它查找容易，插入删除也会快起来。哈希表就是讲两者结合起来的产物。

#### 3、常用的构造散列函数的方法

　1. 直接寻址法：取关键字或关键字的某个线性函数值为散列地址。即H（key）=key或H（key） = a？key + b，其中a和b为常数（这种散列函数叫做自身函数）
 　2. 数字分析法：分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构成散列地址，则冲突的几率会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。
 　3.  平方取中法：取关键字平方后的中间几位作为散列地址。
 　4. 折叠法：将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（去除进位）作为散列地址。
 　5. 随机数法：选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。
 　6.  除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即 H（key） = key MOD p， p<=m。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生同义词。

#### 4、处理hash冲突的方法

　1. 开放寻址法；Hi=(H(key) + di) MOD m, i=1,2,…, k(k<=m-1)，其中H(key)为散列函数，m为散列表长，di为增量序列，可有下列三种取法：

　　（1） di=1,2,3,…, m-1，称线性探测再散列；

　　（2）di=1^2, (-1)^2, 2^2,(-2)^2, (3)^2, …, ±(k)^2,(k<=m/2)称二次探测再散列;

　　（3）di=伪随机数序列，称伪随机探测再散列。 

2. 再散列法：Hi=RHi(key), i=1,2,…,k RHi均是不同的散列函数，即在同义词产生地址冲突时计算另一个散列函数地址，直到冲突不再发生，这种方法不易产生“聚集”，但增加了计算时间。
3. 链地址法(拉链法)






## String

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210408114400735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Nzc5NDM3Ng==,size_16,color_FFFFFF,t_70)



![image-20210416005127312](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416005127312.png)



## AQS

AbstractQueuedSynchronizer(AQS)在同步组件的实现中，AQS是核心部分，**同步组件的实现者通过使用AQS提供的模板方法实现同步组件语义**，AQS则实现了对**同步状态**的管理，以及对**阻塞线程进行排队**，等待通知等等一些底层的实现处理。AQS的核心也包括了这些方面：同步队列，独占式锁的获取和释放，共享锁的获取和释放以及可中断锁，超时等待锁获取这些特性的实现。

队列同步器，有头尾指针，双向队列

在AQS有一个**静态内部类Node**，其中有这样一些属性：

![image-20210416081043810](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081043810.png)

![image-20210416081346212](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081346212.png)

节点的状态有以下这些：

![image-20210416081113454](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081113454.png)

![image-20210416081403159](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081403159.png)

![image-20210416081420385](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081420385.png)

![image-20210416081549395](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081549395.png)

![image-20210416081700735](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416081700735.png)

当前同步队列的尾节点为null，调用方法enq()插入;2. 当前队列的尾节点不为null，则采用尾插（compareAndSetTail（）方法）的方式入队。另外还会有另外一个问题：如果 if (compareAndSetTail(pred, node))为false怎么办？会继续执行到enq()方法，同时很明显compareAndSetTail是一个CAS操作，通常来说如果CAS操作失败会继续自旋（死循环）进行重试。因此，经过我们这样的分析，enq()方法可能承担两个任务：1. 处理当前同步队列尾节点为null时进行入队操作；2. 如果CAS尾插入节点失败后负责自旋进行尝试。

![image-20210416082010734](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416082010734.png)



在上面的分析中我们可以看出在第1步中会先创建头结点，说明同步队列是带头结点的链式存储结构。带头结点与不带头结点相比，会在入队和出队的操作中获得更大的便捷性，因此同步队列选择了带头结点的链式存储结构。那么带头节点的队列初始化时机是什么？自然而然是在tail为null时，即当前线程是第一次插入同步队列。compareAndSetTail(t, node)方法会利用CAS操作设置尾节点，如果CAS操作失败会在for (;;)for死循环中不断尝试，直至成功return返回为止。

现在我们已经很清楚**获取独占式锁失败的线程包装成Node**然后插入同步队列的过程了？那么紧接着会有下一个问题？在同步队列中的节点（线程）会做什么事情来保证自己能够有机会获得独占式锁了

![image-20210416082346785](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416082346785.png)

程序逻辑通过注释已经标出，整体来看这是一个这又是一个自旋的过程（for循环），代码首先获取当前节点的先驱节点，如果先驱节点是头结点的并且成功获得同步状态的时候（if (p == head && tryAcquire(arg))），当前节点所指向的线程能够获取锁。反之，获取锁失败进入等待状态。
acquireQueued()在自旋过程中主要完成了两件事情：

1. **如果当前节点的前驱节点是头节点，并且能够获得同步状态的话，当前线程能够获得锁该方法执行结束退出**；
2. **获取锁失败的话，先将节点状态设置成SIGNAL，然后调用LookSupport.park方法使得当前线程阻塞**。

### tryAcquire

protected final boolean tryAcquire(int acquires) {
// 获取“当前线程”

final Thread current = Thread.currentThread();

// 获取“独占锁”的状态

int c = getState();

// c=0意味着“锁没有被任何线程锁拥有”，

if (c == 0) {
// 若“锁没有被任何线程锁拥有”，

// 则判断“当前线程”是不是CLH队列中的第一个线程线程，

// 若是的话，则获取该锁，设置锁的状态，并切设置锁的拥有者为“当前线程”。

if (!hasQueuedPredecessors() &&

compareAndSetState(0, acquires)) {
setExclusiveOwnerThread(current);

return true;

}

}

else if (current == getExclusiveOwnerThread()) {
// 如果“独占锁”的拥有者已经为“当前线程”，

// 则将更新锁的状态。

int nextc = c + acquires;

if (nextc < 0)

throw new Error("Maximum lock count exceeded");

setState(nextc);

return true;

}

return false;

}

### acquire()独占式锁方法流程图

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191214223714472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aGlua3dvbi5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

## ReentrantLock

ReentrantLock重入锁，是实现Lock接口的一个类，**支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞**，ReentrantLock还支持**公平锁和非公平锁**两种方式

公平锁每次获取到锁为同步队列中的第一个节点，保证请求资源时间上的绝对顺序，而非公平锁有可能刚释放锁的线程下次继续获取该锁，则有可能导致其他线程永远无法获取到锁，造成“饥饿”现象。

公平锁为了保证时间上的绝对顺序，需要频繁的上下文切换，而非公平锁会降低一定的上下文切换，降低性能开销。因此，ReentrantLock默认选择的是非公平锁，则是为了减少一部分上下文切换，保证了系统更大的吞吐量。

## Lock和Synchronize区别

1、两者所处层面不同
synchronized是Java中的一个**关键字**，当我们调用它时会从在虚拟机指令层面加锁，关键字为**monitorenter和monitorexit**。Lock是Java中的一个**接口**，它有许多的实现类来为它提供各种功能，加锁的关键代码为大体为Lock和unLock；

2、解锁操作
synchronized：不能指定解锁操作，执行完代码块的对象会自动释放锁
Lock：可调用ulock方法去释放锁比synchronized更灵活

3、获锁方式
synchronized可对实例方法、静态方法和代码块加锁，相对应的，加锁前需要获得实例对象的锁或类对象的锁或指定对象的锁。说到底就是要先获得对象的监视器（即对象的锁）然后才能够进行相关操作。
Lock的使用离不开它的实现类AQS，而它的加锁并不是针对对象的，而是针对当前线程的，并且AQS中有一个原子类state来进行加锁次数的计数。

4、获锁失败
使用关键字synchronized加锁的程序中，获锁失败的对象会被加入到一个虚拟的等待队列中被阻塞，直到锁被释放；1.6以后加入了自旋操作
使用Lock加锁的程序中，获锁失败的线程会被自动加入到AQS的等待队列中进行自旋，自旋的同时再尝试去获取锁，等到自旋到一定次数并且获锁操作未成功，线程就会被阻塞。

5、偏向或重入
synchronized中叫做偏向锁
当线程访问同步块时，会使用 CAS 将线程 ID 更新到锁对象的 Mark Word 中，如果更新成功则获得偏向锁，并且之后每次进入这个对象锁相关的同步块时都不需要再次获取锁了。
Lock中叫做重入锁
AQS的实现类ReentrantLock实现了重入的机制，即若线程a已经获得了锁，a再次请求锁时则会判断a是否持正有锁，然后会将原子值state+1来实现重入的计数操作

## 枚举类

#### 枚举的实现

枚举是JDK1.5之后的特性，在此之前一般是在类中对常量进行定义。那么为什么需要枚举呢？举个栗子：

### 使用静态变量定义四季

假如我们需要使用四个变量来代表“春夏秋冬”：

```java
public class Season {
    public final static int SRPING = 1;
    public final static int SUMMER = 2;
    public final static int AUTUMN = 3;
    public final static int WINTER = 4;
}

```

这时候只要直接引用Season.SPRING就可以了，我们不需要去操心SPRING在存储时是什么数据。但是如果我们想做更多的事：知道下一个季节是什么，还想把季节打印出来：

```java
public class Season {

    private Season(){}

    public final static Season SPRING = new Season();
    public final static Season SUMMER = new Season();
    public final static Season AUTUMN = new Season();
    public final static Season WINTER = new Season();

    public static Season getNextSeason(Season nowSeason){
        if(nowSeason == SPRING){
            return SUMMER;
        }else if(nowSeason == SUMMER){
            return AUTUMN;
        }else if(nowSeason == AUTUMN){
            return WINTER;
        }else{
            return SPRING;
        }
    }

    public static void printNowSeason(Season nowSeason){
        if(nowSeason == SPRING){
            System.out.println("春季");
        }else if(nowSeason == SUMMER){
            System.out.println("夏季");
        }else if(nowSeason == AUTUMN){
            System.out.println("秋季");
        }else{
            System.out.println("冬季");
        }
    }

    public static void main(String[] args){
        Season nowSeason = Season.SUMMER;
        Season.printNowSeason(nowSeason);
        Season nextSeason = Season.getNextSeason(nowSeason);
        Season.printNowSeason(nextSeason);
    }
}

```

因为将Season类的构造方法私有化，外界就不能创建该类的对象了，这就避免了其他奇怪的季节的出现，所有Season对象都在该内部创建。

但是有个问题，用于存储的int值不见了，所以我们还需要设定另一个方法：

```java
    public static int toInt(Season nowSeason){
        if(nowSeason == SPRING){
            return 1;
        }else if(nowSeason == SUMMER){
            return 2;
        }else if(nowSeason == AUTUMN){
            return 3;
        }else{
            return 4;
        }
    }

```

这时如果需要一个Season对象对应的int数据，只需要Season.toInt(Season.SPRING)即可。

但是这种写法有一个隐患：如果想要扩展功能，需要写大量的if-else判断。

这时，枚举来啦。

### 枚举定义四季

我们还是以四季作为栗子：

```java
public enum Season {
    SPRING, SUMMER, AUTUMN, WINTER;
}

```

好啦，枚举定义完了。我们来看看怎么使用它：

```java
class Test{
    public static void main(String[] args){
        System.out.println(Season.SUMMER);  //输出：SUMMER
    }
}

```

在枚举中，默认的toString()方法返回的就是枚举类中对应的名称。但是我们上面要求打印出来的是如”春季“等，而不是名称本身，且四季对应的int值也是必要的。所以我们还得自己完善枚举：

```java
public enum Season {
    SPRING(0), SUMMER(1), AUTUMN(2), WINTER(3);

    private int value;

    private Season(int value){
        this.value = value;
    }

    public static Season getNextSeason(Season nowSeason){
        int nextDayValue = nowSeason.value;
        if(++nextDayValue == 3){
            nextDayValue = 0;
        }
        return getSeasonByValue(nextDayValue);
    }

    public static Season getSeasonByValue(int value){
        for(Season s : Season.values()){
            if(s.value == value){
                return s;
            }
        }
        return null;
    }
}
class Test{
    public static void main(String[] args){
        System.out.println("nowSeason->"+Season.SPRING+", value->"+Season.SPRING.ordinal());
        System.out.println("nextSeason->"+Season.getNextSeason(Season.SPRING));
    }
}

```

这样，我们就实现了既定的目标，和之前的代码相比，没有那么多if-else，是不是感觉少了很多烦恼呢？

所以，我们在定义有限的序列时，如星期、性别等，一般会通过静态变量的形式进行定义，但是这种形式在添加功能的时候，就会需要很多不利于扩展和维护的代码，所以枚举的实现，可以简化这些操作。

### 枚举的用法

枚举类中有些方法还是比较常用的，在此演示几个比较重要的方法。以四季为例：

```java
public enum Season {
    SPRING, SUMMER, AUTUMN, WINTER
}

```

#### Season.valueOf()方法

此方法的作用是**传来一个字符串，然后将它转换成对应的枚举变量**。前提是传入的字符串和定义枚举变量的字符串一模一样，须区分大小写。如果传入了一个不存在的字符串，那么会抛出异常。

```java
System.out.println(Season.valueOf("spring".toUpperCase()));
System.out.println(Season.valueOf("nyfor2020"));

```

运行结果为：

```java
Exception in thread "main" SPRING
java.lang.IllegalArgumentException: No enum constant Season.nyfor2020
 at java.lang.Enum.valueOf(Enum.java:238)
 at Season.valueOf(Season.java:5)
 at Test.main(Season.java:11)

```

Season.values()方法和Season.ordinal()方法
Season.values()方法会返回包括所有枚举变量的数据。

默认情况下，枚举会给所有的枚举变量提供一个默认的次序，该次序类似数组的下标，从0开始，而Season.ordinal()方法正是可以获取其次序的方法。

```java
for (Season s: Season.values()){
            System.out.println(s + ".ordinal() --> "+s.ordinal());
        }

```

运行结果为：

```java
for (Season s: Season.values()){
            System.out.println(s + ".ordinal() --> "+s.ordinal());
        }

```



### 枚举与switch

枚举是JDK1.5才有的特性，同时switch也更新了。使用switch进行条件判断的时候，条件整数一般只能是整型，字符型，而枚举型确实也被switch所支持。还是用“四季“举个栗子：

```java
public enum Season {
    SPRING, SUMMER, AUTUMN, WINTER
}
class SeasonSwitch{
    public void judge(Season s){
        switch (s){
            case SPRING:
                System.out.println("spring");
                break;
            case SUMMER:
                System.out.println("summer");
                break;
            case AUTUMN:
                System.out.println("autumn");
                break;
            case WINTER:
                System.out.println("winter");
                break;
        }
    }
    public static void main(String[] args){
        Season s = Season.SPRING;
        SeasonSwitch seasonSwitch = new SeasonSwitch();
        seasonSwitch.judge(s);
    }
}

```

运行结果为：

```java
spring

```

###  枚举的原理

我们还是拿“四季”作为栗子：



```java
public enum Season {
    SPRING() {
        @Override
        public Season getNextSeason() {
            return SUMMER;
        }
    }, SUMMER() {
        @Override
        public Season getNextSeason() {
            return AUTUMN;
        }
    }, AUTUMN() {
        @Override
        public Season getNextSeason() {
            return WINTER;
        }
    }, WINTER() {
        @Override
        public Season getNextSeason() {
            return SPRING;
        }
    };

    public abstract Season getNextSeason();
}

```

反编译之后，我们可以看到：

```java
>javap Season.class
Compiled from "Season.java"
public abstract class Season extends java.lang.Enum<Season> {
  public static final Season SPRING;
  public static final Season SUMMER;
  public static final Season AUTUMN;
  public static final Season WINTER;
  public static Season[] values();
  public static Season valueOf(java.lang.String);
  public abstract Season getNextSeason();
  Season(java.lang.String, int, Season$1);
  static {};
}

```

经过编译器编译之后，**Season是一个继承了Enum类的抽象类**，而且枚举中定义的**枚举变量变成了相应的public static final属性**，**其类型为抽象类Season类型**，名字就是枚举变量的名字。

同时我们可以看到，Season.class的相同路径下看到四个内部类的.class文件：

![image-20210428103652736](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210428103652736.png)

也就是说，**这四个枚举常量分别使用了内部类来实现**。

同时还**添加了两个方法values()和valueOf(String s)**。我们使用的是默认的无参构造函数，但**现在的构造函数有两个参数**。还**生成了一个静态代码块**。下面我们来详细看下是怎么回事儿：





# JUC

## 线程上下文切换的开销

###  进程切换开销分析 

 开销分成两种，一种是直接开销、一种是间接开销。 

 **进程上下文**：当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文 

直接开销就是在切换时，cpu必须做的事情，包括：

1、切换页表全局目录(**页表查找是一个很慢的过程**，因此通常使用**Cache**来缓存常用的地址映射，这样可以加速页表查找，这个cache就是**TLB**.当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢)

2、切换内核态堆栈

3、切换硬件上下文（进程恢复前，必须装入寄存器的数据统称为硬件上下文）

- ip(instruction pointer)：指向当前执行指令的下一条指令
- bp(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址
- sp(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址
- cr3:页目录基址寄存器，保存页目录表的物理地址

4、刷新TLB

```
 虚拟内存是操作系统为每个进程提供的一种抽象，每个进程都有属于自己的、私有的、地址连续的虚拟内存，当然我们知道最终进程的数据及代码必然要放到物理内存上，那么必须有某种机制能记住虚拟地址空间中的某个数据被放到了哪个物理内存地址上，这就是所谓的地址空间映射，也就是虚拟内存地址与物理内存地址的映射关系，那么操作系统是如何记住这种映射关系的呢，答案就是页表，页表中记录了虚拟内存地址到物理内存地址的映射关系。有了页表就可以将虚拟地址转换为物理内存地址了，这种机制就是虚拟内存。
```

### 线程切换开销

 切换内核栈和硬件上下文 

当一个cpu从一个线程切换到另一个线程时，cpu需要保存当前线程的本地数据，程序当前的指针等，然后加载下一个等待执行的线程的本地数据，程序指针等。这种切换被称之为上下文切换。cpu从执行一个线程切换去执行另一个线程。

上下文切换需要花费很多资源。除非必要，你不要去切换上下文。

### 总结

其实进程切换和线程切换核心就在于页表有没有切换，进程切换的时候才会切换页表，那么块表也就是TLB就会失效，TLB失效命中率低。

## 内存泄漏原因

 该内存空间使用完毕之后未回收)即所谓内存泄漏。 

###  **常见的内存泄露造成的原因** 

 **1、单例造成的内存泄漏**
由于**单例的静态特性使得其生命周期和应用的生命周期一样长**，如果一个对象已经不再需要使用了，而**单例对象还持有该对象的引用**，就会使得该对象不能被正常回收，从而导致了内存泄漏。
示例：防止单例导致内存泄漏的实例 







## JMM

说起JMM的话，还是要从cpu的发展历史说起

英特尔创始人戈登·摩尔曾经说过一句名言：**集成电路上可容纳的晶体管数目，约每隔18个月便会增加一倍，性能也将提升一倍。**

所以我们电脑CPU 的性能越来越强劲，英特尔CPU 从Intel Core 一直到 Intel Core i7，前些年单核CPU 的晶体管数量确实符合摩尔定律





现在的电脑都是多核cpu的，但是有一个问题：**CPU 运算器的运算速度远比内存读写速度快，所以CPU 大部分时间都在等数据从内存读取，运算完数据写回内存。**



因为CPU 运行速度实在太快，主存（就是内存）的数据读取速度和CPU 运算速度差了有几个数量级，所以现代计算机系统通过**在CPU 和主存之前加了一层读写速度尽可能接近CPU 运行速度的高速缓存来做数据缓冲**，这样缓存提前从主存获取数据，CPU 不再从主存取数据，而是从缓存取数据。这样就缓解由于主存速度太慢导致的CPU 饥饿的问题。同时CPU 内还有寄存器，一些计算的中间结果临时放在寄存器内。



**缓存和主存不仅仅是读取写入数据速度上的差异，还有另外更大的区别**：研究人员发现了程序80%的时间在运行20% 的代码，所以缓存本质上只要把20%的常用数据和指令放进来就可以了（其实这一点是和Redis 存放热点数据很像），另外CPU 访问主存数据时存在二个局部性的现象：

1. 时间局部性现象

   **如果一个主存内部的数据正在被访问，那么在短期内它被再次访问的概率会非常大**。想想你程序大部分时间是不是在运行主流程20%的代码。

2. 空间局部性现象

   **CPU使用到某块内存区域数据，这块内存区域后面临近的数据很大概率立即会被使用到。**这个很好解释，我们程序经常用的数组、集合（本质也是数组）经常会顺序访问（内存地址连续或邻近）。

因为这二个局部性现象的存在使得缓存的存在可以很大程度上缓解CPU 饥饿的问题。

现在主流的多核CPU的硬件架构，如下图所示。

![image-20210910102725848](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910102725848.png)

现代操作系统一般会有多级缓存（Cache Line），一般有L1、L2，甚至有L3



### 数据是怎么在主存、缓存、CPU寄存器之间流转

比如以 `i = i + 2;` 为例， 当线程执行到这条语句时，会先从主存中读取i 的值，然后复制一份到缓存中，CPU 读取缓存数据（取数指令），进行 i + 2 操作（中间数据放寄存器），然后把结果写入缓存，最后将缓存中i最新的值刷新到主存当中（写回主存时间不确定）。

这个数据操作逻辑在单线程环境和多线程环境下还是有区别的

例如：有A、B二个线程，在二个不同的CPU 上运行，因为每个线程运行的CPU 都有自己的缓存，i是共享变量，初始值是0，A 线程从内存读取i 的值存入缓存，B 线程此时也读取i 的值存入自己CPU的缓存，A 线程对i 进行+1操作，i变成了1，B线程缓存中的变量 i 还是0，B线程也对i 进行+1操作，最后A、B线程先后将缓存数据写回内存共享区，预期的结果应该是2，因为发生了二次+1操作，但是实际是1。

![image-20210910103153183](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910103153183.png)

缓存不一致

这个就是非常著名的**缓存一致性问题**，注意这里还只是多CPU的缓存一致性问题，**和我们常说的多线程共享变量安全问题还不相同。**

<!--单核CPU 的多线程也会出现上面的线程不安全的问题，只是产生原因不是多核CPU缓存不一致的问题导致，而是CPU调度线程切换，多线程局部变量不同步引起的。-->

### cpu如何解决缓存一致性问题

早期的一些CPU 设计中，是通过锁总线（总线访问加Lock# 锁）的方式解决的

**通过总线锁机制，只能单一线程访问主存的数据，其他线程不能访问主存，这种锁粒度其实是很大的**

![image-20210910103548589](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910103548589.png)

CPU内体系结构

因为CPU 都是通过总线来读取主存中的数据，因此对总线加Lock# 锁的话，其他CPU 访问主存就被阻塞了，这样防止了对共享变量的竞争。但是锁总线对CPU的性能损耗非常大，把多核CPU 并行的优势直接给干没了！（还记得并发第一集的并行知识吧）

后面为了解决缓存一致性问题，研究人员就搞出了一套协议：**缓存一致性协议**。协议的类型很多（MSI、MESI、MOSI、Synapse、Firefly），最常见的就是Intel （英特尔）的MESI 协议。缓存一致性协议主要规范了CPU 读写主存、管理缓存数据的一系列规范，如下图所示。

![image-20210910103910977](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910103910977.png)



缓存一致性协议（MESI协议）的核心思想：

- 定义了缓存中的数据状态只有四种，MESI 是四种状态的首字母。
- 当CPU写数据时，如果写的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态；
- 当CPU读取共享变量时，发现自己缓存的该变量的缓存行是无效的，那么它就会从内存中重新读取。

> 缓存中数据都是以缓存行（Cache Line）为单位存储

![image-20210910104047334](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910104047334.png)

> 1、M(Modify) 表示共享数据只缓存在当前 CPU 缓存中， 并且是被修改状态，也就是缓存的数据和主内存中的数据不一致。
> 2、E(Exclusive) 表示缓存的独占状态，数据只缓存在当前 CPU 缓存中，并且没有被修改。
> 3、S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致。
> 4、I(Invalid) 表示缓存已经失效。
> 在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的 读写操作，而且也监听(snoop)其它 Cache 的读写操作。
> 对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则:
>
> 1、CPU 读请求:缓存处于 M、E、S 状态都可以被读取，I 状 态 CPU 只能从主存中读取数据。
> 2、CPU 写请求:缓存处于 M、E 状态才可以被写。对于 S 状 态的写，需要将其他 CPU 中缓存行置为无效才可写 使用总线锁和缓存锁机制之后，CPU 对于内存的操作大概 可以抽象成下面这样的结构。从而达到缓存一致性效果。
>

**既然有MESI 的存在，解决多核CPU的缓存一致性，为什么还需要Java用volatile 这种关键字？**

因为我们知道volatile 也是保证共享变量的可见性。

**volatile是Java语言层面来定义的，Java语言实现volatile 的内存可见性需要借助MESI，但是有的CPU只有单核、或者不支持MESI、**那怎么实现内存可见呢？可以是通过锁总线的方式，**volatile其实是屏蔽了不同硬件的差异**（毕竟java要实现跨平台，同样的代码在不同的操作系统上执行结果），**说直接点：使用volatile 修饰的变量是有内存可见性的，这是Java 语法定的，Java 不关心你底层操作系统、硬件CPU 是如何实现内存可见的，我的语法规定就是volatile 修饰的变量必须是具有可见性的。**

虚拟机实现volatile的方式是写入了一条**lock 前缀的汇编指令**，lock 前缀的汇编指令会**强制变量写入主存**，也可避免前后指令的CPU重排序，并及时让其他核中的相应缓存行失效，volatile是利用MESI达到符合预期的效果。



CPU 有X86（复杂指令集）、ARM（精简指令集）等体系架构，版本类型也有很多种，CPU 可能通过锁总线、MESI 协议实现多核心缓存的一致性。**因为有硬件的差异以及编译器和处理器的指令重排优化的存在，所以Java 需要一种协议来规避硬件平台的差异**，保障同一段代码在所有平台运行效果一致，这个协议叫做Java 内存模型（Java Memory Model）。

Java内存模型（ `Java Memory Model`）并不是真实存在，只是定义了一套规范

所有的变量都存储在**主内存**中，每个线程还有自己的**工作内存**，线程的工作内存中保存了该线程使用到的变量（主内存的拷贝），线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，如下图所示，线程的所有操作都是把主内存的数据放在自己的工作内存进行。

JMM 中定义的每个线程私有的工作内存是抽象的规范，实际上工作内存和真实的CPU 内存架构如下所示，Java 内存模型和真实硬件内存架构是不同的：

![image-20210910111128873](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910111128873.png)

JMM 是内存模型，是抽象的协议。首先真实的内存架构是没有区分堆和栈的，这个Java 的JVM 来做的划分，另外线程私有的本地内存线程栈可能包括CPU 寄存器、缓存和主存。堆亦是如此

### JMM 内存模型规范

- 初始变量首先存储在主内存中；
- 线程操作变量需要从主内存拷贝到线程本地内存中；
- 线程的**本地工作内存**是一个抽象概念，包括了缓存、寄存器、store buffer(CPU内的缓存区域)等。

一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作（单一操作都是原子的）来完成：

- **lock（锁定）**：作用于主内存的变量，把一个变量标识为一条线程独占状态。
- **unlock（解锁）**：作用于主内存变量，把一个处于锁定状态的变量解除锁定，解除锁定后的变量才可以被其他线程锁定。
- **read（读取）**：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
- **load（载入）**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
- **use（使用）**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
- **assign（赋值）**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
- **store（有的指令是save/存储）**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。
- **write（写入）**：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。
- ![image-20210910111752136](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910111752136.png)

Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：

- 如果要把一个变量从主内存中复制到工作内存，需要顺序执行read 和load 操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行store 和write 操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行，也就是操作不是原子的，一组操作可以中断。
- 不允许read和load、store和write操作之一单独出现，必须成对出现。
- 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。
- 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。
- 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。
- 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现
- 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值
- 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。
- 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。

#### final语义中的内存屏障

对于final域，编译器和CPU会遵循两个排序规则：

1、新建对象过程中，构造体中**对final域的初始化写入和这个对象赋值给其他引用变量**，这两个操作不能重排序；
2、初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序；（意思就是先赋值引用，再调用final值）
总之上面规则的意思可以这样理解：必需保证一个对象的所有final域被写入完毕后才能引用和读取。这也是内存屏障的起的作用：
1、写final域：在编译器写final域完毕，构造体结束之前，会插入一个StoreStore屏障，保证前面的对final写入对其他线程/CPU可见，并阻止重排序。
2、读final域：在上述规则2中，两步操作不能重排序的机理就是在读final域前插入了LoadLoad屏障。
3、X86处理器中，由于CPU不会对写-写操作进行重排序，所以StoreStore屏障会被省略；而X86也不会对逻辑上有先后依赖关系的操作进行重排序，所以LoadLoad也会变省略。

#### HappenBefore原则

定义：前一个操作的结果对于后续操作是可见的。在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在 happens-before 关系。这两个操作可以是同一个线程，也可以是不同的线程。

JMM 中有哪些方法建立 happen-before 规则：
1、**as-if-serial 规则（程序顺序执行）：单个线程中的代码顺序不管怎么重排序，对于结果来说是不变的。**
2、volatile 变量规则，对于 volatile 修饰的变量的写的操作， 一定 happen-before 后续对于 volatile 变量的读操作;
3、监视器锁规则（monitor lock rule）：对一个监视器的解锁，happens-before于随后对这个监视器的加锁。
4、传递性规则：如果A happens-before B，且B happens-before C，那么A happens-before C。
5、start 规则：如果线程 A 执行操作 ThreadB.start(),那么线程 A 的 ThreadB.start()操作 happens-before 线程 B 中的任意操作。
6、join 规则：如果线程 A 执行操作 ThreadB.join()并成功返回，那么线程 B 中的任意操作 happens-before 于线程 A 从 ThreadB.join()操作成功返回。

#### 发编程的三个特征

- 可见性

  可见性是指当多个线程访问同一个共享变量时，一个线程修改了这个变量的值，其他线程能够立即看到修改后的值。

- 原子性

  原子性指的一个操作或一组操作要么全部执行，要么全部不执行。

- 有序性

  有序性是指程序执行的顺序按照代码的先后顺序执行。

## ThreadLocal

在处理多线程并发安全的方法中，最常用的方法，就是使用锁，通过锁来控制多个不同线程对临界区的访问。

但是，无论是什么样的锁，乐观锁或者悲观锁，都会在并发冲突的时候对性能产生一定的影响。

那有没有一种方法，可以彻底避免竞争呢？

答案是肯定的，这就是ThreadLocal。

从字面意思上看，ThreadLocal可以解释成线程的局部变量，也就是说一个ThreadLocal的变量只有当前自身线程可以访问，别的线程都访问不了，那么自然就避免了线程竞争。

因此，ThreadLocal提供了一种与众不同的线程安全方式，它不是在发生线程冲突时想办法解决冲突，而是彻底的避免了冲突的发生。

### ThreadLocal的基本使用

创建一个ThreadLocal对象：

```java
private ThreadLocal<Integer> localInt = new ThreadLocal<>();
```

上述代码创建一个localInt变量，由于ThreadLocal是一个泛型类，这里指定了localInt的类型为整数。

下面展示了如果设置和获取这个变量的值：

```java
public int setAndGet(){
    localInt.set(8);
    return localInt.get();
}
```

上述代码设置变量的值为8，接着取得这个值。

由于ThreadLocal里设置的值，只有当前线程自己看得见，这意味着你不可能通过其他线程为它初始化值。为了弥补这一点，ThreadLocal提供了一个withInitial()方法统一初始化所有线程的ThreadLocal的值：

```java
private ThreadLocal<Integer> localInt = ThreadLocal.withInitial(() -> 6);
```

上述代码将ThreadLocal的初始值设置为6，这对全体线程都是可见的。

### ThreadLocal的实现原理

ThreadLocal变量只在单个线程内可见，那它是如何做到的呢？我们先从最基本的get()方法说起：

```Java
public T get() {
    //获得当前线程
    Thread t = Thread.currentThread();
    //每个线程 都有一个自己的ThreadLocalMap，
    //ThreadLocalMap里就保存着所有的ThreadLocal变量
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        //ThreadLocalMap的key就是当前ThreadLocal对象实例，
        //多个ThreadLocal变量都是放在这个map中的
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            //从map里取出来的值就是我们需要的这个ThreadLocal变量
            T result = (T)e.value;
            return result;
        }
    }
    // 如果map没有初始化，那么在这里初始化一下
    return setInitialValue();
}
```

可以看到，所谓的ThreadLocal变量就是保存在每个线程的map中的。这个map就是Thread对象中的threadLocals字段。如下：

```java
ThreadLocal.ThreadLocalMap threadLocals = null;
```


ThreadLocal.ThreadLocalMap是一个比较特殊的Map，它的每个Entry的key都是一个弱引用：

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
    /** The value associated with this ThreadLocal. */
    Object value;
    //key就是一个弱引用
    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        value = v;
    }
}
```

这样设计的好处是，如果这个变量不再被其他对象使用时，可以自动回收这个ThreadLocal对象，避免可能的内存泄露（注意，Entry中的value，依然是强引用，如何回收，见下文分解）。

### 理解ThreadLocal中的内存泄漏问题

虽然ThreadLocalMap中的key是弱引用，当不存在外部强引用的时候，就会自动被回收，但是Entry中的value依然是强引用。这个value的引用链条如下：

![image-20210806161019551](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210806161019551.png)

可以看到，只有当Thread被回收时，这个value才有被回收的机会，否则，只要线程不退出，value总是会存在一个强引用。但是，要求每个Thread都会退出，是一个极其苛刻的要求，对于线程池来说，大部分线程会一直存在在系统的整个生命周期内，那样的话，就会造成value对象出现泄漏的可能。处理的方法是，在ThreadLocalMap进行set(),get(),remove()的时候，都会进行清理：

以getEntry()为例：

```java
private Entry getEntry(ThreadLocal<?> key) {
    int i = key.threadLocalHashCode & (table.length - 1);
    Entry e = table[i];
    if (e != null && e.get() == key)
        //如果找到key，直接返回
        return e;
    else
        //如果找不到，就会尝试清理，如果你总是访问存在的key，那么这个清理永远不会进来
        return getEntryAfterMiss(key, i, e);
}
```

下面是getEntryAfterMiss()的实现：

```java
private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
    Entry[] tab = table;
    int len = tab.length;

    while (e != null) {
        // 整个e是entry ，也就是一个弱引用
        ThreadLocal<?> k = e.get();
        //如果找到了，就返回
        if (k == key)
            return e;
        if (k == null)
            //如果key为null，说明弱引用已经被回收了
            //那么就要在这里回收里面的value了
            expungeStaleEntry(i);
        else
            //如果key不是要找的那个，那说明有hash冲突，这里是处理冲突，找下一个entry
            i = nextIndex(i, len);
        e = tab[i];
    }
    return null;
}

```

下面是getEntryAfterMiss()的实现：

```java
private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
    Entry[] tab = table;
    int len = tab.length;

    while (e != null) {
        // 整个e是entry ，也就是一个弱引用
        ThreadLocal<?> k = e.get();
        //如果找到了，就返回
        if (k == key)
            return e;
        if (k == null)
            //如果key为null，说明弱引用已经被回收了
            //那么就要在这里回收里面的value了
            expungeStaleEntry(i);
        else
            //如果key不是要找的那个，那说明有hash冲突，这里是处理冲突，找下一个entry
            i = nextIndex(i, len);
        e = tab[i];
    }
    return null;
}

```

真正用来回收value的是expungeStaleEntry()方法，在remove()和set()方法中，都会直接或者间接调用到这个方法进行value的清理：

从这里可以看到，ThreadLocal为了避免内存泄露，也算是花了一番大心思。不仅使用了弱引用维护key，还会在每个操作上检查key是否被回收，进而再回收value。

但是从中也可以看到，ThreadLocal并不能100%保证不发生内存泄漏。

比如，很不幸的，你的get()方法总是访问固定几个一直存在的ThreadLocal，那么清理动作就不会执行，如果你没有机会调用set()和remove()，那么这个内存泄漏依然会发生。

因此，一个良好的习惯依然是：当你不需要这个ThreadLocal变量时，主动调用remove()，这样对整个系统是有好处的。

### ThreadLocalMap中的Hash冲突处理

ThreadLocalMap作为一个HashMap和java.util.HashMap的实现是不同的。对于java.util.HashMap使用的是链表法来处理冲突：



但是，对于ThreadLocalMap，它使用的是简单的线性探测法，如果发生了元素冲突，那么就使用下一个槽位存放：
![image-20210806161937941](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210806161937941.png)

具体来说，整个set()的过程如下：

### 可以被继承的ThreadLocal——InheritableThreadLocal

在实际开发过程中，我们可能会遇到这么一种场景。主线程开了一个子线程，但是我们希望在子线程中可以访问主线程中的ThreadLocal对象，也就是说有些数据需要进行父子线程间的传递。比如像这样：

```java
public static void main(String[] args) {
    ThreadLocal threadLocal = new ThreadLocal();
    IntStream.range(0,10).forEach(i -> {
        //每个线程的序列号，希望在子线程中能够拿到
        threadLocal.set(i);
        //这里来了一个子线程，我们希望可以访问上面的threadLocal
        new Thread(() -> {
            System.out.println(Thread.currentThread().getName() + ":" + threadLocal.get());
        }).start();
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    });
}

```

执行上述代码，你会看到：

```java
Thread-0:null
Thread-1:null
Thread-2:null
Thread-3:null

```

因为在子线程中，是没有threadLocal的。如果我们希望子线可以看到父线程的ThreadLocal，那么就可以使用InheritableThreadLocal。顾名思义，这就是一个支持线程间父子继承的ThreadLocal，将上述代码中的threadLocal使用InheritableThreadLocal：

```java
InheritableThreadLocal threadLocal = new InheritableThreadLocal();
```


再执行，就能看到：

再执行，就能看到：

```java
Thread-0:0
Thread-1:1
Thread-2:2
Thread-3:3
Thread-4:4
```

可以看到，每个线程都可以访问到从父进程传递过来的一个数据。虽然InheritableThreadLocal看起来挺方便的，但是依然要注意以下几点：

变量的传递是发生在线程创建的时候，如果不是新建线程，而是用了线程池里的线程，就不灵了
变量的赋值就是从主线程的map复制到子线程，它们的value是同一个对象，如果这个对象本身不是线程安全的，那么就会有线程安全问题

## LockSupport 线程工具类

`LockSupport`会为使用它的线程关联一个许可证（`permit`）状态，`permit`的语义「是否拥有许可」，`0`代表否，`1`代表是，默认是`0`。

- `LockSupport.unpark`：指定线程关联的`permit`直接更新为`1`，如果更新前的`permit<1`，唤醒指定线程
- `LockSupport.park`：当前线程关联的`permit`如果`>0`，直接把`permit`更新为`0`，否则阻塞当前线程

### 优点

为什么推荐使用`LockSupport`来做线程的阻塞与唤醒（**线程间协同工作**），因为它具备如下优点

- 以线程为操作对象更符合阻塞线程的直观语义
- 操作更精准，可以准确地唤醒某一个线程（`notify`随机唤醒一个线程，`notifyAll`唤醒所有等待的线程）
- 无需竞争锁对象（以线程作为操作对象），不会因竞争锁对象产生死锁问题
- `unpark`与`park`没有严格的执行顺序，不会因执行顺序引起死锁问题，比如「`Thread.suspend`和`Thread.resume`」没按照严格顺序执行，就会产生死锁

另外`LockSupport`还提供了`park`的重载函数，提升灵活性

- `void parkNanos(long nanos)`：增加了超时机制
- `void parkUntil(long deadline)`：加入超时机制（指定到某个时间点，`1970`年到指定时间点的毫秒数）
- `void park(Object blocker)`：设置`blocker`对象，当线程没有许可证被阻塞时，该对象会被记录到该线程的内部，方便后续使用诊断工具进行问题排查
- `void parkNanos(Object blocker, long nanos)`：设置`blocker`对象，加入超时机制
- `void parkUntil(Object blocker, long deadline)`：设置`blocker`对象，加入超时机制（指定到某个时间点，`1970`年到指定时间点的毫秒数）

建议使用时，传入`blocker`对象，至于超时根据业务场景选择



## CAS

CAS 它是一种`系统原语`，原语属于操作系统用语，原语也是由若干条指令组成，原语是不可以被中断的，这个实现靠的是操作系统的关中断和开中断来实现的，在执行过程中不允许被中断，也就是说 CAS 是一条 CPU 的原子指令，由操作系统硬件来保证。

**在 Intel 的 CPU 中，使用 cmpxchg 汇编指令。**

JDK 是在 1.5 版本后才引入 CAS 操作，在`sun.misc.Unsafe`这个类中定义了 CAS 相关的方法。

```java
public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x);

public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);

public final native boolean compareAndSwapLong(Object o, long offset, long expected, long x);
```



### CAS 在 Java 语言中的应用

在 Java 编程中我们通常不会直接使用到 CAS，都是通过 JDK 封装好的并发工具类来间接使用的，这些并发工具类都在`java.util.concurrent`包中。

目前 CAS 在 JDK 中主要应用在 J.U.C 包下的 Atomic 相关类中。

![image-20210910091144200](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910091144200.png)

比如说 AtomicInteger 类就可以解决 i++ 非原子性问题，通过查看源码可以发现主要是靠 volatile 关键字和 CAS 操作来实现

### CAS 的问题

#### 典型 ABA 问题

ABA 是 CAS 操作的一个经典问题，假设有一个变量初始值为 A，修改为 B，然后又修改为 A，这个变量实际被修改过了，但是 CAS 操作可能无法感知到。

如果是整形还好，不会影响最终结果，但如果是对象的引用类型包含了多个变量，引用没有变实际上包含的变量已经被修改，这就会造成大问题。

如何解决？思路其实很简单，在变量前加版本号，每次变量更新了就把版本号加一，结果如下：

![image-20210910091238676](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210910091238676.png)

最终结果都是 A 但是版本号改变了。

**从 JDK 1.5 开始提供了`AtomicStampedReference`类**，这个类的 `compareAndSe`方法首先检查`当前引用`是否等于`预期引用`，并且`当前标志`是否等于`预期标志`，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

#### 自旋开销问题

CAS 出现冲突后就会开始`自旋`操作，如果资源竞争非常激烈，自旋长时间不能成功就会给 CPU 带来非常大的开销。

**解决方案：可以考虑限制自旋的次数，避免过度消耗 CPU；另外还可以考虑延迟执行。**

#### 只能保证单个变量的原子性

当对一个共享变量执行操作时，可以使用 CAS 来保证原子性，但是如果要对多个共享变量进行操作时，CAS 是无法保证原子性的，比如需要将 i 和 j 同时加 1：

```
i++；j++；
```

这个时候可以使用 synchronized 进行加锁，有没有其他办法呢？有，将多个变量操作合成一个变量操作。**从 JDK1.5 开始提供了`AtomicReference` 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。**





# 面向对象的七大设计原则

## **单一职责原则（Single Responsibility Principle）**

定义：通俗的说，即一个类只负责一项职责。

**问题由来：**类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有
可能会导致原本运行正常的职责P2功能发生故障。

比如我有一个交通工具的这么一个类。类里面只有一个方法run()，传入的参数是交通工具，然后输出交通工具+在公路上运行.然后我传了一个飞机，就会输出，飞机在公路上运行。这就明显违背了单一职责原则。我们应该根据交通工具运行方式的不同来划分为不同的类.比如我们可以增加一个在天上运输的交通工具类，还有在水上运输的交通工具。这样每一个类的职责就很单一，互不打扰。如果我们不增加这两个类，我们也可以在最开始的类的方法里面加上两个判断，如果传入的参数是飞机，就输出飞机在天上飞，如果传入的是船，就输出船在水上运行。但是可能由于某些原因，就会输出一个摩托车在水上运行，这里我只是举了一个稍微极端的例子，这种错误是绝对不能在客户端发生的，一旦发生，后果可能会很严重。所以也是出于安全的角度，我们还是让每个类的职责更加单一一些。省的以后这个类的功能可能被细化了，从而对这个类做出一些改变的时候，可能会影响到这个类最开始的功能.



## **里氏替换原则（Liskov Substitution Principle）**



任何父类出现的地方，子类一定可以替换这个父类.

## **依赖倒置原则（Dependence Inversion Principle）**

DIP是6大原则中最难以实现的原则，它是实现开闭原则的重要途径，DIP没有实现，就别想实现对扩展开放，对修改关闭。在项目中只要记住“面向接口编程”就基本上抓住了DIP的核心.





## **接口隔离原则（Interface Segregation Principle）**



## **迪米特法则（Law Of Demeter）**



## **开闭原则（Open Close Principle）**





## **组合/聚合复用原则（Composite/Aggregate Reuse Principle CARP）**







# 代理和反射



代理的好处就是让被代理的角色职责更加单一了，比如房东就是出租房子的，那我中介代理你房东是可以加一些附属操作的，比如收中介费，带着要租房子的人去看房子，但是问题就是每增加一个接口的实例，就会创建一个新的代理类，代码量会翻倍(因为根据面向对象的七大原则中的开闭原则，就是对拓展开发，对修改关闭，当我们增加一个真实角色的时候，也就是增加了一个房东就会对原阿来的代理类做出修改)。然后就是使用动态代理

一个动态代理代理的是一个接口，一般对应的是一类业务

一个动态代理类可以代理多个类，只要实现了同一个接口，只要是实现了同一个接口

我们在开发的时候是从dao层到service层再到controller层这样的一个纵向的开发，当我们需要增加一些业务需求的时候，就要实现一个横向的切入，就是在不改变原有代码的情况下，实现对系统功能的一个拓展



![image-20210416132645653](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416132645653.png)

![image-20210416133212540](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416133212540.png)

![image-20210416133629922](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416133629922.png)

## spring实现Aop

![image-20210416134745036](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416134745036.png)

![image-20210416135001528](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135001528.png)

![image-20210416135054243](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135054243.png)

![image-20210416135351493](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135351493.png)

![image-20210416135321025](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135321025.png)

![image-20210416135519263](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135519263.png)

![image-20210416135705569](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135705569.png)

![image-20210416135824834](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416135824834.png)

# JVM

## JVM内存布局

### 程序计数器

程序计数器（Program Counter Register）是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。在虚拟机概念模型中，字节码解释器工作时就是通过改变计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。

程序计数器是一块“线程私有”的内存，如上文的图所示，每条线程都有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储。这样设计使得在多线程环境下，线程切换后能恢复到正确的执行位置。

如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；若执行的是Native方法，则计数器为空（Undefined）（因为对于Native方法而言，它的方法体并不是由Java字节码构成的，自然无法应用上述的“字节码指令的地址”的概念）。程序计数器也是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的内存区域。

### Java虚拟机栈

Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame），栈帧中存储着**局部变量表**、**操作数栈**(i++和++i)、**动态链接**、**方法出口等**信息。每一个方法从调用直至执行完成的过程，会对应一个栈帧在虚拟机栈中入栈到出栈的过程。与程序计数器一样，Java虚拟机栈也是线程私有的。

函数的调用有完美的嵌套关系——调用者的生命期总是长于被调用者的生命期，并且后者在前者的之内。这样，被调用者的局部信息所占空间的分配总是后于调用者的（后入），而其释放则总是先于调用者的（先出），所以正好可以满足栈的LIFO顺序，选用栈这种数据结构来实现调用栈是一种很自然的选择。

局部变量表中存放了编译期可知的各种：

基本数据类型(boolen、byte、char、short、int、 float、 long、double）
对象引用（reference类型，它不等于对象本身，可能是一个指向对象起始地址的指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）
returnAddress类型（指向了一条字节码指令的地址）
其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot变量槽），其余数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。这里说的“大小”是指变量槽的数量，虚拟机真正使用多大的内存空间（譬如按照1个变量槽占用32个比特、 64个比特， 或者更多） 来实现一个变量槽， 这是完全由具体的虚拟机实现自行决定的事情  。

Java虚拟机规范中对这个区域规定了两种异常状况：

StackOverflowError：线程请求的栈深度大于虚拟机所允许的深度，将会抛出此异常。
OutOfMemoryError：当可动态扩展的虚拟机栈在扩展时无法申请到足够的内存，就会抛出该异常。

### 本地方法栈

本地方法栈（Native Method Stack）与Java虚拟机栈作用很相似，它们的区别在于虚拟机栈为虚拟机执行Java方法（即字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。

在虚拟机规范中对本地方法栈中使用的语言、方式和数据结构并无强制规定，因此具体的虚拟机可实现它。甚至有的虚拟机（Sun HotSpot虚拟机）直接把本地方法栈和虚拟机栈合二为一。与虚拟机一样，本地方法栈会抛出StackOverflowError和OutOfMemoryError异常。

### Java堆

对于大多数应用而言，Java堆（Heap）是Java虚拟机所管理的内存中最大的一块，它被所有线程共享的，在虚拟机启动时创建。此内存区域唯一的目的是存放对象实例，几乎所有的对象实例都在这里分配内存，且每次分配的空间是不定长的。在Heap 中分配一定的内存来保存对象实例，实际上只是保存对象实例的属性值，属性的类型和对象本身的类型标记等，并不保存对象的方法（方法是指令，保存在Stack中）,在Heap 中分配一定的内存保存对象实例和对象的序列化比较类似。对象实例在Heap 中分配好以后，需要在Stack中保存一个4字节的Heap 内存地址，用来定位该对象实例在Heap 中的位置，便于找到该对象实例。

Java虚拟机规范中描述道：所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展和逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都在堆上分配的定论也并不“绝对”了。比如逃逸分析。我们一个方法里面的一个变量如果没有被其他类所引用的话，那么这个变量就在栈上分配空间，我记得叫栈空间，那虽然方法被执行就压栈，随着方法结束就弹出栈，变量的栈空间被释放。

新生代（Young）： 新生成的对象优先存放在新生代中，新生代对象朝生夕死，存活率很低。在新生代中，常规应用进行一次垃圾收集一般可以回收70% ~ 95% 的空间，回收效率很高。新生代又可细分为Eden空间、From Survivor空间、To Survivor空间，默认比例为8:1:1。

老年代（Tenured/Old）：在新生代中经历了多次（具体看虚拟机配置的阀值）GC后仍然存活下来的对象会进入老年代中。老年代中的对象生命周期较长，存活率比较高，在老年代中进行GC的频率相对而言较低，而且回收的速度也比较慢。

永久代（Perm）：永久代存储类信息、常量、静态变量、即时编译器编译后的代码等数据，对这一区域而言，Java虚拟机规范指出可以不进行垃圾收集，一般而言不会进行垃圾回收。

BEA JRockit、 IBM J9等来说， 是不存在永久代的概念的  

jdk1.6字符串常量池在方法区中。

1.7之后在堆中。运行时常量池一直在方法区中。

jdk1.8开始，移除永久代概念，方法区用元空间实现。原空间采用本地内存

### 方法区

方法区（Method Area）与Java堆一样，是各个线程共享的内存区域。Object Class Data(类定义数据)是存储在方法区的，此外，常量、静态变量、JIT编译后的代码也存储在方法区。正因为方法区所存储的数据与堆有一种类比关系，所以它还被称为 Non-Heap。

JDK 1.8以前的永久代（PermGen）

Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集，也就是说，Java虚拟机规范只是规定了方法区的概念和它的作用，并没有规定如何去实现它。对于JDK 1.8之前的版本，HotSpot虚拟机设计团队选择把GC分代收集扩展至方法区，即用永久代来实现方法区，这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。对于其他的虚拟机（如Oracle JRockit、IBM J9等）来说是不存在永久代的概念的。

如果运行时有大量的类产生，可能会导致方法区被填满，直至溢出。常见的应用场景如：

Spring和ORM框架使用CGLib操纵字节码对类进行增强，增强的类越多，就需要越大的方法区来保证动态生成的Class可以加载入内存。
大量JSP或动态产生JSP文件的应用（JSP第一次运行时需要编译为Java类）。
基于OSGi的应用（即使是同一个类文件，被不同的类加载器加载也会视为不同的类）。 ……
这些都会导致方法区溢出，报出java.lang.OutOfMemoryError: PermGen space。

JDK 1.8的元空间（Metaspace）

在JDK 1.8中，HotSpot虚拟机设计团队为了促进HotSpot与 JRockit的融合，修改了方法区的实现，移除了永久代，选择使用本地化的内存空间（而不是JVM的内存空间）存放类的元数据，这个空间叫做元空间（Metaspace）。

做了这个改动以后，java.lang.OutOfMemoryError: PermGen的空间问题将不复存在，并且不再需要调整和监控这个内存空间。且虚拟机需要为方法区设计额外的GC策略：如果类元数据的空间占用达到参数“MaxMetaspaceSize”设置的值，将会触发对死亡对象和类加载器的垃圾回收。 为了限制垃圾回收的频率和延迟，适当的监控和调优元空间是非常有必要的。元空间过多的垃圾收集可能表示类、类加载器内存泄漏或对你的应用程序来说空间太小了。

元空间的内存管理由元空间虚拟机来完成。先前，对于类的元数据我们需要不同的垃圾回收器进行处理，现在只需要执行元空间虚拟机的C++代码即可完成。在元空间中，类和其元数据的生命周期和其对应的类加载器是相同的。话句话说，只要类加载器存活，其加载的类的元数据也是存活的，因而不会被回收掉。

#### 运行时常量池（Runtime Constant Pool）

运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量(常量，string字符串)和符号引用，这部分内容将在类加载后进入方法区的运行时常量池存放。

Java虚拟机对Class文件每一部分（自然包括常量池）的格式有严格规定，每一个字节用于存储那种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行。但对于运行时常量池，Java虚拟机规范没有做任何有关细节的要求，不同的提供商实现的虚拟机可以按照自己的需求来实现此内存区域。不过一般而言，除了保存Class文件中的描述符号引用外，还会把翻译出的直接引用也存储在运行时常量池中。

运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译器才能产生，也就是并非置入Class文件中的常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，此特性被开发人员利用得比较多的便是String类的intern() 方法。

### 直接内存

直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但这部分内存也被频繁运用，而却可能导致OutOfMemoryError异常出现，所以这里放到一起讲解。

以NIO（New Input/Output）类为例，NIO引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能避免在Java堆和Native堆中来回复制数据，在一些场景里显著提高性能。

本机直接内存的分配不会受到Java堆大小的限制，但是既然是内存，还是会受到本机总内存（包括RAM以及SWAP区或分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统的限制），从而导致动态扩展时出现OutOfMemoryError异常。

## 对象的创建过程

### Java的对象创建大致有如下四种方式：

1、new关键字 这应该是我们最常见和最常用最简单的创建对象的方式。
2、使用newInstance()方法 这里包括Class类的newInstance()方法和Constructor类的newInstance()方法（前者其实也是调用的后者）。
3、使用clone()方法 要使用clone()方法我们必须实现实现Cloneable接口，用clone()方法创建对象并不会调用任何构造函数。即我们所说的浅拷贝。
4、反序列化 要实现反序列化我们需要让我们的类实现Serializable接口。当我们序列化和反序列化一个对象，JVM会给我们创建一个单独的对象，在反序列化时，JVM创建对象并不会调用任何构造函数。即我们所说的深拷贝。

### 类加载检查

虚拟机遇到一条new指令时，首先将去检查**这个指令的参数是否能在常量池中定位到一个类的符号引用**，并且检查**这个符号引用代表的类是否已被加载、解析和初始化过的**，如果没有，则必须先执行相应的类加载过程。

### 类加载 

首先通过一个类的全限定名来获取此类的二进制字节流；其次将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构；最后在java堆中生成一个代表这个类的Class对象，作为方法区这些数据的访问入口。总的来说就是查找并加载类的二进制数据。 

### 链接

#### 验证：确保被加载类的正确性

验证是链接阶段的第一步，这一步主要的目的是确保class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身安全。
验证阶段主要包括四个检验过程：文件格式验证、元数据验证、字节码验证和符号引用验证。

1.文件格式验证

 验证class文件格式规范，例如： class文件是否已魔术0xCAFEBABE开头 ， 主、次版本号是否在当前虚拟机处理范围之内等

2.元数据验证

这个阶段是对字节码描述的信息进行语义分析，以保证起描述的信息符合java语言规范要求。验证点可能包括：这个类是否有父类(除了java.lang.Object之外，所有的类都应当有父类)、这个类是否继承了不允许被继承的类(被final修饰的)、如果这个类的父类是抽象类，是否实现了起父类或接口中要求实现的所有方法。

3.字节码验证

 进行数据流和控制流分析，这个阶段对类的方法体进行校验分析，这个阶段的任务是保证被校验类的方法在运行时不会做出危害虚拟机安全的行为。如：保证访法体中的类型转换有效，例如可以把一个子类对象赋值给父类数据类型，这是安全的，但不能把一个父类对象赋值给子类数据类型、保证跳转命令不会跳转到方法体以外的字节码命令上。

4.符号引用验证

符号引用中通过字符串描述的全限定名是否能找到对应的类、符号引用类中的类，字段和方法的访问性(private、protected、public、default)是否可被当前类访问。


#### 准备：为类的静态变量分配内存，并将其初始化为默认值

准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的知识点，首先是这时候进行内存分配的仅包括类变量(static 修饰的变量),而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在java堆中。其次是这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量定义为:

public static int value  = 12;

那么变量value在准备阶段过后的初始值为0而不是12，因为这时候尚未开始执行任何java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器<clinit>()方法之中，所以把value赋值为12的动作将在初始化阶段才会被执行。

上面所说的“通常情况”下初始值是零值，那相对于一些特殊的情况，如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，建设上面类变量value定义为：

public static final int value = 123;

编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value设置为123。


#### 解析：把类中的符号引用转换为直接引用

解析阶段是虚拟机常量池内的符号引用替换为直接引用的过程。
符号引用：符号引用是一组符号来描述所引用的目标对象，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标对象并不一定已经加载到内存中。

直接引用：直接引用可以是直接指向目标对象的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机内存布局实现相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同，如果有了直接引用，那引用的目标必定已经在内存中存在。

虚拟机规范并没有规定解析阶段发生的具体时间，只要求了在执行anewarry、checkcast、getfield、instanceof、invokeinterface、invokespecial、invokestatic、invokevirtual、multianewarray、new、putfield和putstatic这13个用于操作符号引用的字节码指令之前，先对它们使用的符号引用进行解析，所以虚拟机实现会根据需要来判断，到底是在类被加载器加载时就对常量池中的符号引用进行解析，还是等到一个符号引用将要被使用前才去解析它。

解析的动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行。分别对应编译后常量池内的CONSTANT_Class_Info、CONSTANT_Fieldref_Info、CONSTANT_Methodef_Info、CONSTANT_InterfaceMethoder_Info四种常量类型。

### 分配内存

在类加载检查通过后，虚拟机就将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定（如何确定在下一节对象内存布局时再详细讲解），为对象分配空间的任务具体便等同于从Java堆中划出一块大小确定的内存空间，可以分如下两种情况讨论：

Java堆中内存绝对规整 所有用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump The Pointer）。

Java堆中的内存不规整 已被使用的内存和空闲的内存相互交错，那就没有办法简单的进行指针碰撞了，虚拟机就必须维护一个列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。

选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。因此在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时（说明一下，CMS收集器可以通过UseCMSCompactAtFullCollection或CMSFullGCsBeforeCompaction来整理内存），就通常采用空闲列表。

除如何划分可用空间之外，另外一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并非线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存。解决这个问题有如下两个方案：

对分配内存空间的动作进行同步 实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性。
把内存分配的动作按照线程划分在不同的空间之中进行 即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（TLAB ，Thread Local Allocation Buffer），哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完，分配新的TLAB时才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。

### 初始化

内存分配完成之后，虚拟机需要**将分配到的内存空间都初始化为零值（不包括对象头）**，如果使用TLAB的话，这一个工作也可以提前至TLAB分配时进行。这步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用。

###  设置对象头

接下来，虚拟机要**设置对象的信息**（如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息）并存放在对象的**对象头（Object Header）**中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

### 执行`<init>`方法

在上面工作都完成之后，在虚拟机的视角来看，一个新的对象已经产生了。但是在Java程序的视角看来，对象创建才刚刚开始——<init>方法还没有执行，所有的字段都还为零值。所以一般来说（由字节码中是否跟随有invokespecial指令所决定），new指令之后会接着执行<init>方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。


## JDK1.8默认收集器

JDK1.8中默认使用的是Parallel Scavenge和Parallel Old收集器组合。

![image-20210415152016774](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210415152016774.png)

![image-20210415152030089](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210415152030089.png)

#### 



## 虚拟机栈和本地方法栈溢出  

由于HotSpot虚拟机中并不区分虚拟机栈和本地方法栈， 因此对于HotSpot来说， -Xoss参数（设置本地方法栈大小） 虽然存在， 但实际上是没有任何效果的， 栈容量只能由-Xss参数来设定。 关于虚拟机栈和本地方法栈， 在《Java虚拟机规范》 中描述了两种异常：  

1） 如果线程请求的栈深度大于虚拟机所允许的最大深度， 将抛出StackOverflowError异常。
2） 如果虚拟机的栈内存允许动态扩展， 当扩展栈容量无法申请到足够的内存时， 将抛出
OutOfMemoryError异常。  

《Java虚拟机规范》 明确允许Java虚拟机实现自行选择是否支持栈的动态扩展， 而HotSpot虚拟机的选择是不支持扩展，所以除非在创建线程申请内存时就因无法获得足够内存而出现OutOfMemoryError异常， 否则在线程运行时是不会因为扩展而导致内存溢出的， 只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。  

## 垃圾收集器

![image-20210416012634201](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416012634201.png)

### Serial收集器

Serial收集器应该是**最基础、 历史最悠久**的收集器， 曾经（在JDK 1.3.1之前） 是HotSpot虚拟机新生代收集器的唯一选择。 这个收集器是一个**单线程工作的收集器**， 但它的“单线程”的意义并不仅仅是说明**它只会使用一个处理器或一条收集线程去完成垃圾收集工作， 更重要的是强调在它进行垃圾收集时， 必须暂停其他所有工作线程， 直到它收集结束。** “Stop The World”这个词语也许听起来很酷， 但这项工作是由虚拟机在后台自动发起和自动完成的， 在用户不可知、 不可控的情况下把用户的正常工作的线程全部停掉， 这对很多应用来说都是不能接受的。 读者不妨试想一下， 要是你的电脑每运行一个小时就会暂停响应五分钟， 你会有什么样的心情？

对于单核处理器或处理器核心数较少的环境来说， Serial收集器由于没有线程交互的开销， 专心做垃圾收集自然可以获得最高的单线程收集效率。   

### ParNew收集器  

ParNew收集器实质上是Serial收集器的**多线程并行版本**， 除了同时使用多条线程进行垃圾收集之外， 其余的行为包括Serial收集器可用的所有控制参数（例如： -XX： SurvivorRatio、 -XX：PretenureSizeThreshold、 -XX： HandlePromotionFailure等） 、 收集算法、 Stop The World、 对象分配规则、 回收策略等都与Serial收集器完全一致， 在实现上这两种收集器也共用了相当多的代码。  

ParNew收集器除了支持多线程并行收集之外， 其他与Serial收集器相比并没有太多创新之处， 但它却是不少运行在服务端模式下的HotSpot虚拟机， 尤其是JDK 7之前的遗留系统中首选的新生代收集器， 其中有一个与功能、 性能无关但其实很重要的原因是： 除了Serial收集器外， 目前只有它能与CMS收集器配合工作。 

并行（Parallel） ： 并行描述的是多条垃圾收集器线程之间的关系， 说明同一时间有多条这样的线程在协同工作， 通常默认此时用户线程是处于等待状态 。

·并发（Concurrent） ： 并发描述的是垃圾收集器线程与用户线程之间的关系， 说明同一时间垃圾收集器线程与用户线程都在运行。 由于用户线程并未被冻结， 所以程序仍然能响应服务请求， 但由于垃圾收集器线程占用了一部分系统资源， 此时应用程序的处理的吞吐量将受到一定影响。  

ParNew收集器在单核心处理器的环境中绝对不会有比Serial收集器更好的效果， 甚至由于存在线程交互的开销， 该收集器在通过超线程（Hyper-Threading） 技术实现的伪双核处理器环境中都不能百分之百保证超越Serial收集器。 当然， 随着可以被使用的处理器核心数量的增加， ParNew对于垃圾收集时系统资源的高效利用还是很有好处的。 它默认开启的收集线程数与处理器核心数量相同， 在处理器核心非常多（譬如32个， 现在CPU都是多核加超线程设计， 服务器达到或超过32个逻辑核心的情况非常普遍） 的环境中， 可以使用-XX： ParallelGCThreads参数来限制垃圾收集的线程数。  

### Parallel Scavenge收集器  

Parallel Scavenge收集器也是一款新生代收集器， 它同样是基于标记-复制算法实现的收集器， 也是能够并行收集的多线程收集器  。

Parallel Scavenge收集器的特点是它的关注点与其他收集器不同， **CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间， 而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量**（Throughput） 。 所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值  。

![image-20210416012928851](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416012928851.png)

**如果虚拟机完成某个任务， 用户代码加上垃圾收集总共耗费了100分钟， 其中垃圾收集花掉1分钟， 那吞吐量就是99%**。 停顿时间越短就越适合需要与用户交互或需要保证服务响应质量的程序， 良好的响应速度能提升用户体验； 而高吞吐量则可以最高效率地利用处理器资源， 尽快完成程序的运算任务， 主要适合在后台运算而不需要太多交互的分析任务。  

Parallel Scavenge收集器提供了**两个参数用于精确控制吞吐量**， 分别是控制最大垃圾收集停顿时间的-XX： MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX： GCTimeRatio参数。  

-XX： MaxGCPauseMillis参数允许的值是一个大于0的毫秒数， 收集器将尽力保证内存回收花费的时间不超过用户设定值。 不过大家不要异想天开地认为如果把这个参数的值设置得更小一点就能使得系统的垃圾收集速度变得更快， 垃圾收集停顿时间缩短是以牺牲吞吐量和新生代空间为代价换取的：系统把新生代调得小一些， 收集300MB新生代肯定比收集500MB快， 但这也直接导致垃圾收集发生得更频繁， 原来10秒收集一次、 每次停顿100毫秒， 现在变成5秒收集一次、 每次停顿70毫秒。 停顿时间的确在下降， 但吞吐量也降下来了。-XX： GCTimeRatio参数的值则应当是一个大于0小于100的整数， 也就是垃圾收集时间占总时间的比率， 相当于吞吐量的倒数。 譬如把此参数设置为19， 那允许的最大垃圾收集时间就占总时间的5%即1/(1+19)） ， 默认值为99， 即允许最大1%（即1/(1+99)） 的垃圾收集时间。  

由于与吞吐量关系密切， Parallel Scavenge收集器也经常被称作“吞吐量优先收集器”。 除上述两个参数之外， Parallel Scavenge收集器还有一个参数-XX： +UseAdaptiveSizePolicy值得我们关注。 这是一个开关参数， 当这个参数被激活之后， 就不需要人工指定新生代的大小（-Xmn） 、 Eden与Survivor区的比例（-XX： SurvivorRatio） 、 晋升老年代对象大小（-XX： PretenureSizeThreshold） 等细节参数了， 虚拟机会根据当前系统的运行情况收集性能监控信息， 动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 这种调节方式称为垃圾收集的自适应的调节策略（GC Ergonomics）。   

如果读者对于收集器运作不太了解， 手工优化存在困难的话， 使用Parallel Scavenge收集器配合自适应调节策略， 把内存管理的调优任务交给虚拟机去完成也许是一个很不错的选择。 只需要把基本的内存数据设置好（如-Xmx设置最大堆） ， 然后使用-XX： MaxGCPauseMillis参数（更关注最大停顿时间） 或-XX： GCTimeRatio（更关注吞吐量） 参数给虚拟机设立一个优化目标， 那具体细节参数的调节工作就由虚拟机完成了。 自适应调节策略也是Parallel Scavenge收集器区别于ParNew收集器的一个重要特性。  

### Serial Old收集器  

Serial Old是Serial收集器的老年代版本， 它同样是一个单线程收集器， 使用**标记-整理算法**。 这个收集器的主要意义也是供客户端模式下的HotSpot虚拟机使用。 如果在服务端模式下， 它也可能有两种用途： 一种是在JDK 5以及之前的版本中与Parallel Scavenge收集器搭配使用， 另外一种就是作为CMS收集器发生失败时的后备预案， 在并发收集Concurrent Mode Failure时使用。



### Parallel Old收集器    

**Parallel Old是Parallel Scavenge收集器的老年代版本**， 支持多线程并发收集， **基于标记-整理**算法实现。 这个收集器是直到JDK 6时才开始提供的， 在此之前， 新生代的Parallel Scavenge收集器一直处于相当尴尬的状态， 原因是如果新生代选择了Parallel Scavenge收集器， 老年代除了Serial Old（PSMarkSweep） 收集器以外别无选择， 其他表现良好的老年代收集器， 如CMS无法与它配合工作。 由于老年代Serial Old收集器在服务端应用性能上的“拖累”， 使用Parallel Scavenge收集器也未必能在整体上获得吞吐量最大化的效果。 同样， 由于单线程的老年代收集中无法充分利用服务器多处理器的并行处理能力， 在老年代内存空间很大而且硬件规格比较高级的运行环境中， 这种组合的总吞吐量甚至不一定比ParNew加CMS的组合来得优秀。直到Parallel Old收集器出现后， “吞吐量优先”收集器终于有了比较名副其实的搭配组合， 在注重
**吞吐量或者处理器资源较为稀缺的场合， 都可以优先考虑Parallel Scavenge加Parallel Old收集器这个组合。**   



### ※※※CMS收集器  

CMS（Concurrent Mark Sweep） 收集器是一种以**获取最短回收停顿时间为目标的收集器**。 目前很大一部分的Java应用集中在互联网网站或者基于浏览器的B/S系统的服务端上， 这类应用通常都会较为关注服务的响应速度， 希望系统停顿时间尽可能短， 以给用户带来良好的交互体验。 CMS收集器就非常符合这类应用的需求  。

从名字（包含“Mark Sweep”） 上就可以看出CMS收集器是基于标记-清除算法实现的， 它的运作
过程相对于前面几种收集器来说要更复杂一些， 整个过程分为四个步骤， 包括：  

1） 初始标记（CMS initial mark）
2） 并发标记（CMS concurrent mark）
3） 重新标记（CMS remark）
4） 并发清除（CMS concurrent sweep）  

其中初始标记、 重新标记这两个步骤仍然需要“Stop The World”。 **初始标记仅仅只是标记一下GCRoots能直接关联到的对象， 速度很快；** **并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程，** 这个过程耗时较长但是不需要停顿用户线程， 可以与垃圾收集线程一起并发运行； **而重新标记阶段则是为了修正并发标记期间， 因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录** ， 这个阶段的停顿时间通常会比初始标记阶段稍长一些， 但也远比并发标记阶段的时间短； 最后是并发清除阶段， 清理删除掉标记阶段判断的已经死亡的对象， 由于不需要移动存活对象， 所以这个阶段也是可以与用户线程同时并发的。  

缺点：

首先， **CMS收集器对处理器资源非常敏感**。 事实上， **面向并发设计的程序都对处理器资源比较敏感**。 在并发阶段， 它虽然不会导致用户线程停顿， **但却会因为占用了一部分线程**（或者说处理器的计算能力） 而导致应用程序变慢， 降低总吞吐量。   

CMS收集器无法处理“浮动垃圾”（Floating Garbage）  有可能出现“Con-current ModeFailure”失败进而导致另一次完全“Stop The World”的Full GC的产生。 **在CMS的并发标记和并发清理阶段， 用户线程是还在继续运行的，** 程序在运行自然就还会伴随有新的垃圾对象不断产生， 但这一部分垃圾对象是出现在标记过程结束以后， CMS无法在当次收集中处理掉它们， 只好留待下一次垃圾收集时再清理掉。 这一部分垃圾就称为“浮动垃圾”。  

CMS是一款基于“标记-清除”算法实现的收集器，就可能想到这意味着收集结束时会有大量空间碎片产生。  

### Garbage First(G1)收集器

在G1收集器出现之前的所有其他收集器， 包括CMS在内， 垃圾收集的目标范围要么是整个新生代（Minor GC） ， 要么就是整个老年代（Major GC） ， 再要么就是整个Java堆（Full GC） 。   而G1是可以面向堆内存任何部分来组成回收集（Collection Set， 一般简称CSet） 进行回收， 衡量标准不再是它属于哪个分代， 而是**哪块内存中存放的垃圾数量最多， 回收收益最大**， 这就是G1收集器的Mixed GC模式。  

作为CMS收集器的替代者和继承人， 设计者们希望做出一款能够建立起“**停顿时间模型”**（PausePrediction Model） 的收集器， 停顿时间模型的意思是**能够支持指定在一个长度为M毫秒的时间片段内， 消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标。**

把连续的Java堆划分为多个大小相等的独立区域（Region） ， 每一个Region都可以根据需要， 扮演新生代的Eden空间、 Survivor空间， 或者老年代空间。收集器能够**对扮演不同角色的Region采用不同的策略去处理**， 这样无论是新创建的对象还是已经存活了一段时间、 熬过多次收集的旧对象都能获取很好的收集效果。Region中还有一类特殊的Humongous区域， 专门用来存储大对象。 G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。  每个Region的大小可以通过参数-XX： G1HeapRegionSize设定， 取值范围为1MB～32MB， 且应为2的N次幂。 而对于那些**超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中， G1的大多数行为都把Humongous Region作为老年代的一部分来进行看待。**

虽然G1仍然保留新生代和老年代的概念， 但新生代和老年代不再是固定的了， 它们都是一系列区域（不需要连续） 的动态集合。 G1收集器之所以能建立可预测的停顿时间模型， 是因为它将Region作为单次回收的最小单元， 即**每次收集到的内存空间都是Region大小的整数倍**， 这样可以有计划地避免在整个Java堆中进行全区域的垃圾收集。 更具体的处理思路是让G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小， 价值即回收所获得的空间大小以及回收所需时间的经验值， 然后在**后台维护一个优先级列表**， 每次根据用户设定允许的收集停顿时间（使用参数-XX： MaxGCPauseMillis指定， 默认值是200毫秒） ， 优先处理回收价值收益最大的那些Region， 这也就是“Garbage First”名字的由来。这种使用Region划分内存空间， 以及具有优先级的区域回收方式， 保证了G1收集器在有限的时间内获取尽可能高的收集效率  。

·初始标记（Initial Marking） ： **仅仅只是标记一下GC Roots能直接关联到的对象**， 并且修改TAMS指针的值， 让下一阶段用户线程并发运行时， 能正确地在可用的Region中分配新对象。 这个阶段需要停顿线程， 但耗时很短， 而且是借用进行Minor GC的时候同步完成的， 所以G1收集器在这个阶段实际并没有额外的停顿。 

·并发标记（Concurrent Marking） ： 从GC Root开始对堆中对象进行可达性分析， 递归扫描整个堆里的对象图， 找出要回收的对象， 这阶段耗时较长， 但可与用户程序并发执行。 当对象图扫描完成以后， 还要重新处理SATB记录下的在并发时有引用变动的对象。   

·重新标记（Final Marking） ： 对用户线程做另一个短暂的暂停， 用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。  

· 并发清除（Final Marking） ： 对用户线程做另一个短暂的暂停， 用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。  

## GC Roots的对象  

在虚拟机栈（栈帧中的本地变量表） 中引用的对象， 譬如各个线程被调用的方法堆栈中使用到的
参数、 局部变量、 临时变量等。  

在方法区中类静态属性引用的对象， 譬如Java类的引用类型静态变量。  

在方法区中常量引用的对象， 譬如字符串常量池（String Table） 里的引用  

在本地方法栈中JNI（即通常所说的Native方法） 引用的对象。  

Java虚拟机内部的引用， 如基本数据类型对应的Class对象， 一些常驻的异常对象（比如
NullPointExcepiton、 OutOfMemoryError） 等， 还有系统类加载器。  

所有被同步锁（synchronized关键字） 持有的对象  。

引用计数法有一个问题就是无法解决多个对象间相互引用的问题，本来这两个对象是没有GCroots可以连接到这两个对象的，但是因为他们自身的引用计数都不为0，所以无法进行一个回收，多了的话可能就会导致内存泄漏 。其实内存泄漏是我们写代码的时候更多的是不规范而导致的。比如我一个for循环创建了一个集合，每次新建一个object类型的变量，加入到这个集合以后，我再另创建的对象的引用为nul。，**如果我们仅仅释放引用本身**，**那么 Vector 仍然引用该对象**，所以**这个对象对 GC 来说是不可回收的**。因此，如果对象加入到Vector 后，还必须从 Vector 中删除，最简单的方法就是将 **Vector 对象设置为 null。**

![image-20210416143425363](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416143425363.png)

除了这些固定的GC Roots集合以外， 根据用户所选用的垃圾收集器以及当前回收的内存区域不
同， 还可以有其他对象“临时性”地加入， 共同构成完整GC Roots集合。 譬如后文将会提到的分代收集
和局部回收（Partial GC） ， 如果只针对Java堆中某一块区域发起垃圾收集时（如最典型的只针对新生
代的垃圾收集） ， 必须考虑到内存区域是虚拟机自己的实现细节（在用户视角里任何内存区域都是不
可见的） ， 更不是孤立封闭的， 所以某个区域里的对象完全有可能被位于堆中其他区域的对象所引
用， 这时候就需要将这些关联区域的对象也一并加入GC Roots集合中去， 才能保证可达性分析的正确
性。  

## 强软弱虚

### 强引用

强引用是最传统的“引用”的定义， 是指在程序代码之中普遍存在的引用赋值， 即类似“Object
obj=new Object()”这种引用关系。 无论任何情况下， 只要强引用关系还存在， 垃圾收集器就永远不会回
收掉被引用的对象  

### 软引用

**软引用是用来描述一些还有用， 但非必须的对象**。 只被软引用关联着的对象， **在系统将要发生内**
**存溢出异常前， 会把这些对象列进回收范围之中进行第二次回收**， 如果这次回收还没有足够的内存，
才会抛出内存溢出异常。 在JDK 1.2版之后提供了SoftReference类来实现软引用  

### 弱引用

弱引用也是用来描述那些非必须对象， 但是它的强度比软引用更弱一些， 被弱引用关联的对象只
能生存到下一次垃圾收集发生为止。 当垃圾收集器开始工作， 无论当前内存是否足够， 都会回收掉只
被弱引用关联的对象。 在JDK 1.2版之后提供了WeakReference类来实现弱引用  

### 虚引用

虚引用也称为“幽灵引用”或者“幻影引用”， 它是最弱的一种引用关系。 一个对象是否有虚引用的
存在， 完全不会对其生存时间构成影响， 也无法通过虚引用来取得一个对象实例。 为一个对象设置虚
引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。 在JDK 1.2版之后提供
了PhantomReference类来实现虚引用。  

## 回收方法区

判定一个常量是否“废弃”还是相对简单， 而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。 需要同时满足下面三个条件：  

该类所有的实例都已经被回收， 也就是Java堆中不存在该类及其任何派生子类的实例。  

加载该类的类加载器已经被回收， 这个条件除非是经过精心设计的可替换类加载器的场景， 如OSGi、 JSP的重加载等， 否则通常是很难达成的  。

该类对应的java.lang.Class对象没有在任何地方被引用， 无法在任何地方通过反射访问该类的方法。  



 Java虚拟机被允许对满足上述三个条件的无用类进行回收， 这里说的仅仅是“被允许”， 而并不是
和对象一样， 没有引用了就必然会回收。 关于是否要对类型进行回收， HotSpot虚拟机提供了-
Xnoclassgc参数进行控制， 还可以使用-verbose： class以及-XX： +TraceClass-Loading、 -XX：
+TraceClassUnLoading查看类加载和卸载信息， 其中-verbose： class和-XX： +TraceClassLoading可以在
Product版的虚拟机中使用， -XX： +TraceClassUnLoading参数需要FastDebug版[1]的虚拟机支持。
在大量使用反射、 动态代理、 CGLib等字节码框架， 动态生成JSP以及OSGi这类频繁自定义类加载
器的场景中， 通常都需要Java虚拟机具备类型卸载的能力， 以保证不会对方法区造成过大的内存压
力。  

## 基础故障处理工具

### jps： 虚拟机进程状况工具  

JDK的很多小工具的名字都参考了UNIX命令的命名方式， jps（ JVM Process Status Tool） 是其中
的典型。 除了名字像UNIX的ps命令之外， 它的功能也和ps命令类似： 可以列出正在运行的虚拟机进
程， 并显示虚拟机执行主类（ Main Class， main()函数所在的类） 名称以及这些进程的本地虚拟机唯一
ID（ LVMID， Local Virtual Machine Identifier） 。 虽然功能比较单一， 但它绝对是使用频率最高的JDK
命令行工具， 因为其他的JDK工具大多需要输入它查询到的LVMID来确定要监控的是哪一个虚拟机进
程。 对于本地虚拟机进程来说， LVMID与操作系统的进程ID（ PID， Process Identifier） 是一致的， 使
用Windows的任务管理器或者UNIX的ps命令也可以查询到虚拟机进程的LVMID， 但如果同时启动了
多个虚拟机进程， 无法根据进程名称定位时， 那就必须依赖jps命令显示主类的功能才能区分了  

jps命令格式： jps [ options ] [ hostid ]  

![image-20210427214726438](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210427214726438.png) 

### jstat： 虚拟机统计信息监视工具  

jstat（ JVM Statistics Monitoring Tool） 是用于监视虚拟机各种运行状态信息的命令行工具。 它可
以显示本地或者远程[1]虚拟机进程中的类加载、 内存、 垃圾收集、 即时编译等运行时数据， 在没有
GUI图形界面、 只提供了纯文本控制台环境的服务器上， 它将是运行期定位虚拟机性能问题的常用工
具。  

![image-20210427214801851](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210427214801851.png)



### jinfo： Java配置信息工具  

jinfo（ Configuration Info for Java） 的作用是实时查看和调整虚拟机各项参数。 使用jps命令的-v参
数可以查看虚拟机启动时显式指定的参数列表， 但如果想知道未被显式指定的参数的系统默认值， 除
了去找资料外， 就只能使用jinfo的-flag选项进行查询了（ 如果只限于JDK 6或以上版本的话， 使用javaXX： +PrintFlagsFinal查看参数默认值也是一个很好的选择） 。 jinfo还可以使用-sysprops选项把虚拟机
进程的System.getProperties()的内容打印出来。 这个命令在JDK 5时期已经随着Linux版的JDK发布， 当
时只提供了信息查询的功能， JDK 6之后， jinfo在Windows和Linux平台都有提供， 并且加入了在运行期
修改部分参数值的能力（ 可以使用-flag[+|-]name或者-flag name=value在运行期修改一部分运行期可写的
虚拟机参数值） 。 在JDK 6中， jinfo对于Windows平台功能仍然有较大限制， 只提供了最基本的-flag选
项。  

![image-20210427214840819](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210427214840819.png)

### jmap： Java内存映像工具  

map（ Memory Map for Java） 命令用于生成堆转储快照（ 一般称为heapdump或dump文件） 。 如
果不使用jmap命令， 要想获取Java堆转储快照也还有一些比较“暴力”的手段： 譬如在第2章中用过的-
XX： +HeapDumpOnOutOfMemoryError参数， 可以让虚拟机在内存溢出异常出现之后自动生成堆转储
快照文件， 通过-XX： +HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成堆转储快
照文件， 又或者在Linux系统下通过Kill-3命令发送进程退出信号“恐吓”一下虚拟机， 也能顺利拿到堆转
储快照  

jmap的作用并不仅仅是为了获取堆转储快照， 它还可以查询finalize执行队列、 Java堆和方法区的
详细信息， 如空间使用率、 当前用的是哪种收集器等  

和jinfo命令一样， jmap有部分功能在Windows平台下是受限的， 除了生成堆转储快照的-dump选项
和用于查看每个类的实例、 空间占用统计的-histo选项在所有操作系统中都可以使用之外， 其余选项都
只能在Linux/Solaris中使用。  

![image-20210427215012481](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210427215012481.png)



### jhat： 虚拟机堆转储快照分析工具  

### jstack： Java堆栈跟踪工具  

jstack（ Stack Trace for Java） 命令用于生成虚拟机当前时刻的线程快照（ 一般称为threaddump或者
javacore文件） 。 线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合， 生成线程快照的
目的通常是定位线程出现长时间停顿的原因， 如线程间死锁、 死循环、 请求外部资源导致的长时间挂
起等， 都是导致线程长时间停顿的常见原因。 线程出现停顿时通过jstack来查看各个线程的调用堆栈，
就可以获知没有响应的线程到底在后台做些什么事情， 或者等待着什么资源。  

![image-20210427215130860](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210427215130860.png)



## 调优参数

### 堆的参数配置

-XX:+PrintGC 每次触发GC的时候打印相关日志
-XX:+UseSerialGC 串行回收
-XX:+PrintGCDetails 更详细的GC日志
-Xms 堆初始值
-Xmx 堆最大可用值
-Xmn 新生代堆最大可用值
-XX:SurvivorRatio 用来设置新生代中eden空间和from/to空间的比例.
含以-XX:SurvivorRatio=eden/from=den/to
总结:在实际工作中，我们可以直接将初始的堆大小与最大堆大小相等，
这样的好处是可以减少程序运行时垃圾回收次数，从而提高效率。
-XX:SurvivorRatio 用来设置新生代中eden空间和from/to空间的比例.

### 设置最大堆内存

参数: -Xms5m -Xmx20m -XX:+PrintGCDetails -XX:+UseSerialGC -XX:+PrintCommandLineFlags

### 设置新生代与老年代优化参数

-Xmn 新生代大小，一般设为整个堆的1/3到1/4左右
-XX:SurvivorRatio 设置新生代中eden区和from/to空间的比例关系n/1

### 设置新生代比例参数

参数: -Xms20m -Xmx20m -Xmn1m -XX:SurvivorRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC

### 设置新生与老年代代参数

-Xms20m -Xmx20m -XX:SurvivorRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC
-Xms20m -Xmx20m -XX:SurvivorRatio=2 -XX:+PrintGCDetails -XX:+UseSerialGC
-XX:NewRatio=2
总结:不同的堆分布情况，对系统执行会产生一定的影响，在实际工作中，应该根据系统的特点做出合理的配置，基本策略：尽可能将对象预留在新生代，减少老年代的GC次数。除了可以设置新生代的绝对大小(-Xmn),可以使用(-XX:NewRatio)设置新生代和老年代的比例:-XX:NewRatio=老年代/新生代

### ※※※内存溢出解决办法

设置堆内存大小

### 错误原因: java.lang.OutOfMemoryError: Java heap space

**解决办法:设置堆内存大小 -Xms1m -Xmx70m -XX:+HeapDumpOnOutOfMemoryError**

设置栈内存大小

### 错误原因: java.lang.StackOverflowError

栈溢出 产生于递归调用，循环遍历是不会的，但是循环方法里面产生递归调用， 也会发生栈溢出。
解决办法:设置线程最大调用深度
-Xss5m 设置最大调用深度

## JVM参数调优总结

在JVM启动参数中，可以设置跟内存、垃圾回收相关的一些参数设置，默认情况不做任何设置JVM会工作的很好，但对一些配置很好的Server和具体的应用必须仔细调优才能获得最佳性能。通过设置我们希望达到一些目标：

GC的时间足够的小
GC的次数足够的少
发生Full GC的周期足够的长
前两个目前是相悖的，要想GC时间小必须要一个更小的堆，要保证GC次数足够少，必须保证一个更大的堆，我们只能取其平衡。

针对JVM堆的设置，一般可以通过-Xms -Xmx限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，我们通常把最大、最小设置为相同的值
年轻代和年老代将根据默认的比例（1：2）分配堆内存，可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代，比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize设置为同样大小
年轻代和年老代设置多大才算合理？这个我问题毫无疑问是没有答案的，否则也就不会有调优。我们观察一下二者大小变化有哪些影响
 更大的年轻代必然导致更小的年老代，大的年轻代会延长普通GC的周期，但会增加每次GC的时间；小的年老代会导致更频繁的Full GC
 更小的年轻代必然导致更大年老代，小的年轻代会导致普通GC很频繁，但每次的GC时间会更短；大的年老代会减少Full GC的频率
 如何选择应该依赖应用程序对象生命周期的分布情况：如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。
但很多应用都没有这样明显的特性，在抉择时应该根据以下两点：（A）本着Full GC尽量少的原则，让年老代尽量缓存常用对象，JVM的默认比例1：2也是这个道理 （B）通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响Full GC的前提下，根据实际情况加大年轻代，比如可以把比例控制在1：1。但应该给年老代至少预留1/3的增长空间



# 阿里巴巴开发手册

## 命名风格  

1. 【强制】 代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。
   反例： _name / __name / $name / name_ / name$ / name__  

2.  【强制】方法名、参数名、成员变量、局部变量都统一使用 lowerCamelCase 风格，必须遵从
   驼峰形式  正例： localValue / getHttpMessage() / inputUserId  

3. 【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。  

   正例： MAX_STOCK_COUNT
   反例： MAX_COUNT  

## 常量定义

1. 【强制】 在 long 或者 Long 赋值时， 数值后使用大写的 L，不能是小写的 l，小写容易跟数字混淆，造成误解。
   说明： Long a = 2l; 写的是数字的 21，还是 Long 型的 2?  

## 代码格式  

1. 【强制】大括号的使用约定。如果是大括号内为空，则简洁地写成{}即可，不需要换行； 如果
   是非空代码块则：
   1） 左大括号前不换行。
   2） 左大括号后换行。
   3） 右大括号前换行。
   4） 右大括号后还有 else 等代码则不换行； 表示终止的右大括号后必须换行。  

## OOP 规约  

1. 【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成
   本，直接用类名来访问即可  
2.  【强制】所有的覆写方法，必须加@Override 注解。
   说明： getObject()与 get0bject()的问题。一个是字母的 O，一个是数字的 0，加@Override
   可以准确判断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编
   译报错。  

## 集合处理  

1. 【强制】 关于 hashCode 和 equals 的处理，遵循如下规则：
   1） 只要重写 equals，就必须重写 hashCode。
   2） 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的
   对象必须重写这两个方法。
   3） 如果自定义对象作为 Map 的键，那么必须重写 hashCode 和 equals。
   说明： String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象
   作为 key 来使用。  

   

## ♥并发处理

【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。
说明： Executors 返回的线程池对象的弊端如下：
1） FixedThreadPool 和 SingleThreadPool:
允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。
2） CachedThreadPool 和 ScheduledThreadPool:
允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM。  

# 仿写springioc

其实我写的那个小demo就是简单的实现一个属性注入的这么一个过程，大概流程

```
package com.qcby.spring;

import org.w3c.dom.Document;
import org.w3c.dom.Element;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;
import java.io.FileNotFoundException;
import java.io.InputStream;
import java.lang.reflect.Field;

import java.util.HashMap;
import java.util.Map;

public class SpringIOC {
    private Map<String, Object> beanMap = new HashMap<String,Object>();
    private SpringIOC(){}
    SpringIOC(String xmlName) throws Exception {
    loadBean(xmlName);
    }
    private void loadBean(String xmlName) throws Exception {
        //将xml文件转为输入流
        InputStream inputStream = SpringIOC.class.getClassLoader().getResourceAsStream(xmlName);
        //没找到xml文件就抛出异常
        if (inputStream==null){
            throw new FileNotFoundException("没有找到此xml文件：" + xmlName);
        }
        //创建一个DocumentBuilderFactury对象
        DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
        //创建DocumentBuilder对象
        DocumentBuilder documentBuilder = dbf.newDocumentBuilder();
        //通过DocumentBuilder对象的parser方法加载Io流文件
        Document parse = documentBuilder.parse(inputStream);
        //用完关闭流
        inputStream.close();
        //获取所有bean节点的集合
        NodeList bean = parse.getElementsByTagName("bean");
        //遍历bean标签
        for (int i = 0; i <bean.getLength() ; i++) {
            Node node = bean.item(i);
            //node 强制类型转换为Element
            if (node instanceof Element){
                Element element = (Element) node;
                //获取bean标签里面的指定元素的值；
                String beanId = element.getAttribute("id");
                String beanClass = element.getAttribute("class");
                //通过反射获取对象
               Class beanClazz = Class.forName(beanClass);
               //创建bean对象
               Object beanObj = beanClazz.newInstance();
                // 获取bean标签的子标签。
                NodeList propertyList = element.getElementsByTagName("property");
                for (int j = 0; j <propertyList.getLength() ; j++) {
                    Node item = propertyList.item(j);
                    if (item instanceof Element){
                        Element element1 = (Element) item;
                        //获得到属性名称
                        String name = element1.getAttribute("name");
                        //获得属性的值
                        String value = element1.getAttribute("value");
                        //通过反射获取指定属性字段
                        Field declaredField = beanObj.getClass().getDeclaredField(name);
                        //将私有属性设置为可以访问的
                        declaredField.setAccessible(true);
                        String fieldTypeName = declaredField.getType().getName();
                        Object o = ParamType(fieldTypeName, value);
                        //为该成员属性赋值
                        declaredField.set(beanObj, o);
                        //将该字段属性设置值
                        beanMap.put(beanId, beanObj);
                    }
                }
            }
        }
    }
    private Object ParamType(String fieldTypeName, String value) {
        Object obj = null;
        //判断该成员属性是否为int或Integer类型
        if ("int".equals(fieldTypeName) || "java.lang.Integer".equals(fieldTypeName)) {
            //转换为int类型并为该成员属性赋值
            int intFieldValue = Integer.parseInt(value);
            obj = intFieldValue;

        }//判断该成员属性是否为String类型
        if ("java.lang.String".equals(fieldTypeName)) {
            //为该成员属性赋值
            obj = value;
        }//判断另外类型同理
        //if(){ }
        return obj;
    }
    public Object getBean(String beanName) {
        Object bean = beanMap.get(beanName);
        if (bean == null) {
            throw new IllegalArgumentException("无法实例化该名称的bean，请确定名称是否正确 " + beanName);
        }
        return bean;
    }
}

```

![image-20210416123006977](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416123006977.png)



![image-20210416123024548](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416123024548.png)

![image-20210416123042500](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210416123042500.png)



# JDBC破坏双亲委派

首先是接口，先加载数据库驱动，java提供了Driber接口，各大数据库供应商提供具体的实现

## 概述

**Java本身有一套资源管理服务JNDI（Java naming and directory interface，Java命名和目录接口），是放置在rt.jar中，由启动类加载器加载的，JDBC也在其中，我们就以我们最熟悉的JDBC为例，来看看为什么JDBC要打破双亲委派模型。**

**我们都知道，我们在使用JDBC时需要自己下载数据库厂商提供的数据库连接驱动jar包，这个jar包实际上就是Driver接口的实现类，下面是Driver接口：**

```java
public interface Driver {
    Connection connect(String url, java.util.Properties info)
        throws SQLException;
    boolean acceptsURL(String url) throws SQLException;
    DriverPropertyInfo[] getPropertyInfo(String url, java.util.Properties info)
                         throws SQLException;
    int getMajorVersion();
    int getMinorVersion();
    boolean jdbcCompliant();
    public Logger getParentLogger() throws SQLFeatureNotSupportedException;
}

```

JDK只能提供一个规范接口，而不能提供对应实现，这个要各数据库厂商去实现。**各数据库厂商通过面向接口编程，实现这个Driver接口，从而屏蔽不同种类数据库的不同实现，使得不同的数据库可以使用相同的API来进行数据操作和查询。**除此之外，还有一个负责**管理Driver的类**，就是DriverManager，大多数人应该都很熟悉，但不一定能理解背后的原理，我们先来看一下删减过的源码：

```java
public class DriverManager {
    // 这里用来保存所有Driver的具体实现
    private final static CopyOnWriteArrayList<DriverInfo> registeredDrivers = new CopyOnWriteArrayList<>();
    public static synchronized void registerDriver(java.sql.Driver driver)
        throws SQLException {
        registerDriver(driver, null);
    }

    public static synchronized void registerDriver(java.sql.Driver driver,
            DriverAction da)
        throws SQLException {

        /* Register the driver if it has not already been added to our list */
        if(driver != null) {
            registeredDrivers.addIfAbsent(new DriverInfo(driver, da));
        } else {
            // This is for compatibility with the original DriverManager
            throw new NullPointerException();
        }

        println("registerDriver: " + driver);
    }
}

```

**以看到我们使用数据库驱动前必须先要在DriverManager中使用registerDriver()注册，然后我们才能正常使用。**

## 不破坏双亲委托模型

**按照我们以前的习惯，我们会使用Class.forName()方法加载驱动，然后再通过DriverManager获取连接，就像这样**

```java
// 1.加载数据访问驱动
Class.forName("com.mysql.jdbc.Driver");
// 2.连接到数据库
Connection conn= DriverManager.getConnection("jdbc:mysql://localhost:3306/mydb?characterEncoding=GBK", "root", "123456");

```

**很显然，Class.forName()方法触发了驱动类的加载，我们以MySQL的驱动类为例看看驱动类内部是如何注册Driver的。**

```java
public class Driver extends NonRegisteringDriver implements java.sql.Driver {
    public Driver() throws SQLException {
    }

    static {
        try {
            DriverManager.registerDriver(new Driver());
        } catch (SQLException var1) {
            throw new RuntimeException("Can't register driver!");
        }
    }
}

```

当驱动类被Class.forName()加载时，类内静态代码块将会被执行，然后MySQL实现的Driver对象就会实例化并且注册到DriverManager。我们通过DriverManager去获取connection的时候只要遍历当前所有Driver实现，然后选择一个建立连接就可以了。

## 破坏双亲委托模型（SPI机制）

**在讲这种加载模式之前，有必要先来了解一下SPI。**

SPI的全名为Service Provider Interface，主要是应用于厂商自定义组件或插件中，在java.util.ServiceLoader的文档里有比较详细的介绍。简单的总结下java SPI机制的思想：系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块、xml解析模块、jdbc模块等方案。

面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。Java SPI就是提供这样的一个机制：为某个接口寻找服务实现。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。

Java SPI的具体约定为：当服务的提供者提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件，该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。

在JDBC4.0以后，开始支持使用SPI的方式来注册这个Driver，具体做法就是在MySQL的驱动jar包中的META-INF/services/java.sql.Driver文件中指明当前使用的Driver实现类，然后使用的时候就直接获取连接就可以了省去了上面的Class.forName()注册过程：

```java
 Connection conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/mydb?characterEncoding=GBK", "root", "123456");

```

**我们来看利用了SPI的加载方式的流程是怎么样的：**

1. **从META-INF/services/java.sql.Driver文件中获取具体的实现类名为“com.mysql.jdbc.Driver”。**
2. **加载这个类，这里也是用class.forName(“com.mysql.jdbc.Driver”)来加载。**

我们发现这种加载方式只是由手动加载变成了自动加载而已，似乎与之前的方式没有什么不同，但是这种加载会遇到一个很大的麻烦。按照类加载规则，Class.forName()加载用的是这个方法的调用者的Classloader，前面讲过这个调用者DriverManager是在rt.jar中的，它的ClassLoader是BootstrapClassLoader，而com.mysql.jdbc.Driver肯定不在<JAVA_HOME>/lib下，所以BootstrapClassLoader肯定是无法加载这个类的。这就是双亲委派模型的局限性了，父级加载器无法加载子级类加载器路径中的类。因此在这种情况下，我们需要破坏双亲委派模型的限制。

那么，这个问题如何解决呢？按照目前情况来分析，这个驱动只有AppClassLoader能加载，那么如果BootstrapClassLoader中有方法能够获取AppClassLoader，然后通过它去加载就可以了。这就是所谓的线程上下文加载器（ContextClassLoader）。ContextClassLoader可以通过Thread.setContextClassLoader()方法设置，如果不特殊设置会从父类继承，一般默认使用的是AppClassLoader。很明显，ContextClassLoader让父级类加载器能通过调用子级类加载器来加载类，这打破了双亲委派模型的原则。

我们可以先对SPI服务加载机制注册驱动的原理进行分析，重点就在DriverManager.getConnection()中。我们知道，调用类的静态方法会初始化该类，而执行其静态代码块是初始化类过程中必不可少的一环。下面是DriverManager的静态代码块：

```java
static {
    loadInitialDrivers();
    println("JDBC DriverManager initialized");
}

```

**静态代码块里面调用了loadInitialDrivers()方法，下面列出这个方法的源码：**

```java
private static void loadInitialDrivers() {
    //省略代码
    //这里就是查找各个数据库厂商在自己的jar包中通过spi注册的驱动
    ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);
    Iterator<Driver> driversIterator = loadedDrivers.iterator();
    try{
         while(driversIterator.hasNext()) {
         	driversIterator.next();
         }
    } catch(Throwable t) {
    	// Do nothing
    }
    //省略代码
}

```

**从源码角度我们看出，SPI的加载流程和我们上面讲的过程完全相同，我们发现SPI加载位于ServiceLoader.load(Driver.class)方法，我们来看一下他的具体实现：**

```java
public static <S> ServiceLoader<S> load(Class<S> service) {
    ClassLoader cl = Thread.currentThread().getContextClassLoader();
    return ServiceLoader.load(service, cl);
}

public static <S> ServiceLoader<S> load(Class<S> service, ClassLoader loader){
    return new ServiceLoader<>(service, loader);
}

```

可以看到代码的核心就是拿到ContextClassLoader，然后构造了一个ServiceLoader。ContextClassLoader默认存放了AppClassLoader的引用，由于它是在运行时被放在了线程中，所以不管当前程序处于何处（BootstrapClassLoader或是ExtClassLoader等），在任何需要的时候都可以用Thread.currentThread().getContextClassLoader()取出应用程序类加载器来完成需要的操作。

**DriverManager中的loadInitialDrivers()方法中有一句driversIterator.next()，它的具体实现如下：**

```java
private S nextService() {
    if (!hasNextService())
        throw new NoSuchElementException();
    String cn = nextName;
    nextName = null;
    Class<?> c = null;
    try {
        //此处的cn就是产商在META-INF/services/java.sql.Driver文件中注册的Driver具体实现类的名称
       //此处的loader就是之前构造ServiceLoader时传进去的ContextClassLoader
        c = Class.forName(cn, false, loader);
    } catch (ClassNotFoundException x) {
        fail(service, "Provider " + cn + " not found");
    }
 	//省略部分代码
}

```

我们成功的做到了通过ContextClassLoader拿到了AppClassLoader，同时我们也查找到了数据库厂商在子级的jar包中注册的驱动具体实现类名，这样我们就可以成功的在rt.jar包中的DriverManager中成功的加载了放在第三方应用程序包中的类了。

到这儿差不多把SPI机制解释清楚了，直白一点说就是JDK提供了一种帮第三方实现者加载服务（如数据库驱动、日志库）的便捷方式，只要遵循约定（把类名写在/META-INF里），那当启动时就会去扫描所有jar包里符合约定的类名的类，再调用forName加载。但这个调用者的ClassLoader是没法加载的，那就把它加载到当前执行线程的线程上下文类加载器里然后再去加载。



# 设计模式



## 单例模式

springIOC中的对象默认是单理的。还有一些大对象创建比较占内存，所以一般就创建一次.因为如果频繁的创建对象，可能对GC垃圾回收造成一定压力.

## 适配器模式

tomcat中的连接器会先把socket请求封装成一个简单requst请求，连接器调用CoyoteAdapter的Sevice方法，传入的是Tomcat Request对象，CoyoteAdapter负责将Tomcat Request转成ServletRequest，再调用容 器的Service方法.

springmvc的适配器

## 代理模式

springAop，就是说为什么我们要使用动态代理，因为我们在开发的时候都是纵向开发，也就是controller层调用service层，service层调用dao层，ok，现在我们的系统发布了，但是现在我们想要增加一个简单的日志功能，如果没有动态代理，我们要在所有执行了这个方法的地方都增加一个输出日志，代码量很大，要修改的地方很多，而且也不符合面向对象的设计原则，面对拓展开发，面对修改关闭，所以我们要横切进去，我们要在不改变原有代码的前提，给我们的系统增加一些功能.所以就用到了AOP

## 模板方法

AQS中提供了几个模仿方法，主要是对资源获取的一个状态的几个模板，AQS底层的CHL队列，AQS已经给我们实现好了，我们在继承AQS的时候只需要重写其中的对对象的状态的这个一个设置就ok了，比如juc下面的那几个工具类都继承了AQS，并重写了关于对象状态的方法，这就是典型的模板方法的设计模式，因为队列我已经实现好了，不需要你们重写了，只要你们各自重写state()的方法就ok.



## 责任链模式

tomcat中的责任链模式

## 工厂方法

spring中的bena工厂。还有很多工厂的例子



## 观察者模式



## 装饰者模式



## 策略模式



# 八大排序

 ![img](https://img-blog.csdnimg.cn/20190206100152611.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI0MDE2MzA5,size_16,color_FFFFFF,t_70) 

## 堆排序

```java
public static void heapSort(int[] array) {
	if (array == null || array.length <= 1) {
		return;
	}

	int length = array.length;

	//1.构建大顶堆
	for (int i = length / 2 - 1; i >= 0; i--) {
		//从第一个非叶子结点从下至上，从右至左调整结构
		adjustHeap(array, i, length);
	}
	//2.调整堆结构+交换堆顶元素与末尾元素
	for (int j = length - 1; j > 0; j--) {
		//将堆顶元素与末尾元素进行交换
		swap(array, 0, j);
		//重新对堆进行调整
		adjustHeap(array, 0, j);
	}

}

/**
 * Description: 调整大顶堆（仅是调整过程，建立在大顶堆已构建的基础上）
 *
 * @param array
 * @param i
 * @param length
 * @return void
 * @author JourWon
 * @date 2019/7/11 17:58
 */
private static void adjustHeap(int[] array, int i, int length) {
	//先取出当前元素i
	int temp = array[i];
	//从i结点的左子结点开始，也就是2i+1处开始
	for (int k = i * 2 + 1; k < length; k = k * 2 + 1) {
		//如果左子结点小于右子结点，k指向右子结点
		if (k + 1 < length && array[k] < array[k + 1]) {
			k++;
		}
		//如果子节点大于父节点，将子节点值赋给父节点（不用进行交换）
		if (array[k] > temp) {
			array[i] = array[k];
			i = k;
		} else {
			break;
		}
	}
	//将temp值放到最终的位置
	array[i] = temp;
}

/**
 * Description: 交换元素位置
 *
 * @param array
 * @param a
 * @param b
 * @return void
 * @author JourWon
 * @date 2019/7/11 17:57
 */
private static void swap(int[] array, int a, int b) {
	int temp = array[a];
	array[a] = array[b];
	array[b] = temp;
}
```



# Linux命令

**一、文件和目录**

### **1. cd命令**

它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径：

- cd /home   进入 '/ home' 目录
- cd ..       返回上一级目录
- cd ../..     返回上两级目录
- cd        进入个人的主目录
- cd ~user1  进入个人的主目录
- cd -       返回上次所在的目录

### **2. pwd命令**

pwd 显示工作路径

### **3. ls命令**

查看文件与目录的命令，list之意：

- ls 查看目录中的文件
- ls -l 显示文件和目录的详细资料
- ls -a 列出全部文件，包含隐藏文件
- ls -R 连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来
- ls [0-9] 显示包含数字的文件名和目录名

### **4. cp 命令**

用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下：

- -a ：将文件的特性一起复制
- -p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份
- -i ：若目标文件已经存在时，在覆盖时会先询问操作的进行
- -r ：递归持续复制，用于目录的复制行为
- -u ：目标文件与源文件有差异时才会复制

### **5.  mv命令**

用于移动文件、目录或更名，move之意：

- -f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖
- -i ：若目标文件已经存在，就会询问是否覆盖
- -u ：若目标文件已经存在，且比目标文件新，才会更新

### **6.  rm 命令**

用于删除文件或目录，remove之意：

- -f ：就是force的意思，忽略不存在的文件，不会出现警告消息
- -i ：互动模式，在删除前会询问用户是否操作
- -r ：递归删除，最常用于目录删除，它是一个非常危险的参数

**二、查看文件内容**

### **7. cat命令**

用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用：

- cat file1 从第一个字节开始正向查看文件的内容

- tac file1 从最后一行开始反向查看一个文件的内容

- cat -n file1 标示文件的行数

- more file1 查看一个长文件的内容

- head -n 2 file1 查看一个文件的前两行

- tail -n 2 file1 查看一个文件的最后两行

- tail -n +1000 file1 从1000行开始显示，显示1000行以后的

- cat filename | head -n 3000 | tail -n +1000 显示1000行到3000行

- cat filename | tail -n +3000 | head -n 1000 从第3000行开始，显示1000(即显示3000~3999行)

  

**三、文件搜索**

### **8. find命令（）**

- find / -name file1 从 '/' 开始进入根文件系统搜索文件和目录
- find / -user user1 搜索属于用户 'user1' 的文件和目录
- find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件
- find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件
- whereis halt 显示一个二进制文件、源码或man的位置
- which halt 显示一个二进制文件或可执行文件的完整路径

删除大于50M的文件：

```
find /var/mail/ -size +50M -exec rm {} ＼;
```

## **四、文件的权限** 使用 "+" 设置权限，使用 "-" 用于取消

### **9. chmod 命令**

- ls -lh 显示权限
- chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r，4 ）、写(w，2)和执行(x，1)的权限
- chmod go-rwx directory1  删除群组(g)与其他人(o)对目录的读写执行权限

### **10. chown 命令**

改变文件的所有者：

- chown user1 file1 改变一个文件的所有人属性
- chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性
- chown user1:group1 file1 改变一个文件的所有人和群组属性

### **11. chgrp 命令**

改变文件所属用户组：

- chgrp group1 file1 改变文件的群组

**五、文本处理**

### **12. grep 命令**

分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等：

- grep Aug /var/log/messages 在文件 '/var/log/messages'中查找关键词"Aug"
- grep ^Aug /var/log/messages 在文件 '/var/log/messages'中查找以"Aug"开始的词汇
- grep [0-9] /var/log/messages 选择 '/var/log/messages' 文件中所有包含数字的行
- grep Aug -R /var/log/* 在目录 '/var/log' 及随后的目录中搜索字符串"Aug"
- sed 's/stringa1/stringa2/g' example.txt 将example.txt文件中的 "string1" 替换成 "string2"
- sed '/^$/d' example.txt 从example.txt文件中删除所有空白行（搜索公众号Java知音，回复“2021”，送你一份Java面试题宝典）

### **13. paste 命令**

- paste file1 file2 合并两个文件或两栏的内容
- paste -d '+' file1 file2 合并两个文件或两栏的内容，中间用"+"区分

### **14. sort 命令**

- sort file1 file2 排序两个文件的内容
- sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)
- sort file1 file2 | uniq -u 删除交集，留下其他的行
- sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)

### 15. comm 命令

- comm -1 file1 file2 比较两个文件的内容只删除 'file1' 所包含的内容
- comm -2 file1 file2 比较两个文件的内容只删除 'file2' 所包含的内容
- comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分

**六、打包和压缩文件**

### **16. tar 命令**

对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压：

- -c ：新建打包文件
- -t ：查看打包文件的内容含有哪些文件名
- -x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中
- -j ：通过bzip2的支持进行压缩/解压缩
- -z ：通过gzip的支持进行压缩/解压缩
- -v ：在压缩/解压缩过程中，将正在处理的文件名显示出来
- -f filename ：filename为要处理的文件
- -C dir ：指定压缩/解压缩的目录dir
- 压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称
- 查询：tar -jtv -f filename.tar.bz2
- 解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录
- bunzip2 file1.bz2 解压一个叫做 'file1.bz2'的文件
- bzip2 file1 压缩一个叫做 'file1' 的文件
- gunzip file1.gz 解压一个叫做 'file1.gz'的文件
- gzip file1 压缩一个叫做 'file1'的文件
- gzip -9 file1 最大程度压缩
- rar a file1.rar test_file 创建一个叫做 'file1.rar' 的包
- rar a file1.rar file1 file2 dir1 同时压缩 'file1', 'file2' 以及目录 'dir1'
- rar x file1.rar 解压rar包
- zip file1.zip file1 创建一个zip格式的压缩包
- unzip file1.zip 解压一个zip格式压缩包
- zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包

**七、系统和关机 (系统的关机、重启以及登出 )**

- shutdown -h now 关闭系统(1)
- init 0 关闭系统(2)
- telinit 0 关闭系统(3)
- shutdown -h hours:minutes & 按预定时间关闭系统
- shutdown -c 取消按预定时间关闭系统
- shutdown -r now 重启(1)
- reboot 重启(2)
- logout 注销
- time 测算一个命令（即程序）的执行时间

**八、进程相关的命令**

### **17 jps命令**

显示当前系统的java进程情况，及其id号：

- jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。

### **18 ps命令**

用于将某个时间点的进程运行情况选取下来并输出，process之意：

- -A ：所有的进程均显示出来
- -a ：不与terminal有关的所有进程
- -u ：有效用户的相关进程
- -x ：一般与a参数一起使用，可列出较完整的信息
- -l ：较长，较详细地将PID的信息列出

```
ps aux # 查看系统所有的进程数据
ps ax # 查看不与terminal有关的所有进程
ps -lA # 查看系统所有的进程数据
ps axjf # 查看连同一部分进程树状态
```

### **19 kill命令**

用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用：

### **20 killall命令**

（向一个命令启动的进程发送一个信号）

### **21 top命令**

是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。

如何杀死进程：

- 图形化界面的方式
- kill -9 pid  （-9表示强制关闭）
- killall -9 程序的名字
- pkill 程序的名字

查看进程端口号：

```
netstat -tunlp|grep 端口号
```

# 场景题

## 扫码登录

三种角色

很明显，扫码登录当中涉及到的三种角色：`PC端`、`手机端`、`服务端`。

![image-20211124204952921](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124204952921.png)

两个问题

扫码登录本质上是一种特殊的登录认证方式，我们面对的是两个问题

- `手机端`如何完成认证
- `PC端`如何完成登录

如果**用普通的账号密码方式登录认证，PC端通过账号密码完成认证，然后服务端给PC端同步返回token key**之类的标识，PC端**再次请求服务端，需要携带token key**，用于标识和证明自己登录的状态。

服务端响应的时候，需要对token key进行校验，通过则正常响应；校验不通过，认证失败；或者token过期，PC端需要再次登录认证，获取新的token key。

![image-20211124205055436](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205055436.png)

现在换成了扫码登录：

- 认证不是通过账号密码了，而是由手机端扫码来完成
- PC端没法同步获取认证成功之后的凭据，必须用某种方式来让PC端获取认证的凭据。

### 手机端如何完成认证

#### 二维码怎么生成

二维码和超市里的条形码类似，超市的条形码实际是一串数字，上面存储了商品的序列号。

二维码的内容就比较自由，里面不止可以存数字，还可以存任何的字符串。我们可以认为，它就是字符的另外一种表现形式。

下面我通过一个网站把文字转成了二维码：

![image-20211124205149617](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205149617.png)

所以，我们手机扫码这个过程，其实是对二维码的解码，获取二维码中包含的数据。

**那么二维码怎么生成呢？**

首先，二维码是展示在我们的PC端，所以生成这个操作应该由PC端去请求服务端，获取相应的数据，再由PC端生成这个二维码。

**二维码包含什么呢？**

二维码在我们这个场景里面是一个重要的媒介，服务端必须给这个数据生成惟一的标识作为**二维码ID**，同时还应该**设置过期的时间**。PC端根据二维码ID等数据生成二维码。

![image-20211124205232620](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205232620.png)

同时，服务端也应该保存二维码的一些状态：`未扫描`、`已成功`、`已失效`。

### APP认证机制

首先，手机端一般是不会存储登录密码的，我们我们发现，只有装载APP，第一次登录的时候，才需要进行基于账号密码的登录，之后即使这个清理掉这个应用进程，甚至手机重启，都是不需要再次输入账号密码的，它可以自动登录。

这背后有一套**基于token的认证机制**，和PC有些类似，但又有一些不同。

![image-20211124205332074](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205332074.png)

- APP登录认证的时候除了账号密码，还有设备信息
- 账号密码校验通过，服务端会把账号与设备进行一个绑定，进行持久化的保存，包含了账号ID，设备ID，设备类型等等
- APP每次请求除了携带token key，还需要**携带设备信息。**

因为**移动端的设备具备唯一性**，可以为每个客户端生成专属token，这个token也不用过期，所以这就是我们可以一次登录，长久使用的原理。

#### 手机扫码干了什么

那这下就清楚了，我们手机扫码干了两件事：

`扫描二维码`：识别PC端展示的二维码，获取二维码ID

![image-20211124205431580](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205431580.png)

`确认登录`：手机端通过带认证信息(token key、设备信息)、二维码信息（二维码ID）请求服务端，完成认证过程，确认PC端的登录。![image-20211124205451117](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205451117.png)

```
ps: 关于手机扫码和确认，不是重点，所以这里进行了简化，一种说法是扫码时同时向服务端申请一次性临时token，确认登录的时候携带这个临时token来访问服务端。
```

## PC端如何完成登录

接下来到我们的重头戏了，手机端完成了它的工作，我们服务端的登录怎么进入登录状态呢？

我们前面讲了，PC端通过token来标识登录状态。那么手机端扫码确认之后，我们的服务端就应该给PC生成相应的token。

那么，这个PC端又如何获取它所需的token key，来完成登录呢？

![image-20211124205517598](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205517598.png)

PC端可以通过获取二维码的状态来进行相应的响应：

- 二维码`未扫描`：无操作
- 二维码`已失效`：提示刷新二维码
- 二维码`已成功`：从服务端获取PC token

获取二维码状态，主要有三种方式：

### 轮询

轮询方式是指客户端会每隔一段时间就主动给服务端发送一次二维码状态的查询请求。

![image-20211124205607806](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205607806.png)

### 长轮询

长轮询是指客户端主动给服务端发送二维码状态的查询请求，服务端会按情况对请求进行阻塞，直至二维码信息更新或超时。当客户端接收到返回结果后，若二维码仍未被扫描，则会继续发送查询请求，直至状态变化（已失效或已成功）。

### Websocket

Websocket是指前端在生成二维码后，会与后端建立连接，一旦后端发现二维码状态变化，可直接通过建立的连接主动推送信息给前端。

![image-20211124205656806](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205656806.png)

### 总结

![image-20211124205723364](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20211124205723364.png)

1. 访问PC端二维码生成页面，PC端请求服务端获取`二维码ID`
2. 服务端生成相应的`二维码ID`，设置二维码的过期时间，状态等。
3. PC获取`二维码ID`，生成相应的二维码。
4. 手机端扫描二维码，获取`二维码ID`。
5. 手机端将`手机端token`和`二维码ID`发送给服务端，确认登录。
6. 服务端校验`手机端token`，根据`手机端token`和`二维码ID`生成`PC端token`
7. PC端通过轮询方式请求服务端，通过`二维码ID`获取二维码状态，如果已成功，返回`PC`token`，登录成功。

